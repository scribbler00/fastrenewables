{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils_pytorch\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn\n",
    "from torch.nn import Embedding\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze_n_final_layer(model, n, include_embedding=False):\n",
    "    \"\"\"\n",
    "    Remove all but the last 'n' layers from the gradient computation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pytorch.nn.ModuleList/pytorch.nn.Sequential/any\n",
    "        the model whose layers are to be excluded from the gradient computation.\n",
    "    n : interger\n",
    "        the number of layers not to be included for gradient computation.\n",
    "    include_embedding : bool\n",
    "        if True, include all embedding layers to the gradient computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Currently embedding layers are either included or excluded through 'include_embedding'.\n",
    "    \"\"\"\n",
    "    # freeze all parameters by excluding them from gradient computation\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Reinclude the parameters of the last n layers to gradient computation\n",
    "    layers = list(model.children())\n",
    "\n",
    "    new_layers = []\n",
    "    for l in layers:\n",
    "        if type(l) is nn.ModuleList:\n",
    "            unfreeze_n_final_layer(l, n, include_embedding=include_embedding)\n",
    "        elif type(l) is Embedding and include_embedding:\n",
    "            for param in l.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif type(l) is Embedding and not include_embedding:\n",
    "            for param in l.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif hasattr(l, \"weight\") or isinstance(l, nn.Sequential):\n",
    "            new_layers.append(l)\n",
    "\n",
    "    if len(new_layers) > 0:\n",
    "        layers = new_layers\n",
    "\n",
    "        if n > len(layers) or n == -1:\n",
    "            n = len(layers)  # relearn the whole network\n",
    "\n",
    "        for i in range(1, n + 1):\n",
    "            for param in layers[-i].parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def freeze(layer):\n",
    "    \"\"\"\n",
    "    Exclude a layer from the gradient computation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer : torch.nn\n",
    "        the layer which is to be excluded from the gradient computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unfreeze(layer):\n",
    "    \"\"\"\n",
    "    Include a layer to the gradient computation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer : torch.nn\n",
    "        the layer which is to be included to the gradient computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    for p in layer.parameters():\n",
    "        p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_requires_grad(\n",
    "    model, include_embedding=True, type_name=\"\", rec_level=0, tabs=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Print which layers of the model are included in the gradient computation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pytorch.nn.ModuleList/pytorch.nn.Sequential/any\n",
    "        the model that is to be analyzed.\n",
    "    include_embedding : bool\n",
    "        currently not used.\n",
    "    type_name : string\n",
    "        currently not used.\n",
    "    rec_level : integer\n",
    "        currently not used.\n",
    "    tabs : string\n",
    "        the amount of space before each print.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    layers = list(model.children())\n",
    "    new_rec_level = rec_level + 1\n",
    "\n",
    "    modules = model._modules\n",
    "    if isinstance(model, nn.ModuleList):\n",
    "        cur_type = \"ModuleList\"\n",
    "    elif isinstance(model, nn.Sequential):\n",
    "        cur_type = \"Sequential\"\n",
    "    else:\n",
    "        cur_type = \"\"\n",
    "    for k, v in modules.items():\n",
    "        if len(v._modules) > 0:\n",
    "            print(f\"{tabs}{cur_type} ({k}): (\")\n",
    "            new_tabs = tabs + \"  \"\n",
    "            print_requires_grad(v, tabs=new_tabs)\n",
    "            print(f\"{tabs})\")\n",
    "        else:\n",
    "            if hasattr(v, \"weight\"):\n",
    "                print(f\"{tabs}({v}) Requires grad: {v.weight.requires_grad}\")\n",
    "            else:\n",
    "                print(f\"{tabs}({v})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def monte_carlo_dropout(model:nn.Module, value:bool):\n",
    "    \"\"\"Method to activate/deactivate monte carlo dropout of a model.\"\"\"\n",
    "    for module in model.modules():\n",
    "        if type(module) in [nn.Dropout, nn.Dropout2d, nn.Dropout3d]:\n",
    "            module.train(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "dropout = nn.Dropout()\n",
    "model = nn.Sequential(nn.Linear(12,12), dropout)\n",
    "monte_carlo_dropout(model, True)\n",
    "test_eq(dropout.training, True)\n",
    "monte_carlo_dropout(model, False)\n",
    "test_eq(dropout.training, False)\n",
    "monte_carlo_dropout(model, True)\n",
    "test_eq(dropout.training, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00a_utils.ipynb.\n",
      "Converted 00b_losses.ipynb.\n",
      "Converted 00c_utils_blitz.ipynb.\n",
      "Converted 00d_baselines.ipynb.\n",
      "Converted 00e_metrics.ipynb.\n",
      "Converted 00f_utils_pytorch.ipynb.\n",
      "Converted 01_tabular.core.ipynb.\n",
      "Converted 02_tabular.data.ipynb.\n",
      "Converted 03_tabular.model.ipynb.\n",
      "Converted 04_tabular.learner.ipynb.\n",
      "Converted 05_timeseries.core.ipynb.\n",
      "Converted 06_timeseries.data.ipynb.\n",
      "Converted 07_timeseries.model.ipynb.\n",
      "Converted 08_timeseries.learner.ipynb.\n",
      "Converted 09_gan.core.ipynb.\n",
      "Converted 10_autoencoder_models.ipynb.\n",
      "Converted 11_probabilistic_models.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
