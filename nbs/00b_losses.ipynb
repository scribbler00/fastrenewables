{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# losses\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VILoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the Kullback-Leibler divergence loss.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : dies.embedding\n",
    "        the given embedding to base the loss on\n",
    "    lambd : float\n",
    "        scalar for the loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        base_loss=torch.nn.MSELoss(),\n",
    "        kl_weight=0.1,\n",
    "        scale_log_likelihood=True\n",
    "    ):\n",
    "        super(VILoss, self).__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.model = model\n",
    "        self.kl_weight = kl_weight\n",
    "        self.scale_log_likelihood=scale_log_likelihood\n",
    "\n",
    "    def forward(self, y, y_hat):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : pytorch.Tensor\n",
    "            any given tensor. Shape: [n, ]\n",
    "        y_hat : pytorch.Tensor\n",
    "            a tensor with the same shape as 'y'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pytorch.Tensor\n",
    "            the resulting accumulated loss\n",
    "        \"\"\"\n",
    "        base_loss = self.base_loss(y, y_hat)\n",
    "\n",
    "        n_samples = max(len(y), 1)\n",
    "\n",
    "        if self.scale_log_likelihood:\n",
    "            base_loss = base_loss * n_samples\n",
    "\n",
    "        kl = self.model.nn_kl_divergence()\n",
    "\n",
    "        loss = base_loss + self.kl_weight * kl\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"VILoss(\\n  (base_loss):\" + str(self.base_loss) + f\"\\n  (kl_weight): {self.kl_weight} \\n)\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Quantile_Score(torch.nn.Module):\n",
    "    \n",
    "    def reshape_1(self, x):\n",
    "        return x.view(x.size()[0],1)\n",
    "    \n",
    "    def __init__(self, taus=[0.25, 0.5, 0.75]):\n",
    "        super(Quantile_Score, self).__init__()\n",
    "        \n",
    "        self.taus =  torch.autograd.Variable(torch.tensor(taus, dtype=torch.float32), \n",
    "                                             requires_grad=False)\n",
    "        \n",
    "        self.taus = self.reshape_1(self.taus).t()\n",
    "        \n",
    "    def forward(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            y = np.array([0.2, 0.1, 0.3, 0.4])\n",
    "            tau=np.array([0.25,0.5,0.75])\n",
    "            for each sample we have one row \n",
    "            y_hat = np.array([[0, 0.2, 0.3], \n",
    "                          [0.05, 0.1, 0.35], \n",
    "                          [0.2, 0.3, 0.6],\n",
    "                          [0.3, 0.4, 0.45],])\n",
    "            res = array([0.125 , 0.2   , 0.25  , 0.0625])\n",
    "        \"\"\"\n",
    "        \n",
    "        y = self.reshape_1(y)\n",
    "        v = y - y_hat\n",
    "        \n",
    "        r = (torch.abs(v*(v>0).float()) * self.taus + \\\n",
    "             torch.abs(v*(v<0).float()) * (1-self.taus))\n",
    "\n",
    "        # this would calculate the loss for each sample\n",
    "        # r =  torch.sum(r,dim=1)\n",
    "        r =  torch.sum(r)\n",
    "        \n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Quantile_Score(taus=[0.25, 0.5, 0.75]).to(\"cpu\")\n",
    "probabilistic_forecasts = torch.tensor([[1,2,3],[4,5,6],[7,8,9],])\n",
    "measurements = torch.tensor([2,5,8])\n",
    "loss(probabilistic_forecasts, measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
