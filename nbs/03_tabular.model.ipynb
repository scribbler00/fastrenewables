{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tabular.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabular.model\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_basics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.tabular.data import *\n",
    "from fastai.tabular.core import *\n",
    "from fastrenewables.tabular.data import *\n",
    "from fastrenewables.utils_blitz import set_train_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fastai.tabular.model import emb_sz_rule\n",
    "from fastai.basics import *\n",
    "from fastai.layers import *\n",
    "\n",
    "\n",
    "from blitz.modules.embedding_bayesian_layer import BayesianEmbedding\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "\n",
    "class EmbeddingType(Enum):\n",
    "    \"\"\"Bayesian or non-Bayesian embedding type.\"\"\"\n",
    "    Normal = 0\n",
    "    Bayes = 1\n",
    "\n",
    "\n",
    "def get_emb_sz_list(dims: list):\n",
    "    \"\"\"\n",
    "    For all elements in the given list, find a size for the respective embedding through trial and error\n",
    "    Each element denotes the amount of unique values for one categorical feature\n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list\n",
    "        a list containing a number of integers.\n",
    "    Returns\n",
    "    -------\n",
    "    list of tupels\n",
    "        a list containing an the amount of unique values and respective embedding size for all elements.\n",
    "    \"\"\"\n",
    "    return [(d, emb_sz_rule(d)) for d in dims]\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class EmbeddingModule(nn.Module):\n",
    "    \"\"\"A container module for a number of embeddings for categorical features.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_dimensions,\n",
    "        embedding_dropout=0.0,\n",
    "        embedding_dimensions=None,\n",
    "        embedding_type=EmbeddingType.Normal,\n",
    "        names=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        categorical_dimensions : list of integers\n",
    "            List with number of categorical values for each feature. \n",
    "            Output size is calculated based on \n",
    "            fastais `emb_sz_rule`. In case explicit dimensions\n",
    "            are required use `embedding_dimensions`.\n",
    "\n",
    "        embedding_dropout : Float\n",
    "            the dropout to be used after the embedding layers.\n",
    "\n",
    "        embedding_dimensions : list of tupels\n",
    "            This list will contain a two element tuple for each\n",
    "            categorical feature. The first element of a tuple will\n",
    "            denote the number of unique values of the categorical\n",
    "            feature. The second element will denote the embedding\n",
    "            dimension to be used for that feature. If None, `categorical_dimensions`\n",
    "            is used to determine the dimensions.\n",
    "        embedding_type : EmbeddingType\n",
    "            the type of embedding that is to be used.\n",
    "        \"\"\"\n",
    "\n",
    "        self.embedding_type = embedding_type\n",
    "\n",
    "        # Set the embedding dimension for all features\n",
    "        if embedding_dimensions is None:\n",
    "            self.embedding_dimensions = get_emb_sz_list(categorical_dimensions)\n",
    "        else:\n",
    "            self.embedding_dimensions = embedding_dimensions\n",
    "\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [self._embedding(ni, nf, **kwargs) for ni, nf in self.embedding_dimensions]\n",
    "        )\n",
    "        self.emb_drop = nn.Dropout(embedding_dropout) if embedding_dropout > 0 else None\n",
    "        self._set_names(names)\n",
    "    \n",
    "    def _set_names(self, names):\n",
    "        if names is not None and len(names) == len(self.embeddings):\n",
    "            self.embeddings_by_names = {n:self.embeddings[i] for i,n in enumerate(names)}\n",
    "        else:\n",
    "            self.embeddings_by_names = None\n",
    "\n",
    "    @property\n",
    "    def _embedding(self):\n",
    "        if self.embedding_type == EmbeddingType.Normal:\n",
    "            emb_type = Embedding\n",
    "        elif self.embedding_type == EmbeddingType.Bayes:\n",
    "            emb_type = BayesianEmbedding\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown embedding type {self.embedding_type}.\")\n",
    "\n",
    "        return emb_type\n",
    "\n",
    "    @property\n",
    "    def no_of_embeddings(self):\n",
    "        return sum(e.embedding_dim for e in self.embeddings)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def categorical_dimensions(self):\n",
    "        return L(e.num_embeddings for e in self.embeddings)\n",
    "\n",
    "    def forward(self, categorical_data):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        categorical_data : pytorch.Tensor\n",
    "            categorical input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pytorch.Tensor\n",
    "            concatenated outputs of the network for all categorical features.\n",
    "        \"\"\"\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                emb_layer(categorical_data[:, i])\n",
    "                for i, emb_layer in enumerate(self.embeddings)\n",
    "            ],\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        x = self.emb_drop(x) if self.emb_drop is not None else x\n",
    "\n",
    "        return x\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Moves and/or casts the parameters of the embeddings.\n",
    "        Parameters\n",
    "        ----------\n",
    "        device (:class:`torch.device`) : the desired device of the parameters\n",
    "                and buffers in this module\n",
    "        dtype (:class:`torch.dtype`) : the desired floating point type of\n",
    "            the floating point parameters and buffers in this module\n",
    "        tensor (torch.Tensor) : Tensor whose dtype and device are the desired\n",
    "            dtype and device for all parameters and buffers in this module\n",
    "        memory_format (:class:`torch.memory_format`) : the desired memory\n",
    "            format for 4D parameters and buffers in this module (keyword\n",
    "            only argument)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self = super().to(*args, **kwargs)\n",
    "        for idx, emb in enumerate(self.embeddings):\n",
    "            self.embeddings[idx] = emb.to(*args, **kwargs)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    @typedispatch\n",
    "    def __getitem__(self, idx: int) -> Module:\n",
    "        return self.embeddings[idx]\n",
    "    @typedispatch\n",
    "    def __getitem__(self, key: str) -> Module:\n",
    "        return self.embeddings_by_names[key]\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = \"\"\n",
    "        if self.embeddings_by_names is not None:\n",
    "            s += f\"Embedding Names: {list(self.embeddings_by_names.keys())}\\n\"\n",
    "            \n",
    "        return s\n",
    "\n",
    "    def reset_cat_embedding(self, emb_id: int, cat_ids: list):\n",
    "        cat_ids = listify(cat_ids)\n",
    "        with torch.no_grad():\n",
    "            emb = self.embeddings[emb_id]\n",
    "            reset_data = self._embedding(emb.num_embeddings, emb.embedding_dim)\n",
    "            if self.embedding_type == EmbeddingType.Normal:\n",
    "                emb.weight[cat_ids, :] = reset_data.weight[cat_ids, :]\n",
    "            else:\n",
    "                emb.weight_sampler.mu[cat_ids, :] = reset_data.weight_sampler.mu[\n",
    "                    cat_ids, :\n",
    "                ]\n",
    "                emb.weight_sampler.rho[cat_ids, :] = reset_data.weight_sampler.rho[\n",
    "                    cat_ids, :\n",
    "                ]\n",
    "\n",
    "    def copy_cat_embedding(self, emb_id: int, from_cat_ids: list, to_cat_ids: list):\n",
    "        from_cat_ids, to_cat_ids = listify(from_cat_ids), listify(to_cat_ids)\n",
    "        with torch.no_grad():\n",
    "            emb = self.embeddings[emb_id]\n",
    "            for idx in range(len(from_cat_ids)):\n",
    "                if isinstance(emb, Embedding):\n",
    "                    emb.weight[to_cat_ids[idx], :] = emb.weight[from_cat_ids[idx], :]\n",
    "                elif isinstance(emb, BayesianEmbedding):\n",
    "                    emb.weight_sampler.mu[to_cat_ids[idx], :] = emb.weight_sampler.mu[\n",
    "                        from_cat_ids[idx], :\n",
    "                    ]\n",
    "                    emb.weight_sampler.rho[to_cat_ids[idx], :] = emb.weight_sampler.rho[\n",
    "                        from_cat_ids[idx], :\n",
    "                    ]\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected embedding type.\")\n",
    "\n",
    "    def increase_embedding_by_one(self, emb_id: int, device=\"cpu\"):\n",
    "        with torch.no_grad():\n",
    "            emb = self.embeddings[emb_id]\n",
    "\n",
    "            if isinstance(emb, Embedding):\n",
    "                emb_new = Embedding(emb.num_embeddings + 1, emb.embedding_dim).to(device)\n",
    "                elements_to_copy = list(range(emb.weight.shape[0]))\n",
    "                emb_new.weight[elements_to_copy, :] = emb.weight[elements_to_copy, :]\n",
    "            elif isinstance(emb, BayesianEmbedding):\n",
    "                emb_new = BayesianEmbedding(emb.num_embeddings + 1, emb.embedding_dim).to(\n",
    "                    device\n",
    "                )\n",
    "                elements_to_copy = list(range(emb.weight_sampler.mu.shape[0]))\n",
    "                emb_new.weight_sampler.mu[elements_to_copy, :] = emb.weight_sampler.mu[\n",
    "                    elements_to_copy, :\n",
    "                ]\n",
    "                emb_new.weight_sampler.rho[elements_to_copy, :] = emb.weight_sampler.rho[\n",
    "                    elements_to_copy, :\n",
    "                ]\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected embedding type.\")\n",
    "\n",
    "            self.embeddings[emb_id] = emb_new\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        set_train_mode(self, mode)\n",
    "\n",
    "\n",
    "@patch\n",
    "def extra_repr(self:BayesianEmbedding): return f\"Shape: {list(self.weight_sampler.mu.shape)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = EmbeddingModule([40,5], names=[\"a\",\"b\"], embedding_type=EmbeddingType.Normal)\n",
    "test_eq(embeddings[0], embeddings[\"a\"])\n",
    "test_eq(embeddings[1], embeddings[\"b\"])\n",
    "embeddings = EmbeddingModule([40,5], names=[\"a\",\"b\"], embedding_type=EmbeddingType.Bayes)\n",
    "test_eq(embeddings[0], embeddings[\"a\"])\n",
    "test_eq(embeddings[1], embeddings[\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = EmbeddingModule(None, names=[\"a\",\"b\"], embedding_dimensions=[(5,2)], \n",
    "                             embedding_type=EmbeddingType.Bayes, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = EmbeddingModule(None, names=[\"a\",\"b\"], embedding_dimensions=[(5,2)], \n",
    "                             embedding_type=EmbeddingType.Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_tensor = torch.tensor([1,2,3,4]).long().reshape(-1,1)\n",
    "test_eq(embeddings(test_cat_tensor).shape, [4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0413, -0.0228]), tensor([0.1093, 0.0611]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.cat([embeddings(test_cat_tensor).detach() for _ in range(1000)])\n",
    "results.mean(0), results.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import ReLU\n",
    "\n",
    "from fastai.tabular.model import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class MultiLayerPerceptron(TabularModel):\n",
    "    \"\"\"An MLP that handles categorical as well as continous features.\"\"\"\n",
    "    @use_kwargs_dict(\n",
    "        ps=None,\n",
    "        embed_p=0.0,\n",
    "        y_range=None,\n",
    "        use_bn=True,\n",
    "        bn_final=False,\n",
    "        act_cls=ReLU(inplace=True),\n",
    "        embedding_module=None,\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        ann_structure,\n",
    "        emb_sz=[],\n",
    "        embedding_module=None,\n",
    "        final_activation=Identity,\n",
    "        bn_cont=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ann_structure : list of integers\n",
    "            amount of features for each layer.\n",
    "        emb_sz : list\n",
    "            currently not used.\n",
    "        embedding_module : dies.embedding\n",
    "            if not 'None', use the given embedding module and adjust the network accordingly.\n",
    "        final_activation : class\n",
    "            activation function for the last layer.\n",
    "        bn_cont : bool\n",
    "            decide whether a batch norm is to be used for the continuous data.\n",
    "        kwargs :\n",
    "\n",
    "        \"\"\"\n",
    "        n_cont = ann_structure[0]\n",
    "        if embedding_module is not None:\n",
    "            emb_sz = []\n",
    "            ann_structure[0] = ann_structure[0] + embedding_module.no_of_embeddings\n",
    "\n",
    "        self.embedding_module = embedding_module\n",
    "        self.final_activation = final_activation()\n",
    "\n",
    "        super(MultiLayerPerceptron, self).__init__(\n",
    "            emb_sz,\n",
    "            ann_structure[0],\n",
    "            ann_structure[-1],\n",
    "            ann_structure[1:-1],\n",
    "            bn_cont=bn_cont,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None\n",
    "\n",
    "    def forward(self, categorical_data, continuous_data):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        categorical_data : pytorch.Tensor\n",
    "            categorical input data. only used when an embedding module is available.\n",
    "        continuous_data : pytorch.Tensor\n",
    "            continuous input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pytorch.Tensor\n",
    "            concatenated outputs of the network for continuous and categorical data.\n",
    "        \"\"\"\n",
    "        if self.embedding_module is None:\n",
    "            x = super().forward(categorical_data, continuous_data)\n",
    "        else:\n",
    "            categorical_data = self.embedding_module(categorical_data)\n",
    "            if self.bn_cont is not None:\n",
    "                continuous_data = self.bn_cont(continuous_data)\n",
    "\n",
    "            x = torch.cat([categorical_data, continuous_data], 1)\n",
    "            x = self.layers(x)\n",
    "\n",
    "        return self.final_activation(x)\n",
    "\n",
    "    def network_split(self):\n",
    "        \"Default split of the body and head\"\n",
    "\n",
    "        if self.embedding_module is not None:\n",
    "            splitter = lambda m: L(\n",
    "                m.layers[0],\n",
    "                m.embedding_module,\n",
    "                m.layers[1:-1],\n",
    "                m.layers[-1:],\n",
    "            ).map(params)\n",
    "\n",
    "            lr = L(1e-6, 1e-6, 1e-6, 1e-4)\n",
    "        else:\n",
    "            splitter = lambda m: L(\n",
    "                m.layers[0],\n",
    "                m.layers[1:-1],\n",
    "                m.layers[-1:],\n",
    "            ).map(params)\n",
    "\n",
    "            lr = L(1e-6, 1e-6, 1e-4)\n",
    "\n",
    "        return splitter, lr\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        set_train_mode(self, mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (final_activation): Identity()\n",
       "  (embeds): ModuleList()\n",
       "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): Linear(in_features=20, out_features=40, bias=False)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): Linear(in_features=40, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayerPerceptron([20,40,1])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (embedding_module): EmbeddingModule(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(40, 13)\n",
       "      (1): Embedding(5, 4)\n",
       "    )\n",
       "  )\n",
       "  (final_activation): Identity()\n",
       "  (embeds): ModuleList()\n",
       "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): Linear(in_features=37, out_features=40, bias=False)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): Linear(in_features=40, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayerPerceptron([20,40,1], \n",
    "                             embedding_module=EmbeddingModule([40,5], embedding_type=EmbeddingType.Normal))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_structure(\n",
    "    initial_size,\n",
    "    percental_reduce,\n",
    "    min_value,\n",
    "    input_size=None,\n",
    "    final_outputs=1,\n",
    "    reverse_structure=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Turn the given parameters into the structure of an ann model.\n",
    "\n",
    "    The 'initial size' acts as the first layer, and each following layer i is of the size\n",
    "    'initial_size' * (1 - percental_reduce) ^ i. This is repeated until 'min_value' is reached. Finally, 'final_outputs'\n",
    "    is appended as the last layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    initial_size : integer\n",
    "        size of the first layer, and baseline for all following layers.\n",
    "    percental_reduce : float\n",
    "        percentage of the size reduction of each subsequent layer.\n",
    "    min_value : integer\n",
    "        the minimum layer size up to which the 'initial_size' is used to create new layers.\n",
    "    input_size : integer\n",
    "        if not None, a layer of the given size will be prepended to the actual structure.\n",
    "    final_outputs : integer\n",
    "        the size of the final layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The finished structure of the ann model.\n",
    "    \"\"\"\n",
    "    ann_structure = [initial_size]\n",
    "    final_outputs = listify(final_outputs)\n",
    "\n",
    "    if 0 in final_outputs or (None in final_outputs):\n",
    "        raise ValueError(\n",
    "            \"Invalid parameters: final_outputs should not contain 0 or None\"\n",
    "        )\n",
    "\n",
    "    if percental_reduce >= 1.0:\n",
    "        percental_reduce = percental_reduce / 100.0\n",
    "\n",
    "    new_size = int(ann_structure[-1] - ann_structure[-1] * percental_reduce)\n",
    "    if new_size >= min_value:\n",
    "        while True:\n",
    "\n",
    "            if new_size <= min_value:\n",
    "                new_size = min_value\n",
    "                ann_structure.append(new_size)\n",
    "                break\n",
    "            else:\n",
    "                ann_structure.append(new_size)\n",
    "\n",
    "            new_size = int(ann_structure[-1] - ann_structure[-1] * percental_reduce)\n",
    "\n",
    "    if reverse_structure:\n",
    "        ann_structure = list(reversed(ann_structure))\n",
    "\n",
    "    if input_size != None:\n",
    "        input_size = listify(input_size)\n",
    "        return input_size + ann_structure + final_outputs\n",
    "\n",
    "    else:\n",
    "        return ann_structure + final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00a_utils.ipynb.\n",
      "Converted 00b_losses.ipynb.\n",
      "Converted 00c_utils_blitz.ipynb.\n",
      "Converted 00d_baselines.ipynb.\n",
      "Converted 00e_metrics.ipynb.\n",
      "Converted 00f_utils_pytorch.ipynb.\n",
      "Converted 01_tabular.core.ipynb.\n",
      "Converted 02_tabular.data.ipynb.\n",
      "Converted 03_tabular.model.ipynb.\n",
      "Converted 04_tabular.learner.ipynb.\n",
      "Converted 05_timeseries.core.ipynb.\n",
      "Converted 06_timeseries.data.ipynb.\n",
      "Converted 07_timeseries.model.ipynb.\n",
      "Converted 08_timeseries.learner.ipynb.\n",
      "Converted 09_gan.core.ipynb.\n",
      "Converted 10_autoencoder_models.ipynb.\n",
      "Converted 11_probabilistic_models.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
