{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gan.learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gan.learner\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fastai.basics import set_seed\n",
    "from fastrenewables.synthetic_data import *\n",
    "from fastrenewables.gan.model import *\n",
    "from fastrenewables.tabular.model import EmbeddingModule\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "#import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GANLearner():\n",
    "    def __init__(self, gan, n_gen=1, n_dis=1):\n",
    "        super(GANLearner, self).__init__()\n",
    "        # gan should contain a class which itself contains a generator and discriminator/critic class and combines them\n",
    "        self.gan = gan\n",
    "        self.n_gen = n_gen\n",
    "        self.n_dis = n_dis\n",
    "   \n",
    "    def generate_samples(self, x_cat, x_cont):\n",
    "        with torch.no_grad():\n",
    "            z = self.gan.noise(x_cont)\n",
    "            fake_samples = self.gan.generator(x_cat, z)\n",
    "        return fake_samples\n",
    "    \n",
    "    def fit(self, dl, epochs=10, lr=1e-3, plot_epochs=10, save_model=False, figsize=(16, 9)):\n",
    "        \n",
    "        self.gan.to_device(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "        self.gan.gen_optim.param_groups[0]['lr'] = lr\n",
    "        self.gan.dis_optim.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        self.gan.train()\n",
    "        \n",
    "        for e in tqdm(range(epochs)):\n",
    "            for x_cat, x_cont, y in dl:\n",
    "                #x_cat[:] = 0\n",
    "                x_cat = x_cat.to(self.gan.device).long()\n",
    "                x_cont = x_cont.to(self.gan.device)\n",
    "                y = y.to(self.gan.device)\n",
    "                                \n",
    "                for _ in range(self.n_dis):\n",
    "                    self.gan.train_discriminator(x_cat, x_cont, y)\n",
    "\n",
    "                for _ in range(self.n_gen):\n",
    "                    self.gan.train_generator(x_cat, x_cont, y)\n",
    "                \n",
    "            if (e+1)%plot_epochs==0:\n",
    "                #plt.figure(figsize=figsize)\n",
    "                #plt.plot(self.gan.real_loss, label='Real Loss')\n",
    "                #plt.plot(self.gan.fake_loss, label='Fake Loss')\n",
    "                #if len(self.gan.aux_loss) > 0:\n",
    "                #    plt.plot(self.gan.aux_loss, label='Aux Loss')\n",
    "                #plt.legend()\n",
    "                #plt.show()\n",
    "                \n",
    "                fig, ax1 = plt.subplots(figsize=figsize)\n",
    "\n",
    "                ax1.set_xlabel('iterations')\n",
    "                ax1.set_ylabel('bce loss')\n",
    "                ax1.plot(self.gan.real_loss, label='real')\n",
    "                ax1.plot(self.gan.fake_loss, label='fake') \n",
    "                ax1.tick_params(axis='y')\n",
    "                ax1.legend(loc='upper right')\n",
    "                ax2 = ax1.twinx()\n",
    "\n",
    "                ax2.set_ylabel('aux loss')\n",
    "                ax2.plot(self.gan.aux_loss, label='aux')\n",
    "                ax2.tick_params(axis='y')\n",
    "                ax2.legend(loc='lower right')\n",
    "                \n",
    "                fig.tight_layout()\n",
    "                plt.show()\n",
    "        \n",
    "        self.gan.eval()\n",
    "        \n",
    "        if save_model:\n",
    "            self.gan.to_device('cpu')\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1337)\n",
    "\n",
    "n_samples = 1024*10\n",
    "n_classes = 4\n",
    "n_features = 1\n",
    "batch_size = 512\n",
    "n_z = 10\n",
    "n_in = n_features\n",
    "n_hidden = 256\n",
    "epochs = 10\n",
    "lr = 1e-5\n",
    "n_gen = 1\n",
    "n_dis = 1\n",
    "gan_type = 'aux'\n",
    "aux_factor = 1/4\n",
    "\n",
    "data = GaussianDataset(n_samples, n_classes)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "emb = EmbeddingModule(categorical_dimensions=[n_classes+1])\n",
    "model = get_gan_model(gan_type=gan_type, structure=[n_z, n_hidden, n_hidden, n_in], n_classes=n_classes, emb_module=emb, bn=True, aux_factor=aux_factor)\n",
    "\n",
    "learner = GANLearner(gan=model, n_gen=n_gen, n_dis=n_dis)\n",
    "learner.fit(dl, epochs=epochs, lr=lr, plot_epochs=epochs, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1337)\n",
    "\n",
    "for x_cat, x_cont, y in dl:\n",
    "    x_cat = x_cat.long()\n",
    "    print('distribution of real data:')\n",
    "    plot_class_hists(x_cat, x_cont, bandwidth=1/25)\n",
    "\n",
    "    x_fake = learner.generate_samples(x_cat, x_cont)\n",
    "    print('distribution of generated data:')\n",
    "    plot_class_hists(x_cat, x_fake, bandwidth=1/25)\n",
    "\n",
    "    for t_id in range(1, n_classes+1):\n",
    "        x_cat[:] = t_id\n",
    "        x_fake = learner.generate_samples(x_cat, x_cont)\n",
    "        print('distribution of generated data:')\n",
    "        plot_class_hists(x_cat, x_fake, bandwidth=1/25)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gan(gan_type, aux_factor, epochs=10):\n",
    "    \n",
    "    set_seed(1337)\n",
    "    model = get_gan_model(gan_type=gan_type, structure=[n_z, n_hidden, n_hidden, n_in], n_classes=n_classes, emb_module=emb, bn=True, aux_factor=aux_factor)\n",
    "    learner = GANLearner(gan=model, n_gen=n_gen, n_dis=n_dis)\n",
    "    learner.fit(dl, epochs=epochs, lr=lr, plot_epochs=epochs, save_model=True)\n",
    "    for x_cat, x_cont, y in dl:\n",
    "        x_cat = x_cat.long()\n",
    "        print('distribution of real data:')\n",
    "        d_real = fit_kde(x_cont, bandwidth=1/25)\n",
    "        x_fake = learner.generate_samples(x_cat, x_cont)\n",
    "        print('distribution of generated data:')\n",
    "        d_fake = fit_kde(x_fake, bandwidth=1/25)\n",
    "        break\n",
    "    kld = calculate_kld(d_real, d_fake)\n",
    "        \n",
    "    return kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = EmbeddingModule(categorical_dimensions=[n_classes+1])\n",
    "\n",
    "klds = []\n",
    "klds.append(evaluate_gan('bce', 1))\n",
    "klds.append(evaluate_gan('aux', 1))\n",
    "klds.append(evaluate_gan('aux', 1/2))\n",
    "klds.append(evaluate_gan('aux', 1/4))\n",
    "klds.append(evaluate_gan('aux', 1/8))\n",
    "klds.append(evaluate_gan('aux', 1/16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
