{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp timeseries.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "from fastai.data.external import *\n",
    "from fastcore.all import *\n",
    "from pathlib import PosixPath\n",
    "from fastcore.test import *\n",
    "from fastai.tabular.all import *\n",
    "import fastai\n",
    "from fastai.tabular.core import _maybe_expand\n",
    "from fastrenewables.tabular.core import *\n",
    "from fastrenewables.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/*.h5')\n",
    "dfs = read_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(splits=None):\n",
    "    return TabularRenewables(pd.concat(dfs), \n",
    "                       pre_process=FilterInconsistentSamplesPerDay, \n",
    "                       splits=ByWeeksSplitter(),\n",
    "                       cat_names=\"TaskID\",\n",
    "                       cont_names = [ 'WindSpeed58m', 'WindSpeed60m'],\n",
    "                       y_names=\"PowerGeneration\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Timeseries(tuple):\n",
    "    def __new__(self, cats, conts, ys, cat_names, cont_names,  y_names):\n",
    "        self.conts = conts\n",
    "        self.cats = cats\n",
    "        self.ys = ys\n",
    "        self.cont_names = cont_names\n",
    "        self.cat_names = cat_names\n",
    "        self.y_names = y_names\n",
    "        return super().__new__(self,(self.conts, self.cats, self.ys))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx[0]\n",
    "        return self.cats[idx:idx+self.bs], self.conts[idx:idx+self.bs], self.ys[idx:idx+self.bs]\n",
    "\n",
    "    def __len__(self): return len(self.cats)\n",
    "    \n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        # TODO: make subplots with grid\n",
    "        n_samples = 5\n",
    "\n",
    "        (\n",
    "            cat,\n",
    "            x,\n",
    "            y,\n",
    "        ) = self\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "            y = y.reshape(1, y.shape[0], y.shape[1])\n",
    "\n",
    "        #  for every feature\n",
    "        for idx in range(x.shape[1]):\n",
    "            # and n samples\n",
    "            for idy in range(min(n_samples, x.shape[0])):\n",
    "                plt.plot(x[idx, idy, :], alpha=0.2)\n",
    "            plt.title(f\"Feature {idx} Samples\")\n",
    "            plt.show()\n",
    "\n",
    "        #  for every target\n",
    "        for idx in range(y.shape[1]):\n",
    "            # and n samples\n",
    "            for idy in range(min(n_samples, y.shape[0])):\n",
    "                plt.plot(y[idx, idy, :], alpha=0.2)\n",
    "            plt.title(f\"Target {idx} Samples\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _convert_tabular_pandas_to_timeseries(\n",
    "        to, \n",
    "        ts_x_length=None, \n",
    "        ts_y_length=None, \n",
    "        y_timeseries_offset=1,\n",
    "        step_size=None\n",
    "    ):\n",
    "        if ts_x_length is None and ts_y_length is None and step_size is None:\n",
    "            timeseries_length = get_samples_per_day(to.items)\n",
    "            ts_x_length = timeseries_length\n",
    "            ts_y_length = timeseries_length\n",
    "            step_size = timeseries_length\n",
    "        elif ts_x_length is not None or ts_y_length is not None or step_size is not None:\n",
    "            raise ValueError(\"Either none or all values must be provided for (ts_x_length, ts_y_length, step_size)\")\n",
    "        \n",
    "        len_data = len(to.xs)\n",
    "        has_cats = len(to.cat_names) > 0\n",
    "        is_cont_output = contains_instance(list(to.procs), RegressionSetup)\n",
    "        \n",
    "        if len_data % ts_x_length != 0:\n",
    "            raise Exception(\"Length of data is not dividable by length of a timeseries sequence.\")\n",
    "        \n",
    "        max_samples = len_data - y_timeseries_offset - ts_y_length\n",
    "\n",
    "        samples_tensor = max_samples // step_size + 1\n",
    "\n",
    "        conts = torch.zeros((samples_tensor, to.conts.shape[1], ts_x_length)).float()\n",
    "        ys = torch.zeros((samples_tensor, to.ys.shape[1], ts_y_length))\n",
    "\n",
    "        cats = None\n",
    "        if has_cats:\n",
    "            cats = torch.zeros((samples_tensor, to.cats.shape[1], ts_x_length)).long()\n",
    "        \n",
    "        for sample_id, i in enumerate(range(0, max_samples + 1, step_size)):\n",
    "            start_x = i\n",
    "            end_x = start_x + ts_x_length\n",
    "            start_y = i + y_timeseries_offset\n",
    "            end_y = start_y + ts_y_length\n",
    "\n",
    "            conts[sample_id, :, :] = tensor(\n",
    "                to.conts[start_x:end_x].values.transpose().reshape(-1, ts_x_length)\n",
    "            )\n",
    "            if has_cats:\n",
    "                cats[sample_id, :, :] = tensor(\n",
    "                    to.cats[start_x:end_x]\n",
    "                    .values.transpose()\n",
    "                    .reshape(-1, ts_x_length)\n",
    "                ).long()\n",
    "\n",
    "            ys[sample_id, :, :] = tensor(\n",
    "                to.ys.iloc[start_y:end_y]\n",
    "                .values.transpose()\n",
    "                .reshape(-1, ts_y_length)\n",
    "            )\n",
    "            \n",
    "        if is_cont_output:\n",
    "            print(\"is cont\")\n",
    "            ys = ys.float()\n",
    "        else:\n",
    "            print(\"is cat\")\n",
    "            ys = ys.long()\n",
    "\n",
    "        return Timeseries(cats, conts, ys, to.cat_names, to.cont_names, to.y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cont\n"
     ]
    }
   ],
   "source": [
    "to = get_data()\n",
    "fast_tuple = _convert_tabular_pandas_to_timeseries(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1502, 2, 24])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tuple.conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   check for types of cats and ys\n",
    "#   check for exception when incorrect size of dataframe\n",
    "#   to.items = to.items[:-2]\n",
    "# _convert_tabular_pandas_to_timeseries(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _check_categoricals(conts, cats, ys, batch_first=True, sequence_last=True):\n",
    "    # If selected, drop all categorical columns which do not have a constant value for each time series\n",
    "    # individually.\n",
    "    if batch_first and sequence_last:\n",
    "        for i in range(cats.shape[1]):\n",
    "            keep_indexes = []\n",
    "            for j in range(cats.shape[0]):\n",
    "                if (cats[j, i, :] - cats[j, i, 0]).sum() == 0:\n",
    "                    keep_indexes += [j]\n",
    "\n",
    "            n_dropped = cats.shape[0] - len(keep_indexes)\n",
    "            if n_dropped > 0:\n",
    "                warnings.warn(\n",
    "                    f\"Dropped {n_dropped} elements due to inconsistent categoricals in a sequence.\"\n",
    "                )\n",
    "            conts = conts[keep_indexes, :, :]\n",
    "            cats = cats[keep_indexes, :, :]\n",
    "            ys = ys[keep_indexes, :, :]\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"Drop inconsistent categoricals is not implemented for batch_first {self.batch_first} and sequence_last {self.sequence_last}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-3d8c93b98559>:13: UserWarning: Dropped 1502 elements due to inconsistent categoricals in a sequence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "to = get_data()\n",
    "cats, conts, ys = _convert_tabular_pandas_to_timeseries(to)\n",
    "cats[1,0,1] = 1\n",
    "_check_categoricals(conts, cats, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _adjust_ts_and_batch(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Swap the dimensions of the given Tensor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        Three dimensional Tensor whose dimensions are to be swapped. Expectes data of the dimension (batch, features, sequence length).\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors should denote the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors should denote the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with swapped dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        pass\n",
    "    elif batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> seq, batch, feature\n",
    "        data = data.permute(2, 0, 1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _convert_to_batch_ts_feature_view(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Converts the data to the followong dimension (batch, sequence length, features).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        three dimensional Tensor whose dimensions are to be swapped.\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors denotes the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors denotes the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with dimensions to be swapped.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # seq, batch, feature -> batch, seq, feature\n",
    "        data = data.permute(1, 0, 2)\n",
    "    elif not batch_first and sequence_last:\n",
    "        # feature, batch, seq -> batch, seq, feature\n",
    "        data = data.permute(1, 2, 0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeseriesTransform(Transform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        to: TabularRenewables,\n",
    "        timeseries_length: int = 24,\n",
    "        batch_first: bool = True,\n",
    "        sequence_last: bool = True,\n",
    "#         drop_last: bool = True,\n",
    "#         is_train: bool = False,\n",
    "#         is_valid: bool = False,\n",
    "        drop_inconsistent_cats: bool = True,\n",
    "        y_timeseries_offset=0,\n",
    "        step_size=24,\n",
    "        splits=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        to : TabularRenewables\n",
    "            input dataset, has to be set up before.\n",
    "        timeseries_length : integer\n",
    "            amount of elements in each time series used for the neural network.\n",
    "        batch_first : bool\n",
    "            determines whether the first dimension of the resulting Tensors denoted the batch.\n",
    "        sequence_last : bool\n",
    "            determines whether the last dimension of the resulting Tensors denoted the sequence length.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.to = to\n",
    "        self.has_cat = len(to.cat_names) > 0\n",
    "        \n",
    "        if getattr(to, \"splits\", None) is not None:\n",
    "            warnings.warn(\"Splitting in in TabularRenewables is currentl supported. \\\n",
    "                          Otherwise a correct splitting for timeseries is not assured. \\\n",
    "                          Fallback to complete data.\")\n",
    "            \n",
    "        self.timeseries_length = timeseries_length\n",
    "        self.step_size = step_size\n",
    "        self.batch_first = batch_first\n",
    "        self.sequence_last = sequence_last\n",
    "        \n",
    "        self.ts = _convert_tabular_pandas_to_timeseries(to)\n",
    "\n",
    "#         self._check_categoricals()\n",
    "\n",
    "        self._adjust_to_required_timeseries_representation()\n",
    "\n",
    "    def _adjust_to_required_timeseries_representation(self):\n",
    "        self.ts.conts = _adjust_ts_and_batch(\n",
    "            self.ts.conts, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        self.ts.ys = _adjust_ts_and_batch(\n",
    "            self.ts.ys, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        if self.has_cat:\n",
    "            self.ts.cats = _adjust_ts_and_batch(\n",
    "                self.ts.cats, self.batch_first, self.sequence_last\n",
    "            )\n",
    "            \n",
    "    @property\n",
    "    def conts(self):\n",
    "        return self.ts.conts\n",
    "    \n",
    "    @property\n",
    "    def cats(self):\n",
    "        return self.ts.cats\n",
    "    \n",
    "    @property\n",
    "    def ys(self):\n",
    "        return self.ts.ys\n",
    "    \n",
    "    @property\n",
    "    def cont_names(self):\n",
    "        return self.to.cont_names\n",
    "    \n",
    "    @property\n",
    "    def cat_names(self):\n",
    "        return self.to.cat_names\n",
    "    \n",
    "    @property\n",
    "    def y_names(self):\n",
    "        return self.to.y_names\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the used TabularPandas.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        integer\n",
    "            amount of lines in the TabularPandas\n",
    "        \"\"\"\n",
    "        return self.ts.conts.shape[0]\n",
    "\n",
    "    @property\n",
    "    def no_input_features(self):\n",
    "        \"\"\"\n",
    "        Return the amount of continuous features in the TabularPandas.\n",
    "        Returns\n",
    "        -------\n",
    "        integer\n",
    "            amount of continuous features in the TabularPandas\n",
    "        \"\"\"\n",
    "        return len(self.tp.cont_names)\n",
    "\n",
    "    def show(self, max_n=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a plot for a 'max_n' of input- and target time series.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_n : interger\n",
    "            amount of samples that are to be plotted.\n",
    "        kwargs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: make subplots with grid\n",
    "        tmp_data = TimeseriesTransform._adjust_ts_and_batch(\n",
    "            self.xs, batch_first=True, sequence_last=True\n",
    "        )\n",
    "\n",
    "        for idx in range(self.xs.shape[1]):\n",
    "            plt.plot(self.xs[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Feature {self.tp.cont_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "        for idx in range(self.ys.shape[1]):\n",
    "            plt.plot(self.ys[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Target {self.tp.y_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "    def _all_names(self):\n",
    "        return [self.to.cat_names, self.to.cont_names, self.to.y_names]\n",
    "    \n",
    "\n",
    "    def encodes(self, i: int):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        i : interger\n",
    "            index of the time series to be processed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Timeseries\n",
    "            Timeseries object of the selected time series.\n",
    "        \"\"\"\n",
    "        cat, cont, y = tensor([]), self.conts[i], self.ys[i]\n",
    "        if self.has_cat:\n",
    "            cat = self.cats[i]\n",
    "        \n",
    "        ts = Timeseries(cat, cont, y, self.cat_names, self.cont_names, self.y_names)\n",
    "\n",
    "        return ts\n",
    "\n",
    "    def decode(self):\n",
    "        \"\"\"\n",
    "        ToDo, not sure about this functionality yet\n",
    "        Revert the transformations of the TabularPandas defined by procs.\n",
    "        Returns\n",
    "        -------\n",
    "        TabularPandas\n",
    "            input TabularPandas with reverted transformations\n",
    "        \"\"\"\n",
    "        print(\"bla2\")\n",
    "        return self.tp.procs.decode(self.tp)\n",
    "\n",
    "    def new(self, data):\n",
    "        \"\"\"\n",
    "        Create a new instance of this class, with the current values as template.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pandas.DataFrame/fastai TabularPandas.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TimeseriesTransform\n",
    "            TimeseriesTransform of the given data.\n",
    "        \"\"\"\n",
    "        print(\"Bla\")\n",
    "        print(\"Bla\")\n",
    "        print(\"Bla\")\n",
    "        new_inst = None\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            new_inst = self.tp.new(data)\n",
    "        elif isinstance(data, TabularPandas):\n",
    "            new_inst = data\n",
    "        else:\n",
    "            raise TypeError\n",
    "\n",
    "        new_inst.process()\n",
    "\n",
    "        new_inst = TimeseriesTransform(\n",
    "            new_inst,\n",
    "            timeseries_length=self.timeseries_length,\n",
    "            sequence_last=self.sequence_last,\n",
    "            batch_first=self.batch_first,\n",
    "            check_consistent_number_per_days=self.check_consistent_number_per_days,\n",
    "            drop_last=self.drop_last,\n",
    "            is_train=False,\n",
    "            is_valid=False,\n",
    "        )\n",
    "\n",
    "        return new_inst\n",
    "\n",
    "    def decodes(self, row):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ToDo\n",
    "        row : list\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            DataFrame containing the data of rows, with the dimension swap being reverted.\n",
    "        \"\"\"\n",
    "        print(\"bla3\")\n",
    "        cat = None\n",
    "\n",
    "        cat, cont, ys = row\n",
    "\n",
    "        cat = TimeseriesTransform._return_to_batch_ts_feature_view(\n",
    "            cat, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        cont = TimeseriesTransform._return_to_batch_ts_feature_view(\n",
    "            cont, self.batch_first, self.sequence_last\n",
    "        )\n",
    "\n",
    "        ys = TimeseriesTransform._return_to_batch_ts_feature_view(\n",
    "            ys, self.batch_first, self.sequence_last\n",
    "        )\n",
    "\n",
    "        cat = to_np(cat.reshape(-1, cat.shape[2]))\n",
    "        cont = to_np(cont.reshape(-1, cont.shape[2]))\n",
    "        ys = to_np(ys.reshape(-1, ys.shape[2]))\n",
    "\n",
    "        print(cat.shape, cont.shape, ys.shape)\n",
    "\n",
    "        df = pd.DataFrame(np.concatenate([cat, cont, ys], axis=1))\n",
    "        df.columns = self.tp.cat_names + self.tp.cont_names + self.tp.y_names\n",
    "\n",
    "        #  drop duplicated columns, e.g., in case of autoencoder\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "        return self.tp.new(df).decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = get_data(ByWeeksSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-216debfd667e>:34: UserWarning: Splitting in in TabularRenewables is currentl supported.                           Otherwise a correct splitting for timeseries is not assured.                           Fallback to complete data.\n",
      "  warnings.warn(\"Splitting in in TabularRenewables is currentl supported. \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cont\n"
     ]
    }
   ],
   "source": [
    "tt = TimeseriesTransform(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabDataset(tt.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TabDataLoader(tt.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]]], device='cuda:0'),\n",
       " tensor([[[ 1.5038,  1.6773,  2.7126,  ..., 10.0086, 10.9092, 11.1178],\n",
       "          [ 0.5298,  0.5688,  0.8911,  ...,  4.8958,  5.5729,  5.7144]],\n",
       " \n",
       "         [[11.3852, 11.8512, 12.6789,  ...,  3.3998,  3.3108,  4.3648],\n",
       "          [ 5.8004,  6.2328,  6.7199,  ...,  1.5870,  1.6341,  1.9479]],\n",
       " \n",
       "         [[ 2.2877,  1.7911,  1.5227,  ...,  3.0596,  2.2090,  3.2375],\n",
       "          [ 0.7184,  0.5582,  0.4286,  ...,  1.1641,  0.7119,  1.3566]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.6861,  1.6764,  2.0730,  ...,  2.3571,  2.5275,  2.5239],\n",
       "          [ 0.6654,  0.6235,  0.8967,  ...,  0.9233,  1.0639,  1.0528]],\n",
       " \n",
       "         [[ 3.1837,  3.3456,  2.9668,  ...,  3.9607,  3.3363,  2.6867],\n",
       "          [ 1.4003,  1.4631,  1.0765,  ...,  1.4572,  0.9433,  0.5493]],\n",
       " \n",
       "         [[ 3.2394,  3.7048,  4.3716,  ...,  8.8222,  7.1345,  7.7008],\n",
       "          [ 0.9227,  1.1231,  1.2343,  ...,  4.1611,  3.2974,  3.4594]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[0.0000, 0.0000, 0.0100, 0.0080, 0.0460, 0.0590, 0.0320, 0.0010,\n",
       "           0.0930, 0.0590, 0.0010, 0.0000, 0.0000, 0.0040, 0.1100, 0.1470,\n",
       "           0.2000, 0.0930, 0.3460, 0.7740, 0.3080, 0.1600, 0.0760, 0.4160]],\n",
       " \n",
       "         [[0.3270, 0.2890, 0.4870, 0.3690, 0.4870, 0.4630, 0.2890, 0.7070,\n",
       "           0.4630, 0.2150, 0.2330, 0.1870, 0.3690, 0.1210, 0.0460, 0.0140,\n",
       "           0.0170, 0.0000, 0.0100, 0.0170, 0.0170, 0.0010, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0020, 0.0000, 0.0000, 0.0010, 0.0000, 0.0010, 0.0080, 0.0020,\n",
       "           0.0080, 0.0590, 0.0320, 0.3080, 0.1870, 0.1600, 0.0590, 0.0460,\n",
       "           0.0410, 0.0460, 0.0410, 0.0510, 0.0590, 0.0170, 0.0140, 0.0010]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0120, 0.0140, 0.0040, 0.0000,\n",
       "           0.0020, 0.0060, 0.0140, 0.0270, 0.0410, 0.0410, 0.1210, 0.0670,\n",
       "           0.0840, 0.0320, 0.1340, 0.0460, 0.2150, 0.1600, 0.0590, 0.0410]],\n",
       " \n",
       "         [[0.0010, 0.0040, 0.0120, 0.0170, 0.0270, 0.1010, 0.0360, 0.2000,\n",
       "           0.2150, 0.2890, 0.3930, 0.4160, 0.1470, 0.2520, 0.2710, 0.4160,\n",
       "           0.2330, 0.2710, 0.4870, 0.1210, 0.1470, 0.1870, 0.1870, 0.0510]],\n",
       " \n",
       "         [[0.2330, 0.0670, 0.1210, 0.0590, 0.3930, 0.3930, 0.1600, 0.4870,\n",
       "           0.2890, 0.3080, 0.0270, 0.2150, 0.0320, 0.0360, 0.0460, 0.0010,\n",
       "           0.0040, 0.0010, 0.0460, 0.0120, 0.0670, 0.0100, 0.0360, 0.0040]],\n",
       " \n",
       "         [[0.0100, 0.0000, 0.0460, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000,\n",
       "           0.0000, 0.0000, 0.0080, 0.0000, 0.0000, 0.0100, 0.0010, 0.0120,\n",
       "           0.1870, 0.1100, 0.0270, 0.0170, 0.0760, 0.1740, 0.2890, 0.8190]],\n",
       " \n",
       "         [[0.2150, 0.0760, 0.1010, 0.1600, 0.1210, 0.0840, 0.0510, 0.2150,\n",
       "           0.1340, 0.6580, 0.5840, 0.8920, 0.8770, 0.9500, 0.8190, 0.6340,\n",
       "           0.8620, 0.7070, 0.9940, 0.6340, 1.0000, 0.7740, 0.7970, 0.5590]],\n",
       " \n",
       "         [[0.9210, 0.3080, 0.1870, 0.8920, 0.2000, 0.2520, 0.1340, 0.2330,\n",
       "           0.1100, 0.4160, 0.4160, 0.3690, 0.3080, 0.6090, 0.3690, 0.5100,\n",
       "           0.4630, 0.6580, 0.6090, 0.1870, 0.2710, 0.1100, 0.1870, 0.1100]],\n",
       " \n",
       "         [[0.0670, 0.0360, 0.0510, 0.1010, 0.2150, 0.2710, 0.1010, 0.0590,\n",
       "           0.0320, 0.1470, 0.0670, 0.0270, 0.0360, 0.0590, 0.0360, 0.0270,\n",
       "           0.0120, 0.0360, 0.0460, 0.0080, 0.0000, 0.0000, 0.0010, 0.0010]],\n",
       " \n",
       "         [[0.0010, 0.0010, 0.0000, 0.0010, 0.0000, 0.0000, 0.0000, 0.0010,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0170, 0.0670, 0.0140, 0.0320, 0.0010, 0.0320]],\n",
       " \n",
       "         [[0.1470, 0.0670, 0.0460, 0.0170, 0.0040, 0.0510, 0.0410, 0.0590,\n",
       "           0.2000, 0.2520, 0.3930, 0.1740, 0.0510, 0.0410, 0.1470, 0.1210,\n",
       "           0.2890, 0.1100, 0.1210, 0.0460, 0.1600, 0.0270, 0.0220, 0.0930]],\n",
       " \n",
       "         [[0.0320, 0.0080, 0.0100, 0.0010, 0.0840, 0.0170, 0.0270, 0.0000,\n",
       "           0.1210, 0.0020, 0.0590, 0.1100, 0.0760, 0.0840, 0.0840, 0.1600,\n",
       "           0.5350, 0.7070, 0.7070, 0.1340, 0.4630, 0.4630, 0.5840, 0.6090]],\n",
       " \n",
       "         [[0.8770, 1.0000, 0.4870, 0.6580, 0.5100, 0.3690, 0.2520, 0.4160,\n",
       "           0.5350, 0.5100, 0.3460, 0.1100, 0.3080, 0.1470, 0.5350, 0.1010,\n",
       "           0.0170, 0.0930, 0.0360, 0.0270, 0.0320, 0.0010, 0.0080, 0.0000]],\n",
       " \n",
       "         [[0.0010, 0.0000, 0.0080, 0.0460, 0.0000, 0.0010, 0.0000, 0.0010,\n",
       "           0.2890, 0.6090, 0.3270, 0.1870, 0.0460, 0.0270, 0.2710, 0.2330,\n",
       "           0.1100, 0.1470, 0.1600, 0.1100, 0.1600, 0.0120, 0.1870, 0.5590]],\n",
       " \n",
       "         [[0.1210, 0.6340, 0.4870, 0.0840, 0.0930, 0.0510, 0.0510, 0.1340,\n",
       "           0.2150, 0.1010, 0.0410, 0.0670, 0.0360, 0.1210, 0.0220, 0.0140,\n",
       "           0.0080, 0.4400, 0.7970, 0.3460, 0.0140, 0.0460, 0.0930, 0.2710]],\n",
       " \n",
       "         [[0.2710, 0.3080, 0.0930, 0.1600, 0.0460, 0.0010, 0.0080, 0.0220,\n",
       "           0.0760, 0.2150, 0.2150, 0.4400, 0.6340, 0.4630, 0.1210, 0.2890,\n",
       "           0.0460, 0.0270, 0.1010, 0.0510, 0.3080, 0.4400, 0.0510, 0.0010]],\n",
       " \n",
       "         [[0.0010, 0.0080, 0.0360, 0.0670, 0.0760, 0.0100, 0.0010, 0.0000,\n",
       "           0.0010, 0.0000, 0.0010, 0.0010, 0.0220, 0.0020, 0.0010, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0010, 0.0040, 0.0010, 0.0010, 0.0010, 0.0020, 0.0020,\n",
       "           0.0000, 0.0000, 0.0840, 0.0220, 0.0270, 0.0930, 0.0220, 0.0010,\n",
       "           0.0320, 0.0120, 0.0120, 0.0010, 0.0010, 0.0000, 0.0060, 0.0080]],\n",
       " \n",
       "         [[0.0000, 0.0100, 0.0100, 0.0010, 0.0010, 0.0040, 0.0060, 0.0060,\n",
       "           0.0010, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010,\n",
       "           0.0010, 0.0010, 0.0060, 0.0040, 0.0080, 0.0100, 0.0170, 0.0100]],\n",
       " \n",
       "         [[0.0010, 0.0120, 0.0040, 0.0010, 0.0020, 0.0010, 0.0000, 0.0000,\n",
       "           0.0010, 0.0000, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010,\n",
       "           0.0010, 0.0000, 0.0000, 0.0120, 0.0010, 0.0010, 0.0010, 0.0020]],\n",
       " \n",
       "         [[0.0040, 0.0010, 0.0000, 0.0010, 0.0010, 0.0010, 0.0000, 0.0140,\n",
       "           0.0590, 0.0120, 0.0170, 0.0840, 0.1100, 0.0410, 0.2000, 0.1870,\n",
       "           0.1470, 0.0590, 0.0170, 0.0410, 0.0060, 0.0170, 0.0120, 0.0010]],\n",
       " \n",
       "         [[0.0040, 0.0080, 0.0060, 0.0010, 0.0020, 0.0040, 0.0270, 0.0010,\n",
       "           0.0670, 0.0060, 0.0670, 0.0930, 0.0410, 0.0220, 0.0120, 0.0140,\n",
       "           0.0460, 0.0010, 0.0010, 0.0040, 0.0010, 0.0010, 0.0170, 0.0120]],\n",
       " \n",
       "         [[0.0510, 0.0510, 0.0080, 0.0020, 0.0460, 0.0170, 0.0120, 0.0010,\n",
       "           0.0010, 0.0100, 0.0080, 0.0170, 0.0590, 0.0410, 0.0140, 0.0010,\n",
       "           0.0080, 0.0000, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0010, 0.0010, 0.0010, 0.1870, 0.0760, 0.0460,\n",
       "           0.0590, 0.0460, 0.0320, 0.0410, 0.0840, 0.0840, 0.4400, 0.3270]],\n",
       " \n",
       "         [[0.2890, 0.0120, 0.0140, 0.0000, 0.0010, 0.7520, 0.3270, 0.5590,\n",
       "           0.3460, 0.1740, 0.3930, 0.1210, 0.2890, 0.1600, 0.3930, 0.1210,\n",
       "           0.2520, 0.1340, 0.0080, 0.0000, 0.0040, 0.0170, 0.0040, 0.1740]],\n",
       " \n",
       "         [[0.0220, 0.0170, 0.1740, 0.0840, 0.0670, 0.0100, 0.0010, 0.0270,\n",
       "           0.0460, 0.1340, 0.3080, 0.4400, 0.2890, 0.3930, 0.1340, 0.2000,\n",
       "           0.3080, 0.1010, 0.0360, 0.0060, 0.0120, 0.1740, 0.0270, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0010, 0.0000, 0.0220, 0.0170, 0.0170, 0.0080, 0.0320,\n",
       "           0.1210, 0.0320, 0.0410, 0.0020, 0.1870, 0.2330, 0.0410, 0.0010,\n",
       "           0.0010, 0.0170, 0.0320, 0.0060, 0.0140, 0.0170, 0.0100, 0.0010]],\n",
       " \n",
       "         [[0.0010, 0.0060, 0.0020, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0060, 0.0040, 0.0040, 0.0140, 0.0080, 0.0010, 0.0020,\n",
       "           0.0010, 0.0010, 0.0000, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0010, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
       "           0.0000, 0.0170, 0.0140, 0.0460, 0.1600, 0.2330, 0.0140, 0.0170,\n",
       "           0.0000, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0010, 0.0000, 0.0000, 0.0010, 0.0060, 0.0140, 0.1210, 0.1100,\n",
       "           0.1100, 0.0510, 0.1010, 0.1600, 0.2890, 0.4870, 0.3270, 0.1470,\n",
       "           0.0510, 0.0840, 0.0120, 0.0010, 0.0140, 0.0010, 0.0000, 0.0010]],\n",
       " \n",
       "         [[0.0670, 0.0510, 0.0140, 0.0410, 0.1100, 0.1870, 0.1600, 0.0760,\n",
       "           0.2000, 0.0670, 0.3080, 0.2150, 0.1340, 0.0840, 0.0930, 0.0510,\n",
       "           0.1600, 0.0170, 0.0220, 0.0410, 0.1740, 0.2520, 0.4870, 0.1010]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adapt based on tabular core dataloader, add splits in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
