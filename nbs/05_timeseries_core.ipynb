{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp timeseries.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "from fastai.data.external import *\n",
    "from fastcore.all import *\n",
    "from pathlib import PosixPath\n",
    "from fastcore.test import *\n",
    "from fastai.tabular.all import *\n",
    "import fastai\n",
    "from fastai.tabular.core import _maybe_expand\n",
    "from fastrenewables.tabular.core import *\n",
    "from fastrenewables.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/*.h5')\n",
    "dfs = read_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(splits=None):\n",
    "    return TabularRenewables(pd.concat(dfs), \n",
    "                       pre_process=FilterInconsistentSamplesPerDay, \n",
    "                       splits=splits,\n",
    "                       cat_names=\"TaskID\",\n",
    "                       cont_names = [ 'WindSpeed58m', 'WindSpeed60m'],\n",
    "                       y_names=\"PowerGeneration\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _convert_tabular_pandas_to_timeseries(\n",
    "        to, \n",
    "        ts_x_length=None, \n",
    "        ts_y_length=None, \n",
    "        y_timeseries_offset=1,\n",
    "        step_size=None\n",
    "    ):\n",
    "        if ts_x_length is None and ts_y_length is None and step_size is None:\n",
    "            timeseries_length = get_samples_per_day(to.items)\n",
    "            ts_x_length = timeseries_length\n",
    "            ts_y_length = timeseries_length\n",
    "            step_size = timeseries_length\n",
    "        elif ts_x_length is not None or ts_y_length is not None or step_size is not None:\n",
    "            raise ValueError(\"Either none or all values must be provided for (ts_x_length, ts_y_length, step_size)\")\n",
    "        \n",
    "        len_data = len(to.xs)\n",
    "        has_cats = len(to.cat_names) > 0\n",
    "        is_cont_output = contains_instance(list(to.procs), RegressionSetup)\n",
    "        \n",
    "        if len_data % ts_x_length != 0:\n",
    "            raise Exception(\"Length of data is not dividable by length of a timeseries sequence.\")\n",
    "        \n",
    "        max_samples = len_data - y_timeseries_offset - ts_y_length\n",
    "\n",
    "        samples_tensor = max_samples // step_size + 1\n",
    "\n",
    "        conts = torch.zeros((samples_tensor, to.conts.shape[1], ts_x_length)).float()\n",
    "        ys = torch.zeros((samples_tensor, to.ys.shape[1], ts_y_length))\n",
    "\n",
    "        cats = None\n",
    "        if has_cats:\n",
    "            cats = torch.zeros((samples_tensor, to.cats.shape[1], ts_x_length)).long()\n",
    "        else:\n",
    "            cats = torch.empty(((samples_tensor, to.cats.shape[1], ts_x_length)))\n",
    "            \n",
    "        for sample_id, i in enumerate(range(0, max_samples + 1, step_size)):\n",
    "            start_x = i\n",
    "            end_x = start_x + ts_x_length\n",
    "            start_y = i + y_timeseries_offset\n",
    "            end_y = start_y + ts_y_length\n",
    "\n",
    "            conts[sample_id, :, :] = tensor(\n",
    "                to.conts[start_x:end_x].values.transpose().reshape(-1, ts_x_length)\n",
    "            )\n",
    "            if has_cats:\n",
    "                cats[sample_id, :, :] = tensor(\n",
    "                    to.cats[start_x:end_x]\n",
    "                    .values.transpose()\n",
    "                    .reshape(-1, ts_x_length)\n",
    "                ).long()\n",
    "\n",
    "            ys[sample_id, :, :] = tensor(\n",
    "                to.ys.iloc[start_y:end_y]\n",
    "                .values.transpose()\n",
    "                .reshape(-1, ts_y_length)\n",
    "            )\n",
    "            \n",
    "        if is_cont_output:\n",
    "            print(\"is cont\")\n",
    "            ys = ys.float()\n",
    "        else:\n",
    "            print(\"is cat\")\n",
    "            ys = ys.long()\n",
    "\n",
    "        return cats, conts, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = get_data()\n",
    "cats, conts, ys = _convert_tabular_pandas_to_timeseries(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   check for types of cats and ys\n",
    "#   check for exception when incorrect size of dataframe\n",
    "#   to.items = to.items[:-2]\n",
    "# _convert_tabular_pandas_to_timeseries(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _check_categoricals(conts, cats, ys, batch_first=True, sequence_last=True):\n",
    "    # If selected, drop all categorical columns which do not have a constant value for each time series\n",
    "    # individually.\n",
    "    if batch_first and sequence_last:\n",
    "        for i in range(cats.shape[1]):\n",
    "            keep_indexes = []\n",
    "            for j in range(cats.shape[0]):\n",
    "                if (cats[j, i, :] - cats[j, i, 0]).sum() == 0:\n",
    "                    keep_indexes += [j]\n",
    "\n",
    "            n_dropped = cats.shape[0] - len(keep_indexes)\n",
    "            if n_dropped > 0:\n",
    "                warnings.warn(\n",
    "                    f\"Dropped {n_dropped} elements due to inconsistent categoricals in a sequence.\"\n",
    "                )\n",
    "            conts = conts[keep_indexes, :, :]\n",
    "            cats = cats[keep_indexes, :, :]\n",
    "            ys = ys[keep_indexes, :, :]\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"Drop inconsistent categoricals is not implemented for batch_first {self.batch_first} and sequence_last {self.sequence_last}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = get_data()\n",
    "cats, conts, ys = _convert_tabular_pandas_to_timeseries(to)\n",
    "cats[1,0,1] = 1\n",
    "_check_categoricals(conts, cats, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _adjust_ts_and_batch(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Swap the dimensions of the given Tensor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        Three dimensional Tensor whose dimensions are to be swapped. Expectes data of the dimension (batch, features, sequence length).\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors should denote the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors should denote the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with swapped dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        pass\n",
    "    elif batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> seq, batch, feature\n",
    "        data = data.permute(2, 0, 1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _convert_to_batch_ts_feature_view(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Converts the data to the followong dimension (batch, sequence length, features).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        three dimensional Tensor whose dimensions are to be swapped.\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors denotes the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors denotes the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with dimensions to be swapped.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # seq, batch, feature -> batch, seq, feature\n",
    "        data = data.permute(1, 0, 2)\n",
    "    elif not batch_first and sequence_last:\n",
    "        # feature, batch, seq -> batch, seq, feature\n",
    "        data = data.permute(1, 2, 0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeseriesTransform(Transform, FilteredBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        to: TabularRenewables,\n",
    "        timeseries_length: int = 24,\n",
    "        batch_first: bool = True,\n",
    "        sequence_last: bool = True,\n",
    "        drop_inconsistent_cats: bool = True,\n",
    "        y_timeseries_offset=0,\n",
    "        step_size=24,\n",
    "        splits=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        to : TabularRenewables\n",
    "            input dataset, has to be set up before.\n",
    "        timeseries_length : integer\n",
    "            amount of elements in each time series used for the neural network.\n",
    "        batch_first : bool\n",
    "            determines whether the first dimension of the resulting Tensors denoted the batch.\n",
    "        sequence_last : bool\n",
    "            determines whether the last dimension of the resulting Tensors denoted the sequence length.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.to = to\n",
    "        self.has_cat = len(to.cat_names) > 0\n",
    "        \n",
    "        if getattr(to, \"splits\", None) is not None:\n",
    "            warnings.warn(\"Splitting in TabularRenewables is currentl supported. \\\n",
    "                          Otherwise a correct splitting for timeseries is not assured. \\\n",
    "                          Fallback to complete data.\")\n",
    "            \n",
    "        self.timeseries_length = timeseries_length\n",
    "        self.step_size = step_size\n",
    "        self.batch_first = batch_first\n",
    "        self.sequence_last = sequence_last\n",
    "        \n",
    "        self.cats, self.conts, self.ys = _convert_tabular_pandas_to_timeseries(to)\n",
    "\n",
    "        self._adjust_to_required_timeseries_representation()\n",
    "        \n",
    "        if splits is None:\n",
    "            self.split = range(0,len(self))\n",
    "        else:\n",
    "            # TODO: check if it is already an object?\n",
    "            splits = splits(self)\n",
    "            self.split = splits\n",
    "\n",
    "    def _adjust_to_required_timeseries_representation(self):\n",
    "        self.conts = _adjust_ts_and_batch(\n",
    "            self.conts, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        self.ys = _adjust_ts_and_batch(\n",
    "            self.ys, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        if self.has_cat:\n",
    "            self.cats = _adjust_ts_and_batch(\n",
    "                self.cats, self.batch_first, self.sequence_last\n",
    "            )\n",
    "            \n",
    "    # required for splitting of train and eval\n",
    "    def subset(self, i): \n",
    "        # ToDo: index=None, batch_first=True, sequence_last=True\n",
    "#         split = slice(0,self.split) if i==0 else slice(self.split,len(self))\n",
    "#         split = self.split if i==0 else slice(self.split,len(self))\n",
    "        if len(self.split) == 2:\n",
    "            return TimeseriesDataset(self._data_by_split(self.split[i]), self._all_names())\n",
    "        elif i == 0:\n",
    "            return TimeseriesDataset(self._data_by_split(self.split), self._all_names())\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.subset(0)\n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.subset(1)\n",
    "    \n",
    "    def _data_by_split(self, split):\n",
    "        return (self.cats[split], self.conts[split], self.ys[split])\n",
    "    \n",
    "    def _all_names(self):\n",
    "        return (self.cat_names, self.cont_names, self.y_names)\n",
    "            \n",
    "    @property\n",
    "    def cont_names(self):\n",
    "        return self.to.cont_names\n",
    "    \n",
    "    @property\n",
    "    def cat_names(self):\n",
    "        return self.to.cat_names\n",
    "    \n",
    "    @property\n",
    "    def y_names(self):\n",
    "        return self.to.y_names\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the used TabularPandas.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        integer\n",
    "            amount of lines in the TabularPandas\n",
    "        \"\"\"\n",
    "        # TODO depends on position of batch\n",
    "        return self.conts.shape[0]\n",
    "\n",
    "    def show(self, max_n=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a plot for a 'max_n' of input- and target time series.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_n : interger\n",
    "            amount of samples that are to be plotted.\n",
    "        kwargs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: make subplots with grid\n",
    "        tmp_data = TimeseriesTransform._adjust_ts_and_batch(\n",
    "            self.xs, batch_first=True, sequence_last=True\n",
    "        )\n",
    "\n",
    "        for idx in range(self.xs.shape[1]):\n",
    "            plt.plot(self.xs[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Feature {self.tp.cont_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "        for idx in range(self.ys.shape[1]):\n",
    "            plt.plot(self.ys[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Target {self.tp.y_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "    def _all_names(self):\n",
    "        return [self.to.cat_names, self.to.cont_names, self.to.y_names]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeseriesDataset(fastuple):\n",
    "    \"A dataset from a `TimeseriesTransform` object\"\n",
    "#     TODO add index\n",
    "    def __init__(self, data, names, index=None, batch_first=True, sequence_last=True):\n",
    "        self.cats, self.conts, self.ys = data\n",
    "        self.cat_names, self.cont_names, self.y_names = names\n",
    "        if not batch_first or not sequence_last:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx[0]\n",
    "        return self.cats[idx:idx+self.bs], self.conts[idx:idx+self.bs], self.ys[idx:idx+self.bs]\n",
    "\n",
    "    def __len__(self): return len(self.conts)\n",
    "    \n",
    "    def _as_df(self, max_n):\n",
    "        df_cont = pd.DataFrame(data=self.conts[:max_n].reshape(-1,self.conts.shape[1]), columns=self.cont_names)\n",
    "        df_cat = pd.DataFrame(data=self.cats[:max_n].reshape(-1,self.cats.shape[1]), columns=self.cat_names)\n",
    "        df_y = pd.DataFrame(data=self.ys[:max_n].reshape(-1,self.ys.shape[1]), columns=self.y_names)\n",
    "        return pd.concat([df_cont, df_cat, df_y], axis=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        represenation = f\"{self.cat_names}:\\n{self.cats}\\n\\n{self.cont_names}:\\n{self.conts}\\n\\n{self.y_names}:\\n{self.ys}\\n\\n\"\n",
    "        return represenation\n",
    "    \n",
    "    def show(self, max_n=10, **kwargs): \n",
    "        display_df(self._as_df(max_n))\n",
    "        \n",
    "    def show_batch(self, max_n=10, **kwargs): \n",
    "        self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeSeriesDataLoaders(DataLoaders):\n",
    "    def __init__(self, to, bs=64, val_bs=None, shuffle_train=True, device='cpu', **kwargs):\n",
    "        train_ds = to.train\n",
    "        valid_ds = to.valid\n",
    "        val_bs = bs if val_bs is None else val_bs\n",
    "        train = TabDataLoader(train_ds, bs=bs, shuffle=shuffle_train, device=device, **kwargs)\n",
    "        valid = TabDataLoader(valid_ds, bs=val_bs, shuffle=False, device=device, **kwargs)\n",
    "        super().__init__(train, valid, device=device, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cont\n"
     ]
    }
   ],
   "source": [
    "tt = TimeseriesTransform(to, splits=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabDataLoaders(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 24]), torch.Size([16, 2, 24]), torch.Size([16, 1, 24]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = TabDataLoader(tt.train, bs=16)\n",
    "cats,conts, ys = dl.one_batch()\n",
    "cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 24]), torch.Size([16, 2, 24]), torch.Size([16, 1, 24]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = TabDataLoader(tt.valid, bs=16, shuffle=True)\n",
    "cats,conts, ys = dl.one_batch()\n",
    "cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adapt based on tabular core dataloader, add splits in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
