{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp timeseries.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# timeseries.core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "from fastai.data.external import *\n",
    "from fastcore.all import *\n",
    "from pathlib import PosixPath\n",
    "from fastcore.test import *\n",
    "from fastai.tabular.all import *\n",
    "import fastai\n",
    "from fastai.tabular.core import _maybe_expand\n",
    "from fastrenewables.tabular.core import *\n",
    "from fastrenewables.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/*.h5')\n",
    "dfs = read_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(splits=None):\n",
    "    return TabularRenewables(pd.concat(dfs), \n",
    "                       pre_process=FilterInconsistentSamplesPerDay, \n",
    "                       splits=splits,\n",
    "                       cat_names=\"TaskID\",\n",
    "                       cont_names = [ 'WindSpeed58m', 'WindSpeed60m'],\n",
    "                       y_names=\"PowerGeneration\",\n",
    "                       procs=Categorify,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_df():\n",
    "    np.random.seed(123)\n",
    "    cont1, cont2 = np.arange(0,48, 0.5), np.arange(0,48, 0.5)[::-1]\n",
    "    conts = np.concatenate([cont1.reshape(-1,1), cont2.reshape(-1,1)], axis=1)\n",
    "    cat = np.random.randint(0,5, 96)\n",
    "    task_ids = np.zeros(96)\n",
    "    task_ids[-16:] = 1\n",
    "    y = np.random.randn((96))\n",
    "    df = pd.DataFrame(conts, columns=[\"x1\", \"x2\"])\n",
    "    df[\"cat\"] = cat\n",
    "    df[\"TID\"] = task_ids\n",
    "    df[\"y\"] = y\n",
    "    df.index =pd.date_range(\"1/1/2021\", freq=\"3H\", periods=96)\n",
    "    return df\n",
    "\n",
    "def get_test_tabular(target=\"y\"):\n",
    "    df = get_test_df()\n",
    "    \n",
    "    return TabularRenewables(df.sample(frac=1), cat_names=\"cat\", y_names=target, \n",
    "                             cont_names=[\"x1\", \"x2\"], group_id=\"TID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reshape_dataframe_to_timeseries_representation(df, ts_length, column_names):\n",
    "    \"Returns tensor in the shape [n_samples, timeseries length, number features].\\\n",
    "    Assumes that dataframe is of a single task.\"\n",
    "    \n",
    "    df = df.sort_index()\n",
    "    reshaped_values = df[column_names].values.reshape(-1, ts_length, len(column_names))\n",
    "    return tensor(reshaped_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_first_cont_tensor = tensor([[0,47.5],\n",
    "       [0.5, 47],\n",
    "       [1,46.5],\n",
    "       [1.5,46],\n",
    "       [2,45.5],\n",
    "       [2.5,45],\n",
    "       [3,44.5],\n",
    "       [3.5,44],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(expected_first_cont_tensor, _reshape_dataframe_to_timeseries_representation(get_test_df(), 24//3, [\"x1\", \"x2\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_samples_per_day_single_task(to):\n",
    "    \"Gets the number of samples per day, for a TabularRenewables with multiple tasks.\"\n",
    "    task_ids = to[to.group_id].unique()\n",
    "    df = to.items[to.items[to.group_id]==task_ids[0]]\n",
    "    return get_samples_per_day(df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>cat</th>\n",
       "      <th>TID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-12 12:00:00</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.240680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 03:00:00</th>\n",
       "      <td>4.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.181689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       x1    x2  cat  TID         y\n",
       "2021-01-12 12:00:00  46.0   1.5    1  1.0 -0.240680\n",
       "2021-01-02 03:00:00   4.5  43.0    0  0.0 -0.181689"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = get_test_tabular();to.group_id\n",
    "to.items.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we test wheter we can find the correct samples per day in a shufled dataframe \n",
    "# with multiple tasks. this can e.g. occur in a preprocessed tabular renewables\n",
    "# that should be converted to a timeseries representation\n",
    "test_eq(8, _get_samples_per_day_single_task(to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _correct_types(to, cats, conts, ys):\n",
    "    if len(to.cat_names) > 0:\n",
    "        cats = cats.long()\n",
    "    # continious/regression output\n",
    "    if contains_instance(list(to.procs), RegressionSetup):\n",
    "        ys = ys.float()\n",
    "    else:\n",
    "        ys = ys.long()\n",
    "    return cats, conts, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def convert_to_timeseries_representation(to:TabularRenewables, timeseries_length:int):\n",
    "    \"Converts a tabular renewables to a timeseries representation of \\\n",
    "    [n_samples, timeseries length, number features].\"\n",
    "    cats, conts, ys= [], [], []\n",
    "    has_cats = len(to.cat_names) > 0\n",
    "    for task_id, df in to.items.groupby(to.group_id):\n",
    "        df = df.sort_index()\n",
    "        conts.append(_reshape_dataframe_to_timeseries_representation(df, timeseries_length, to.cont_names))\n",
    "        ys.append(_reshape_dataframe_to_timeseries_representation(df, timeseries_length, to.y_names))\n",
    "        if has_cats:\n",
    "            cats.append(_reshape_dataframe_to_timeseries_representation(df, timeseries_length, to.cat_names).long())\n",
    "    # batch, seq, features -> batch, features, seq\n",
    "    cats, conts, ys = torch.cat(cats).permute(0, 2, 1), torch.cat(conts).permute(0, 2, 1), torch.cat(ys).permute(0, 2, 1)\n",
    "    return _correct_types(to, cats, conts, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(expected_first_cont_tensor.T, convert_to_timeseries_representation(to, 24//3)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# TODO: should work with typedispatch for convert_to_timeseries_representation\n",
    "# but is not redirecting correctly\n",
    "# @typedispatch\n",
    "def _reshape_dataframe_to_timeseries_representation_different_lengths(df:pd.DataFrame, cont_names:list, \n",
    "                                         cat_names:list, y_names:list,\n",
    "                                         ts_x_length:int, ts_y_length:int, \n",
    "                                        step_size:int, y_timeseries_offset:int):\n",
    "    len_data = df.shape[0]\n",
    "    has_cats = len(cat_names)>0\n",
    "    max_samples = len_data - y_timeseries_offset - ts_y_length\n",
    "\n",
    "    samples_tensor = max_samples // step_size + 1\n",
    "\n",
    "    conts = torch.zeros((samples_tensor, len(cont_names), ts_x_length)).float()\n",
    "    ys = torch.zeros((samples_tensor, len(cat_names), ts_y_length))\n",
    "\n",
    "    cats = None\n",
    "    if has_cats:\n",
    "        cats = torch.zeros((samples_tensor, len(cat_names), ts_x_length)).long()\n",
    "    else:\n",
    "        cats = torch.empty(((samples_tensor, len(cat_names), ts_x_length)))\n",
    "\n",
    "    for sample_id, i in enumerate(range(0, max_samples + 1, step_size)):\n",
    "        start_x = i\n",
    "        end_x = start_x + ts_x_length\n",
    "        start_y = i + y_timeseries_offset\n",
    "        end_y = start_y + ts_y_length\n",
    "\n",
    "        conts[sample_id, :, :] = tensor(\n",
    "            df[cont_names][start_x:end_x].values.transpose().reshape(-1, ts_x_length)\n",
    "        )\n",
    "        if has_cats:\n",
    "            cats[sample_id, :, :] = tensor(\n",
    "                df[cat_names][start_x:end_x]\n",
    "                .values.transpose()\n",
    "                .reshape(-1, ts_x_length)\n",
    "            ).long()\n",
    "\n",
    "        ys[sample_id, :, :] = tensor(\n",
    "            df[y_names].iloc[start_y:end_y]\n",
    "            .values.transpose()\n",
    "            .reshape(-1, ts_y_length)\n",
    "        )\n",
    "\n",
    "    return cats, conts, ys\n",
    "\n",
    "# @typedispatch\n",
    "def convert_to_timeseries_representation_different_lengths(to:TabularRenewables, \n",
    "                                                           ts_x_length:int, \n",
    "                                                           ts_y_length:int, \n",
    "                                                           step_size:int, \n",
    "                                                           y_timeseries_offset:int):\n",
    "    \"Converts a tabular renewables to a timeseries representation of \\\n",
    "    [n_samples, timeseries length, number features].\\\n",
    "    ts_x_length: The length of the input timeseries.\\\n",
    "    ts_y_length: The length of the output timeseries.\\\n",
    "    step_size: The shift for the output. Similar to a sliding window. \\\n",
    "    y_timeseries_offset: The (initial) offset of the output compared to the input.\"\n",
    "    \n",
    "    cats, conts, ys= L(), L(), L()\n",
    "    has_cats = len(to.cat_names) > 0\n",
    "    for task_id, df in to.items.groupby(to.group_id):\n",
    "        df = df.sort_index()\n",
    "        cat, cont, y = _reshape_dataframe_to_timeseries_representation_different_lengths(df,  \n",
    "                                                            cont_names=to.cont_names, \n",
    "                                                            cat_names=to.cat_names, \n",
    "                                                            y_names=to.y_names, \n",
    "                                                            ts_x_length=ts_x_length, \n",
    "                                                            ts_y_length=ts_y_length, \n",
    "                                                            step_size=step_size, \n",
    "                                                            y_timeseries_offset=y_timeseries_offset)\n",
    "        conts += cont\n",
    "        ys += y\n",
    "        if has_cats:\n",
    "            cats += cat\n",
    "    cats, conts, ys = torch.cat(list(cats)), torch.cat(list(conts)), torch.cat(list(ys))\n",
    "\n",
    "    return _correct_types(to, cats, conts, ys)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_day = 24//3\n",
    "y_timeseries_offset = 2\n",
    "ts_y_length=n_samples_per_day-y_timeseries_offset\n",
    "step_size=n_samples_per_day\n",
    "df = get_test_df()\n",
    "cats, conts, ys = convert_to_timeseries_representation_different_lengths(to, \n",
    "                                                      ts_x_length=n_samples_per_day,\n",
    "                                                      ts_y_length=ts_y_length,\n",
    "                                                      step_size=step_size,\n",
    "                                                      y_timeseries_offset=y_timeseries_offset)\n",
    "test_eq(expected_first_cont_tensor.T, conts[0])\n",
    "# first element of y should be equal to the element by the offset in the dataframe\n",
    "test_eq(df[\"y\"][y_timeseries_offset], ys[0][0][0])\n",
    "# for each sample of the time series we increase by the step size\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size], ys[1][0][0])\n",
    "# for each sample of the time series we increase by the step size\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size], ys[1][0][0])\n",
    "# where the length of this timeseries is given by ts_y_length\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size+ts_y_length-1], ys[1][0][-1])\n",
    "# as we reduced the length of y by the offset, the last element should still be the last element\n",
    "test_eq(df[\"y\"][-1], ys[-1][-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_timeseries_offset = 1\n",
    "ts_y_length = 1\n",
    "ts_x_length = 2\n",
    "step_size=2\n",
    "df = get_test_df()\n",
    "cats, conts, ys = convert_to_timeseries_representation_different_lengths(to, \n",
    "                                                      ts_x_length=ts_x_length,\n",
    "                                                      ts_y_length=ts_y_length,\n",
    "                                                      step_size=step_size,\n",
    "                                                      y_timeseries_offset=y_timeseries_offset)\n",
    "test_eq(df[\"y\"][y_timeseries_offset], ys[0][0][0])\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size], ys[1][0][0])\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size], ys[1][0][0])\n",
    "test_eq(df[\"y\"][y_timeseries_offset+step_size+ts_y_length-1], ys[1][0][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _convert_tabular_pandas_to_timeseries(\n",
    "        to, \n",
    "        ts_x_length=None, \n",
    "        ts_y_length=None, \n",
    "        step_size=None,\n",
    "        y_timeseries_offset=0,\n",
    "    ):\n",
    "        timeseries_length = None\n",
    "        if (ts_x_length == None) and (ts_y_length == None) and (step_size == None):\n",
    "            timeseries_length = _get_samples_per_day_single_task(to)\n",
    "            ts_x_length = timeseries_length\n",
    "            ts_y_length = timeseries_length\n",
    "            step_size = timeseries_length\n",
    "        elif None in (ts_x_length, ts_y_length, step_size):\n",
    "            raise ValueError(\"Either none or all values must be provided for (ts_x_length, ts_y_length, step_size)\")\n",
    "        \n",
    "        len_data = len(to.xs)\n",
    "        has_cats = len(to.cat_names) > 0\n",
    "        n_conts, n_cats, n_ys = len(to.cont_names),  len(to.cat_names), len(to.y_names)\n",
    "        \n",
    "        if len_data % ts_x_length != 0:\n",
    "            raise Exception(\"Length of data is not dividable by length of a timeseries sequence.\")\n",
    "        \n",
    "        if (ts_x_length == ts_y_length == step_size) and (y_timeseries_offset==0) and timeseries_length is not None:\n",
    "            cats, conts, ys = convert_to_timeseries_representation(to, timeseries_length)\n",
    "        else:\n",
    "            cats, conts, ys = convert_to_timeseries_representation_different_lengths(to, \n",
    "                                                ts_x_length=ts_x_length, \n",
    "                                                ts_y_length=ts_y_length,\n",
    "                                                step_size=step_size, \n",
    "                                                y_timeseries_offset=y_timeseries_offset)\n",
    "        ts_lengths = (ts_x_length, ts_y_length, step_size)\n",
    "        return ts_lengths, cats, conts, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 1, 8]), torch.Size([12, 2, 8]), torch.Size([12, 1, 8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = get_test_tabular()\n",
    "ts_lengths, cats, conts, ys = _convert_tabular_pandas_to_timeseries(to)\n",
    "cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 1, 8]), torch.Size([12, 2, 8]), torch.Size([12, 1, 8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = get_test_tabular()\n",
    "ts_lengths, cats, conts, ys = _convert_tabular_pandas_to_timeseries(to, ts_x_length=8, ts_y_length=8, step_size=8)\n",
    "cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _check_categoricals(conts, cats, ys, batch_first=True, sequence_last=True):\n",
    "    # If selected, drop all categorical columns which do not have a constant value for each time series\n",
    "    # individually.\n",
    "    if batch_first and sequence_last:\n",
    "        for i in range(cats.shape[1]):\n",
    "            keep_indexes = []\n",
    "            for j in range(cats.shape[0]):\n",
    "                if (cats[j, i, :] - cats[j, i, 0]).sum() == 0:\n",
    "                    keep_indexes += [j]\n",
    "\n",
    "            n_dropped = cats.shape[0] - len(keep_indexes)\n",
    "            if n_dropped > 0:\n",
    "                warnings.warn(\n",
    "                    f\"Dropped {n_dropped} elements due to inconsistent categoricals in a sequence.\"\n",
    "                )\n",
    "            conts = conts[keep_indexes, :, :]\n",
    "            cats = cats[keep_indexes, :, :]\n",
    "            ys = ys[keep_indexes, :, :]\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"Drop inconsistent categoricals is not implemented for batch_first {self.batch_first} and sequence_last {self.sequence_last}\"\n",
    "        )\n",
    "    return cats, conts, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-1c0d6a704443>:15: UserWarning: Dropped 2 elements due to inconsistent categoricals in a sequence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "to = get_test_tabular()\n",
    "_, cats, conts, ys = _convert_tabular_pandas_to_timeseries(to)\n",
    "# simulate that all catecoricals have the same value along the timerseries axis\n",
    "cats = torch.ones_like(cats)\n",
    "# fake two incorrect values\n",
    "cats[0][0][1]=0\n",
    "cats[-1][0][1]=3\n",
    "cats_checked, conts_checked, ys_checked = _check_categoricals(conts, cats, ys)\n",
    "# check if two values have been removed in all input/output and catecoricals\n",
    "test_eq(cats.shape[0]-2, cats_checked.shape[0])\n",
    "test_eq(conts.shape[0]-2, conts_checked.shape[0])\n",
    "test_eq(ys.shape[0]-2, ys_checked.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _adjust_ts_and_batch(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Swap the dimensions of the given Tensor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        Three dimensional Tensor whose dimensions are to be swapped. Expectes data of the dimension (batch, features, sequence length).\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors should denote the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors should denote the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with swapped dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        pass\n",
    "    elif batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # batch, feature, seq -> seq, batch, feature\n",
    "        data = data.permute(2, 0, 1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _convert_to_batch_ts_feature_view(data, batch_first, sequence_last):\n",
    "    \"\"\"\n",
    "    Converts the data to the followong dimension (batch, sequence length, features).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pytorch.Tensor\n",
    "        three dimensional Tensor whose dimensions are to be swapped.\n",
    "    batch_first : bool\n",
    "        determines whether the first dimension of the resulting Tensors denotes the batch.\n",
    "    sequence_last : bool\n",
    "        determines whether the last dimension of the resulting Tensors denotes the sequence length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pytorch.Tensor\n",
    "        input tensor with dimensions to be swapped.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first and sequence_last:\n",
    "        # batch, feature, seq -> batch, seq, feature\n",
    "        data = data.permute(0, 2, 1)\n",
    "    elif not batch_first and not sequence_last:\n",
    "        # seq, batch, feature -> batch, seq, feature\n",
    "        data = data.permute(1, 0, 2)\n",
    "    elif not batch_first and sequence_last:\n",
    "        # feature, batch, seq -> batch, seq, feature\n",
    "        data = data.permute(1, 2, 0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeseriesTransform(Transform, FilteredBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        to: TabularRenewables,\n",
    "        ts_x_length: int = None,\n",
    "        ts_y_length: int = None,\n",
    "        step_size:int = None, \n",
    "        y_timeseries_offset=0,\n",
    "        batch_first: bool = True,\n",
    "        sequence_last: bool = True,\n",
    "        drop_inconsistent_cats: bool = True,\n",
    "        splits=None,\n",
    "        post_hooks=[]\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        to : TabularRenewables\n",
    "            input dataset, has to be set up before.\n",
    "        ts_x_length: The length of the input timeseries.\n",
    "        ts_y_length: The length of the output timeseries.\n",
    "        step_size: The shift for the output. Similar to a sliding window. \n",
    "        y_timeseries_offset: The (initial) offset of the output compared to the input.\n",
    "        batch_first : bool\n",
    "            determines whether the first dimension of the resulting Tensors denoted the batch.\n",
    "        sequence_last : bool\n",
    "            determines whether the last dimension of the resulting Tensors denoted the sequence length.\n",
    "        post_hooks : Simples transforms applied after transformations of the dataset to a timeseries.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.to = to\n",
    "        self.has_cat = len(to.cat_names) > 0\n",
    "        self.batch_first, self.sequence_last = batch_first, sequence_last\n",
    "        \n",
    "        if getattr(to, \"splits\", None) is not None:\n",
    "            warnings.warn(\"Splitting in TabularRenewables is currentl supported. \\\n",
    "                          Otherwise a correct splitting for timeseries is not assured. \\\n",
    "                          Fallback to complete data.\")\n",
    "            \n",
    "        \n",
    "        ts_lengths, self.cats, self.conts, self.ys = _convert_tabular_pandas_to_timeseries(to, \n",
    "                                                                               ts_x_length=ts_x_length,\n",
    "                                                                               ts_y_length = ts_y_length,\n",
    "                                                                               step_size = step_size,\n",
    "                                                                               y_timeseries_offset = y_timeseries_offset\n",
    "                                                                              )\n",
    "        self.ts_x_length, self.ts_y_length, self.step_size = ts_lengths\n",
    "        self.y_timeseries_offset = y_timeseries_offset\n",
    "        \n",
    "\n",
    "        self._adjust_to_required_timeseries_representation()\n",
    "        \n",
    "        for post_hook in post_hooks:\n",
    "            self.cats, self.conts, self.ys = post_hook(self.cats, self.conts, self.ys)\n",
    "        \n",
    "        if splits is None:\n",
    "            self.split = range(0,len(self))\n",
    "        else:\n",
    "            # TODO: check if it is already an object?\n",
    "            splits = splits(self)\n",
    "            self.split = splits\n",
    "\n",
    "    def _adjust_to_required_timeseries_representation(self):\n",
    "        self.conts = _adjust_ts_and_batch(\n",
    "            self.conts, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        self.ys = _adjust_ts_and_batch(\n",
    "            self.ys, self.batch_first, self.sequence_last\n",
    "        )\n",
    "        if self.has_cat:\n",
    "            self.cats = _adjust_ts_and_batch(\n",
    "                self.cats, self.batch_first, self.sequence_last\n",
    "            )\n",
    "    @property\n",
    "    def n_subsets(self):\n",
    "        return len(self.split)\n",
    "    \n",
    "    # required for splitting of train and eval\n",
    "    def subset(self, i): \n",
    "        # ToDo: index=None, batch_first=True, sequence_last=True\n",
    "        if len(self.split) == 2:\n",
    "            return TimeseriesDataset(self._data_by_split(self.split[i]), \n",
    "                                     self._all_names(), getattr(self.to, \"classes\", None))\n",
    "        elif i == 0:\n",
    "            return TimeseriesDataset(self._data_by_split(self.split), \n",
    "                                     self._all_names(), getattr(self.to, \"classes\", None))\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.subset(0)\n",
    "    \n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.subset(1)\n",
    "    \n",
    "    def _data_by_split(self, split):\n",
    "        return (self.cats[split], self.conts[split], self.ys[split])\n",
    "    \n",
    "    def _data_by_id(self, i:int):\n",
    "        return (self.cats[i], self.conts[i], self.ys[i])\n",
    "    \n",
    "    def _all_names(self):\n",
    "        return (self.cat_names, self.cont_names, self.y_names)\n",
    "    \n",
    "#     def encodes(self, i: int):\n",
    "#         \"\"\"\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         i : interger\n",
    "#             index of the time series to be processed.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         Timeseries\n",
    "#             Timeseries object of the selected time series.\n",
    "#         \"\"\"\n",
    "#         data = self._data_by_id(i)\n",
    "        \n",
    "#         ts = TimeseriesDataset(\n",
    "#             data, self._all_names()\n",
    "#         )\n",
    "         \n",
    "    \n",
    "#         return ts\n",
    "            \n",
    "    @property\n",
    "    def cont_names(self):\n",
    "        return self.to.cont_names\n",
    "    \n",
    "    @property\n",
    "    def cat_names(self):\n",
    "        return self.to.cat_names\n",
    "    \n",
    "    @property\n",
    "    def y_names(self):\n",
    "        return self.to.y_names\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the used TabularPandas.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        integer\n",
    "            amount of lines in the TabularPandas\n",
    "        \"\"\"\n",
    "        # TODO depends on position of batch\n",
    "        return self.conts.shape[0]\n",
    "\n",
    "    def show(self, max_n=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a plot for a 'max_n' of input- and target time series.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_n : interger\n",
    "            amount of samples that are to be plotted.\n",
    "        kwargs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        # TODO: make subplots with grid\n",
    "        tmp_data = TimeseriesTransform._adjust_ts_and_batch(\n",
    "            self.xs, batch_first=True, sequence_last=True\n",
    "        )\n",
    "\n",
    "        for idx in range(self.xs.shape[1]):\n",
    "            plt.plot(self.xs[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Feature {self.tp.cont_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "        for idx in range(self.ys.shape[1]):\n",
    "            plt.plot(self.ys[0:max_n, idx, :].reshape(-1, 1))\n",
    "            plt.title(f\"Target {self.tp.y_names[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "    def _all_names(self):\n",
    "        return [self.to.cat_names, self.to.cont_names, self.to.y_names]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeseriesDataset(fastuple):\n",
    "    \"A dataset from a `TimeseriesTransform` object\"\n",
    "#     TODO add index\n",
    "    def __init__(self, data, names, classes=None, index=None, batch_first=True, sequence_last=True):\n",
    "        self.cats, self.conts, self.ys = data\n",
    "        self.cat_names, self.cont_names, self.y_names = names\n",
    "        self.classes = classes\n",
    "        if not batch_first or not sequence_last:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        self.n_inp = 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx[0]\n",
    "        return self.cats[idx:idx+self.bs], self.conts[idx:idx+self.bs], self.ys[idx:idx+self.bs]\n",
    "\n",
    "    def __len__(self): return len(self.conts)\n",
    "    \n",
    "    def new_empty(self):\n",
    "        return TimeseriesDataset((torch.empty(0), torch.empty(0), torch.empty(0)), [[], [], []])\n",
    "    \n",
    "    def _as_df(self, max_n):\n",
    "        df_cont = pd.DataFrame(data=self.conts[:max_n].reshape(-1,self.conts.shape[1]), columns=self.cont_names)\n",
    "        df_cat = pd.DataFrame(data=self.cats[:max_n].reshape(-1,self.cats.shape[1]), columns=self.cat_names)\n",
    "        df_y = pd.DataFrame(data=self.ys[:max_n].reshape(-1,self.ys.shape[1]), columns=self.y_names)\n",
    "        return pd.concat([df_cont, df_cat, df_y], axis=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        represenation = f\"{self.cat_names}:\\n{self.cats}\\n\\n{self.cont_names}:\\n{self.conts}\\n\\n{self.y_names}:\\n{self.ys}\\n\\n\"\n",
    "        return represenation\n",
    "    \n",
    "    def show(self, max_n=10, **kwargs): \n",
    "        display_df(self._as_df(max_n))\n",
    "        \n",
    "    def show_batch(self, max_n=10, **kwargs): \n",
    "        self.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeSeriesDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, bs=32, num_workers=0, device='cuda', \n",
    "                 to_device=True, shuffle=False, drop_last=True,**kwargs):\n",
    "        \"A `DataLoader` based on a `TabDataset\"\n",
    "        device = device if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        super().__init__(dataset, bs=bs, num_workers=num_workers, shuffle=shuffle, \n",
    "                         device=device, drop_last=drop_last, **kwargs)\n",
    "        \n",
    "        self.dataset.bs=bs\n",
    "        if to_device:self.to_device()\n",
    "    \n",
    "    def create_item(self, s): return s\n",
    "    \n",
    "    def to_device(self, device=None):\n",
    "        if device is None: device = self.device\n",
    "        self.dataset.cats.to(device)\n",
    "        self.dataset.conts.to(device)\n",
    "        self.dataset.ys.to(device)\n",
    "    \n",
    "    def create_batch(self, b):\n",
    "        \"Create a batch of data\"\n",
    "        cat, cont, y = self.dataset[b]\n",
    "        return cat.to(self.device), cont.to(self.device), y.to(self.device)\n",
    "\n",
    "    def get_idxs(self):\n",
    "        \"Get index's to select\"\n",
    "        idxs = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is not None: idxs = list(range(len(self.dataset)))\n",
    "        return idxs\n",
    "\n",
    "    def shuffle_fn(self):\n",
    "        \"Shuffle the interior dataset\"\n",
    "        rng = np.random.permutation(len(self.dataset))\n",
    "        self.dataset.cats = self.dataset.cats[rng]\n",
    "        self.dataset.conts = self.dataset.conts[rng]\n",
    "        self.dataset.ys = self.dataset.ys[rng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeSeriesDataLoaders(DataLoaders):\n",
    "    def __init__(self, to, bs=64, val_bs=None, shuffle_train=True, device='cpu', **kwargs):\n",
    "        if isinstance(to, TimeseriesTransform):\n",
    "            train_ds = to.train\n",
    "            valid_ds = to.valid\n",
    "#         elif isinstance(to, TimeseriesDataset):\n",
    "        else:\n",
    "            train_ds = to\n",
    "            valid_ds = to.new_empty()\n",
    "#         else:\n",
    "#             raise ValueError(\"Unsupported dadatype.\")\n",
    "            \n",
    "        val_bs = bs if val_bs is None else val_bs\n",
    "        train = TimeSeriesDataLoader(train_ds, bs=bs, shuffle=shuffle_train, device=device, **kwargs)\n",
    "        valid = TimeSeriesDataLoader(valid_ds, bs=val_bs, shuffle=False, device=device, **kwargs)\n",
    "        super().__init__(train, valid, device=device, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TimeseriesTransform(to, splits=RandomSplitter(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TimeSeriesDataLoaders(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TimeSeriesDataLoader(tt.train, bs=2)\n",
    "cats,conts, ys = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 8]), torch.Size([2, 2, 8]), torch.Size([2, 1, 8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = TimeSeriesDataLoader(tt.valid, bs=2, shuffle=True)\n",
    "cats,conts, ys = dl.one_batch()\n",
    "cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = get_test_tabular(target=\"TID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reduce_target_timeseries_to_element(cats, conts, ys, element_pos=0):\n",
    "    \"Simple transform to shorten the target timeseries.\"\n",
    "    ys = ys[:,:,element_pos].reshape(-1,1,1)\n",
    "    \n",
    "    return cats,conts,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TimeseriesTransform(to, splits=RandomSplitter(), post_hooks=[])\n",
    "tt.ys[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TimeseriesTransform(to, splits=RandomSplitter(), \n",
    "                         post_hooks=[partial(reduce_target_timeseries_to_element, element_pos=0)])\n",
    "tt.ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.]],\n",
       "\n",
       "        [[0.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.ys[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
