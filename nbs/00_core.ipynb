{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import pandas as pd\n",
    "from nbdev.showdoc import *\n",
    "from fastai.data.external import *\n",
    "from fastcore.all import *\n",
    "from pathlib import PosixPath\n",
    "from fastcore.test import *\n",
    "from fastai.tabular.all import *\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "def str_to_path(file: str):\n",
    "    \"Convers a string to a Posixpath.\"\n",
    "    if isinstance(file, str) and \"~\" in file:\n",
    "        file = os.path.expanduser(file)\n",
    "\n",
    "    file = Path(file)\n",
    "    \n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq_type(Path(\"\"), str_to_path(\"\"))\n",
    "test_eq_type(Path(\"\"), str_to_path(Path(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_hdf(file:PosixPath, key: str = \"/powerdata\", key_metadata=None):\n",
    "    \"Reads a hdf5 table based on the given key.\"\n",
    "    file = str_to_path(file)\n",
    "    if \"/\" not in key: key = \"/\" + key\n",
    "    with pd.HDFStore(file, \"r\") as store:\n",
    "        if key in store.keys():\n",
    "            df = store[key]\n",
    "            if key_metadata is not None:\n",
    "                df_meta = store[key_metadata]\n",
    "                for c in df_meta: df[c] = df_meta[c].values[0]\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
    "                  index=['a', 'b', 'c'])\n",
    "df.to_hdf('data.h5', key='df', mode='w')\n",
    "test_eq(df, read_hdf(\"data.h5\", key=\"df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_csv(file:PosixPath, sep:str =\";\"):\n",
    "    \"Reads a csv file.\"\n",
    "    file = str_to_path(file)\n",
    "    df = pd.read_csv(str(file), sep=sep)\n",
    "    df.drop([\"Unnamed: 0\"], inplace=True, axis=1, errors=\"ignore\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},)\n",
    "df.to_csv('data.csv', sep=\";\")\n",
    "test_eq(df, read_csv(\"data.csv\", sep=\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_files(\n",
    "    files:PosixPath,\n",
    "    key:str =\"/powerdata\",\n",
    "    key_metadata=None,\n",
    "    sep:str=\";\",\n",
    "    add_task_id=True\n",
    ") -> pd.DataFrame:\n",
    "    \"Reads a number of CSV or HDF5 files depending on file ending.\"\n",
    "    \n",
    "    files = listify(files)\n",
    "    dfs=L()\n",
    "    for task_id,file in enumerate(files):\n",
    "        if isinstance(file, str):\n",
    "            file = str_to_path(file)\n",
    "\n",
    "        if file.suffix == \".h5\":\n",
    "            df = read_hdf(file, key, key_metadata=key_metadata)\n",
    "        elif file.suffix == \".csv\":\n",
    "            df = read_csv(file, sep=\";\")\n",
    "        else:\n",
    "            raise f\"File ending of file {file} not supported.\"\n",
    "        if add_task_id:df[\"TaskID\"]=task_id\n",
    "        dfs += df\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
    "                  index=['a', 'b', 'c'])\n",
    "df.to_hdf('data.h5', key='df', mode='w')\n",
    "test_eq(df, read_files(\"data.h5\", key=\"df\", add_task_id=False)[0])\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},)\n",
    "df.to_csv('data.csv', sep=\";\")\n",
    "test_eq(df, read_files(\"data.csv\", add_task_id=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = \"/home/scribbler/data/DAF_ICON_Synthetic_Wind_Power_processed/00011.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AddSeasonalFeatures(TabularProc):\n",
    "    order=0\n",
    "    def encodes(self, to):\n",
    "        to.items[\"Month\"] = to.items.index.month\n",
    "        to.items[\"Day\"] = to.items.index.day\n",
    "        to.items[\"Hour\"] = to.items.index.hour\n",
    "\n",
    "class DropYear(TabularProc):\n",
    "    \"Drops a complete year.\"\n",
    "    order = 10\n",
    "    def __init__(self, year=2020):\n",
    "        year = str(year)\n",
    "        self.year = pd.to_datetime(f\"{year}-01-01\", utc=True)\n",
    "        \n",
    "    def encodes(self, to): \n",
    "        mask = to.items.index.year != self.year\n",
    "        to.items.drop(to.items[mask].index, inplace=True)\n",
    "        \n",
    "class NormalizePerTask(TabularProc):\n",
    "    \"Normalize per TaskId\"\n",
    "    order = 1\n",
    "    def __init__(self, task_id_col=\"TaskID\"):\n",
    "        self.task_id_col = task_id_col\n",
    "    def setups(self, to:Tabular):\n",
    "        print(to.items.shape)\n",
    "        self.means = getattr(to, 'train', to)[to.cont_names + \"TaskID\"].groupby(\"TaskID\").mean()\n",
    "        self.stds = getattr(to, 'train', to)[to.cont_names + \"TaskID\"].groupby(\"TaskID\").std(ddof=0)+1e-7\n",
    "\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to):\n",
    "        for task_id in to.items[self.task_id_col].unique():\n",
    "            # in case this is a new task, we update the means and stds\n",
    "            if task_id not in self.means.index:\n",
    "                print(\"new one\")\n",
    "                mu = getattr(to, 'train', to)[to.cont_names + \"TaskID\"].groupby(\"TaskID\").mean()\n",
    "                print(\"**************\")\n",
    "                print(mu)\n",
    "                print(\"**************\")\n",
    "                self.means= self.means.append(mu)\n",
    "                self.stds = self.stds.append(getattr(to, 'train', to)[to.cont_names + \"TaskID\"].groupby(\"TaskID\").std(ddof=0)+1e-7)\n",
    "                \n",
    "                print(self.means)\n",
    "                print(\"**************\")\n",
    "                \n",
    "            mask = to.loc[:,self.task_id_col] == task_id\n",
    "                   \n",
    "            to.loc[mask, to.cont_names] = ((to.conts[mask] - self.means.loc[task_id]) / self.stds.loc[task_id])\n",
    "\n",
    "        \n",
    "class DropCols(TabularProc):\n",
    "    \"Drops rows by column name.\"\n",
    "    order = 10\n",
    "    def __init__(self, cols):\n",
    "        self.cols = listify(cols)\n",
    "        \n",
    "    def encodes(self, to): \n",
    "        to.items.drop(self.cols, axis=1, inplace=True, errors=\"ignore\")\n",
    "        \n",
    "class FilterByCol(TabularProc):\n",
    "    \"Drops rows by column.\"\n",
    "    order = 0\n",
    "    def __init__(self, col_name, keep=True, drop_col_after_filter=True):\n",
    "        self.col_name = col_name\n",
    "        self.keep = keep\n",
    "        self.drop_col_after_filter=drop_col_after_filter\n",
    "        \n",
    "    def encodes(self, to): \n",
    "        mask = to.items[self.col_name].astype(bool).values\n",
    "        if not self.keep: mask = ~mask\n",
    "        to.items.drop(to.items[mask].index, inplace=True)\n",
    "        if self.drop_col_after_filter: to.items.drop(self.col_name, axis=1, inplace=True, errors=\"ignore\")\n",
    "\n",
    "class FilterMonths(TabularProc):\n",
    "    \"Filter dataframe for specific months.\"\n",
    "    order = 10\n",
    "    def __init__(self, months=range(1,13)):\n",
    "        self.months = listify(months)\n",
    "        \n",
    "    def encodes(self, to): \n",
    "        mask = ~to.items.index.month.isin(self.months)\n",
    "        to.items.drop(to.items[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TabularRenewables(TabularPandas):\n",
    "    def __init__(self, dfs, procs=None, cat_names=None, cont_names=None, do_setup=True, reduce_memory=True,\n",
    "                 y_names=None, add_y_to_x=False, add_x_to_y=False, pre_process=None, device=None, splits=None, y_block=RegressionBlock()):\n",
    "        self.pre_process = pre_process\n",
    "        if do_setup and pre_process is not None:\n",
    "            self.prepared_to = TabularPandas(dfs, y_names=y_names, procs=pre_process, cont_names=cont_names,\n",
    "                                          do_setup=True, reduce_memory=False)\n",
    "            prepared_df = self.prepared_to.items\n",
    "            if splits is not None: splits = splits(range_of(prepared_df))\n",
    "        else:\n",
    "            prepared_df = dfs\n",
    "            \n",
    "        super().__init__(prepared_df, \n",
    "            procs=procs,\n",
    "            cat_names=cat_names,\n",
    "            cont_names=cont_names,\n",
    "            y_names=y_names,\n",
    "            splits=splits,\n",
    "            do_setup=do_setup,\n",
    "            inplace=True,\n",
    "            y_block=y_block, \n",
    "            reduce_memory=reduce_memory)\n",
    "        # TODO add custom pre_process, e.g., for different test data with a different year         \n",
    "#         def new(self, df):\n",
    "#             return type(self)(df, do_setup=False, reduce_memory=False, y_block=TransformBlock(),\n",
    "#                               **attrdict(self, 'procs','cat_names','cont_names','y_names', 'device'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "# def preproces_and_merge_dfs(dfs, task_id_col, y_names, pre_process, offset=0):\n",
    "#     new_dfs = L()\n",
    "#     for task_id,df in enumerate(dfs):\n",
    "#             df = TabularPandas(df, y_names=y_names, procs=pre_process, \n",
    "#                                       do_setup=True, reduce_memory=False).items\n",
    "            \n",
    "#             df[task_id_col] = task_id+offset\n",
    "\n",
    "#             new_dfs += df\n",
    "        \n",
    "#     merged_df = pd.concat(new_dfs, axis=0)\n",
    "    \n",
    "#     return merged_df\n",
    "        \n",
    "# class TabularRenewables(CollBase, GetAttr, FilteredBase):\n",
    "#     def __init__(self, dfs, procs=None, cat_names=None, cont_names=None, \n",
    "#                  y_names=None, add_y_to_x=False, add_x_to_y=False, pre_process=None, \n",
    "#                  include_task_id=False, splits=None, device=None, do_setup=True):\n",
    "#         self.task_id_col = \"TaskID\"\n",
    "#         self.y_names = listify(y_names)\n",
    "#         self.pre_process = pre_process\n",
    "        \n",
    "#         merged_df = preproces_and_merge_dfs(dfs, self.task_id_col, self.y_names, self.pre_process, offset=0)\n",
    "        \n",
    "#         self.cont_names, self.cat_names = cont_cat_split(merged_df, dep_var=y_names, max_card=1000)\n",
    "#         if not include_task_id: self.cat_names = [c for c in self.cat_names if c!= self.task_id_col]\n",
    "        \n",
    "#         if add_y_to_x:\n",
    "#             self.cont_names += self.y_names\n",
    "#         if add_x_to_y:\n",
    "#             self.y_names += self.cont_names\n",
    "\n",
    "        \n",
    "#         if splits is not None: splits = splits(range_of(merged_df))\n",
    "#         self.split = len(df) if splits is None else len(splits[0])\n",
    "#         self.to_device(device)\n",
    "#         self.to = TabularPandas(\n",
    "#             merged_df,\n",
    "#             procs=procs,\n",
    "#             cat_names=self.cat_names,\n",
    "#             cont_names=self.cont_names,\n",
    "#             y_names=self.y_names,\n",
    "#             splits=splits,\n",
    "#             do_setup=do_setup,\n",
    "#             inplace=True,\n",
    "#             y_block=RegressionBlock(),\n",
    "#         )\n",
    "#         super().__init__(self.to.items)\n",
    "#     def new(self, df):\n",
    "#         return type(self.to)(df, do_setup=False, reduce_memory=False, y_block=TransformBlock(),\n",
    "#                           **attrdict(self, 'procs','cat_names','cont_names','y_names', 'device'))\n",
    "        \n",
    "# #     def new(self, df):\n",
    "# #         # TODO: correct to TabularRenewables\n",
    "# #         return type(self)(df, do_setup=False,**attrdict(self, 'procs','cat_names','cont_names','y_names', \\\n",
    "# #                                          'add_y_to_x', 'add_x_to_y','pre_process', 'include_task_id', 'device', ))\n",
    "# #         self.c = copy(self)\n",
    "# #         merged_dfs = preproces_and_merge_dfs(df, self.task_id_col, \n",
    "# #                                              self.y_names, self.pre_process, offset=self.items[self.task_id_col].max()+1)\n",
    "# #         to_new = self.to.new(merged_dfs, )\n",
    "# #         return to_new\n",
    "\n",
    "# #     def subset(self, i): return self.to.new(self.items[slice(0,self.to.split) if i==0 else slice(self.to.split,len(self.to))])\n",
    "#     def subset(self, i): return self.new(self.to.items[slice(0,self.split) if i==0 else slice(self.split,len(self))])\n",
    "#     def copy(self): self.items = self.to.copy(); return self\n",
    "#     def decode(self): return self.to.procs.decode(self.to)\n",
    "#     def decode_row(self, row): return self.to.new(pd.DataFrame(row).T).decode().items.iloc[0]\n",
    "#     def show(self, max_n=10, **kwargs): display_df(self.to.new(self.all_cols[:max_n]).decode().items)\n",
    "#     #   TODO: fix self.to.new to self.new\n",
    "# #     def show(self, max_n=10, **kwargs): display_df(self.to.new(self.all_cols[:max_n]).decode().items)\n",
    "#     def setup(self): self.to.procs.setup(self.to)\n",
    "#     def process(self): self.to.procs(self.to)\n",
    "#     def loc(self): return self.items.loc\n",
    "#     def iloc(self): return _TabIloc(self)\n",
    "#     def targ(self): return self.to.items[self.y_names]\n",
    "#     def x_names (self): return self.to.cat_names + self.to.cont_names\n",
    "#     def n_subsets(self): return 2\n",
    "#     def y(self): return self.to[self.to.y_names[0]]\n",
    "#     def new_empty(self): return self.new(pd.DataFrame({}, columns=self.to.items.columns))\n",
    "#     def to_device(self, d=None):\n",
    "#         self.device = d\n",
    "#         return self\n",
    "    \n",
    "#     def procs(self):\n",
    "#         return self.to.procs\n",
    "\n",
    "#     def all_col_names (self):\n",
    "#         ys = [n for n in self.to.y_names if n in self.to.items.columns]\n",
    "#         return self.to.x_names + self.to.y_names if len(ys) == len(self.to.y_names) else self.to.x_names\n",
    "    \n",
    "# properties(TabularRenewables,'loc','iloc','targ','all_col_names','n_subsets','x_names','y', \"procs\")\n",
    "\n",
    "# fastai.tabular.core._add_prop(TabularRenewables, 'cat')\n",
    "# fastai.tabular.core._add_prop(TabularRenewables, 'cont')\n",
    "# fastai.tabular.core._add_prop(TabularRenewables, 'y')\n",
    "# fastai.tabular.core._add_prop(TabularRenewables, 'x')\n",
    "# fastai.tabular.core._add_prop(TabularRenewables, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, glob\n",
    "# pd.options.mode.chained_assignment=None\n",
    "# # sys.path.append(\"../\")\n",
    "# # from fastai.tabular.all import *\n",
    "# # from fastrenewables.core import *\n",
    "\n",
    "\n",
    "# files = glob.glob(\"../data/*.h5\")\n",
    "# len(files), files[0:2]\n",
    "# n_files = 2\n",
    "# dfs = read_files(files[0:n_files], key_metadata=\"metadata\")\n",
    "# cols_to_drop = L(\n",
    "#     \"long\",\n",
    "#     \"lat\",\n",
    "#     \"loc_id\",\n",
    "#     \"target_file_name\",\n",
    "#     \"input_file_name\",\n",
    "#     \"num_train_samples\",\n",
    "#     \"num_test_samples\",\n",
    "# )\n",
    "# to = TabularRenewables(\n",
    "#     dfs,\n",
    "#     y_names=\"PowerGeneration\",\n",
    "#     pre_process=[DropCols(cols_to_drop), FilterByCol(\"TestFlag\"), AddSeasonalFeatures],\n",
    "#     procs=,\n",
    "#     add_x_to_y=False,\n",
    "#     include_task_id=False,\n",
    "#     splits=RandomSplitter(valid_pct=0.2)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preproces_and_merge_dfs(dfs, task_id_col, y_names, pre_process, offset=0):\n",
    "#     new_dfs = L()\n",
    "#     for task_id,df in enumerate(dfs):\n",
    "# #             df = TabularPandas(df, y_names=y_names, procs=pre_process, \n",
    "# #                                       do_setup=True, reduce_memory=False).items\n",
    "            \n",
    "#             df[task_id_col] = task_id+offset\n",
    "\n",
    "#             new_dfs += df\n",
    "        \n",
    "#     merged_df = pd.concat(new_dfs, axis=0)\n",
    "    \n",
    "#     return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15826, 40)\n",
      "DatetimeIndex(['2019-10-27 15:00:00+00:00', '2019-02-03 19:00:00+00:00',\n",
      "               '2019-04-03 14:00:00+00:00', '2019-02-08 02:00:00+00:00',\n",
      "               '2019-02-27 20:00:00+00:00', '2019-10-20 11:00:00+00:00',\n",
      "               '2019-07-27 00:00:00+00:00', '2019-07-19 08:00:00+00:00',\n",
      "               '2019-05-11 01:00:00+00:00', '2019-09-24 11:00:00+00:00',\n",
      "               ...\n",
      "               '2019-10-24 15:00:00+00:00', '2019-05-04 02:00:00+00:00',\n",
      "               '2019-03-05 10:00:00+00:00', '2019-11-27 22:00:00+00:00',\n",
      "               '2019-02-28 17:00:00+00:00', '2019-05-05 17:00:00+00:00',\n",
      "               '2019-02-28 09:00:00+00:00', '2019-07-09 21:00:00+00:00',\n",
      "               '2019-05-05 14:00:00+00:00', '2019-07-27 06:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='TimeUTC', length=15826, freq=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>rotor_diameter_m</th>\n",
       "      <th>hub_height_m</th>\n",
       "      <th>T_HAG_2_M</th>\n",
       "      <th>RELHUM_HAG_2_M</th>\n",
       "      <th>PS_SFC_0_M</th>\n",
       "      <th>ASWDIFDS_SFC_0_M</th>\n",
       "      <th>ASWDIRS_SFC_0_M</th>\n",
       "      <th>WindSpeed58m</th>\n",
       "      <th>SinWindDirection58m</th>\n",
       "      <th>CosWindDirection58m</th>\n",
       "      <th>WindSpeed60m</th>\n",
       "      <th>SinWindDirection60m</th>\n",
       "      <th>CosWindDirection60m</th>\n",
       "      <th>WindSpeed58mMinus_t_1</th>\n",
       "      <th>SinWindDirection58mMinus_t_1</th>\n",
       "      <th>CosWindDirection58mMinus_t_1</th>\n",
       "      <th>WindSpeed60mMinus_t_1</th>\n",
       "      <th>SinWindDirection60mMinus_t_1</th>\n",
       "      <th>CosWindDirection60mMinus_t_1</th>\n",
       "      <th>WindSpeed58mPlus_t_1</th>\n",
       "      <th>SinWindDirection58mPlus_t_1</th>\n",
       "      <th>CosWindDirection58mPlus_t_1</th>\n",
       "      <th>WindSpeed60mPlus_t_1</th>\n",
       "      <th>SinWindDirection60mPlus_t_1</th>\n",
       "      <th>CosWindDirection60mPlus_t_1</th>\n",
       "      <th>PowerGeneration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>115.7</td>\n",
       "      <td>92</td>\n",
       "      <td>0.468416</td>\n",
       "      <td>-1.194797</td>\n",
       "      <td>-0.502458</td>\n",
       "      <td>0.502105</td>\n",
       "      <td>0.797864</td>\n",
       "      <td>-0.231152</td>\n",
       "      <td>-0.779812</td>\n",
       "      <td>1.156806</td>\n",
       "      <td>0.227371</td>\n",
       "      <td>-0.671907</td>\n",
       "      <td>1.175520</td>\n",
       "      <td>-0.194975</td>\n",
       "      <td>-0.870952</td>\n",
       "      <td>1.108169</td>\n",
       "      <td>0.314154</td>\n",
       "      <td>-0.759932</td>\n",
       "      <td>1.125164</td>\n",
       "      <td>-0.402073</td>\n",
       "      <td>-0.959248</td>\n",
       "      <td>1.044332</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.840573</td>\n",
       "      <td>1.062503</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.704064</td>\n",
       "      <td>0.659828</td>\n",
       "      <td>0.711843</td>\n",
       "      <td>-1.635641</td>\n",
       "      <td>-1.118504</td>\n",
       "      <td>-0.755940</td>\n",
       "      <td>-0.819562</td>\n",
       "      <td>1.046224</td>\n",
       "      <td>-1.068783</td>\n",
       "      <td>0.193894</td>\n",
       "      <td>1.128889</td>\n",
       "      <td>-0.891920</td>\n",
       "      <td>-0.871803</td>\n",
       "      <td>1.025146</td>\n",
       "      <td>-1.118487</td>\n",
       "      <td>0.454499</td>\n",
       "      <td>1.011089</td>\n",
       "      <td>-0.531675</td>\n",
       "      <td>-1.075785</td>\n",
       "      <td>0.918494</td>\n",
       "      <td>-0.939393</td>\n",
       "      <td>-0.584809</td>\n",
       "      <td>1.207543</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>1.008298</td>\n",
       "      <td>-0.477016</td>\n",
       "      <td>-1.083498</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>-0.158465</td>\n",
       "      <td>-0.606647</td>\n",
       "      <td>-1.616294</td>\n",
       "      <td>-0.895593</td>\n",
       "      <td>-0.524751</td>\n",
       "      <td>-1.591566</td>\n",
       "      <td>-0.235503</td>\n",
       "      <td>-0.638582</td>\n",
       "      <td>-1.609063</td>\n",
       "      <td>-0.808917</td>\n",
       "      <td>-0.759177</td>\n",
       "      <td>-1.548602</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>-0.702879</td>\n",
       "      <td>-1.587947</td>\n",
       "      <td>-0.696360</td>\n",
       "      <td>-0.907832</td>\n",
       "      <td>-1.501788</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>-1.054820</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>-0.343809</td>\n",
       "      <td>0.936470</td>\n",
       "      <td>-0.508757</td>\n",
       "      <td>-0.210341</td>\n",
       "      <td>-1.659963</td>\n",
       "      <td>-0.056437</td>\n",
       "      <td>-0.341358</td>\n",
       "      <td>-1.600702</td>\n",
       "      <td>-0.235833</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>-1.631911</td>\n",
       "      <td>0.267286</td>\n",
       "      <td>-0.077069</td>\n",
       "      <td>-1.577210</td>\n",
       "      <td>-0.947675</td>\n",
       "      <td>-0.348903</td>\n",
       "      <td>-1.653730</td>\n",
       "      <td>-0.875131</td>\n",
       "      <td>-0.571864</td>\n",
       "      <td>-1.584077</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.698318</td>\n",
       "      <td>0.126111</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>-1.247913</td>\n",
       "      <td>-1.015346</td>\n",
       "      <td>2.743097</td>\n",
       "      <td>0.974236</td>\n",
       "      <td>0.591287</td>\n",
       "      <td>2.841020</td>\n",
       "      <td>0.879641</td>\n",
       "      <td>0.649184</td>\n",
       "      <td>2.578131</td>\n",
       "      <td>0.973026</td>\n",
       "      <td>0.591782</td>\n",
       "      <td>2.686041</td>\n",
       "      <td>0.868003</td>\n",
       "      <td>0.664287</td>\n",
       "      <td>2.272893</td>\n",
       "      <td>1.063665</td>\n",
       "      <td>0.466680</td>\n",
       "      <td>2.296342</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>115.7</td>\n",
       "      <td>92</td>\n",
       "      <td>-1.216702</td>\n",
       "      <td>1.246966</td>\n",
       "      <td>0.389476</td>\n",
       "      <td>-1.205278</td>\n",
       "      <td>-0.406978</td>\n",
       "      <td>-0.984563</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.716313</td>\n",
       "      <td>-1.034110</td>\n",
       "      <td>1.068016</td>\n",
       "      <td>-1.004337</td>\n",
       "      <td>-0.941445</td>\n",
       "      <td>1.261816</td>\n",
       "      <td>-0.180552</td>\n",
       "      <td>-0.792406</td>\n",
       "      <td>-0.451879</td>\n",
       "      <td>-1.491956</td>\n",
       "      <td>-1.114320</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.782557</td>\n",
       "      <td>-0.850432</td>\n",
       "      <td>-1.335290</td>\n",
       "      <td>-0.575878</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>1.298436</td>\n",
       "      <td>-1.770229</td>\n",
       "      <td>0.350207</td>\n",
       "      <td>0.426632</td>\n",
       "      <td>1.640235</td>\n",
       "      <td>-0.689306</td>\n",
       "      <td>-0.427340</td>\n",
       "      <td>1.145344</td>\n",
       "      <td>-0.220591</td>\n",
       "      <td>-0.568248</td>\n",
       "      <td>1.206932</td>\n",
       "      <td>-0.624902</td>\n",
       "      <td>-0.446515</td>\n",
       "      <td>1.143421</td>\n",
       "      <td>-0.141817</td>\n",
       "      <td>-0.580628</td>\n",
       "      <td>1.206177</td>\n",
       "      <td>-0.815181</td>\n",
       "      <td>-0.442173</td>\n",
       "      <td>1.145114</td>\n",
       "      <td>-0.385980</td>\n",
       "      <td>-0.560779</td>\n",
       "      <td>1.210804</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>0.582884</td>\n",
       "      <td>-0.746091</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>1.054999</td>\n",
       "      <td>1.355690</td>\n",
       "      <td>-0.996700</td>\n",
       "      <td>1.248183</td>\n",
       "      <td>-0.510412</td>\n",
       "      <td>-0.761042</td>\n",
       "      <td>0.719979</td>\n",
       "      <td>-1.197783</td>\n",
       "      <td>-0.662964</td>\n",
       "      <td>1.087523</td>\n",
       "      <td>-0.928524</td>\n",
       "      <td>-0.626952</td>\n",
       "      <td>0.878093</td>\n",
       "      <td>-1.029554</td>\n",
       "      <td>-0.644197</td>\n",
       "      <td>1.141105</td>\n",
       "      <td>0.326916</td>\n",
       "      <td>-0.830321</td>\n",
       "      <td>1.149683</td>\n",
       "      <td>0.083748</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>-1.123340</td>\n",
       "      <td>1.017866</td>\n",
       "      <td>1.225238</td>\n",
       "      <td>-0.627595</td>\n",
       "      <td>-0.813618</td>\n",
       "      <td>-0.102076</td>\n",
       "      <td>-0.563579</td>\n",
       "      <td>-1.625949</td>\n",
       "      <td>-0.790489</td>\n",
       "      <td>-0.877896</td>\n",
       "      <td>-1.514320</td>\n",
       "      <td>-0.130413</td>\n",
       "      <td>-0.567948</td>\n",
       "      <td>-1.625750</td>\n",
       "      <td>-0.791916</td>\n",
       "      <td>-0.965537</td>\n",
       "      <td>-1.480791</td>\n",
       "      <td>-0.137887</td>\n",
       "      <td>-0.562799</td>\n",
       "      <td>-1.623908</td>\n",
       "      <td>-0.839386</td>\n",
       "      <td>-0.811226</td>\n",
       "      <td>-1.533313</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>114</td>\n",
       "      <td>0.222105</td>\n",
       "      <td>-1.187809</td>\n",
       "      <td>1.861269</td>\n",
       "      <td>0.067636</td>\n",
       "      <td>0.362551</td>\n",
       "      <td>-1.569966</td>\n",
       "      <td>-1.099708</td>\n",
       "      <td>-1.404350</td>\n",
       "      <td>-1.468060</td>\n",
       "      <td>-1.809480</td>\n",
       "      <td>-0.615440</td>\n",
       "      <td>-1.491150</td>\n",
       "      <td>-1.539891</td>\n",
       "      <td>-0.955255</td>\n",
       "      <td>-1.348715</td>\n",
       "      <td>-1.826128</td>\n",
       "      <td>-0.560117</td>\n",
       "      <td>-1.512342</td>\n",
       "      <td>0.721765</td>\n",
       "      <td>-1.338484</td>\n",
       "      <td>-1.429774</td>\n",
       "      <td>0.239576</td>\n",
       "      <td>-1.489553</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Month', 'Day', 'Hour', 'rotor_diameter_m', 'hub_height_m']\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(13, 7)\n",
      "    (1): Embedding(32, 11)\n",
      "    (2): Embedding(25, 10)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(3, 3)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): BatchNorm1d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Linear(in_features=57, out_features=200, bias=False)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>0.145778</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.019747</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.118136</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>0.116842</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.110436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.108736</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.103981</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.102541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.101264</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.100906</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# files = glob.glob(\"../data/*.h5\")\n",
    "# n_files = 2\n",
    "\n",
    "\n",
    "# cont_names = ['T_HAG_2_M', 'RELHUM_HAG_2_M', 'PS_SFC_0_M', 'ASWDIFDS_SFC_0_M',\n",
    "#        'ASWDIRS_SFC_0_M', 'WindSpeed58m',\n",
    "#        'SinWindDirection58m', 'CosWindDirection58m', 'WindSpeed60m',\n",
    "#        'SinWindDirection60m', 'CosWindDirection60m', 'WindSpeed58mMinus_t_1',\n",
    "#        'SinWindDirection58mMinus_t_1', 'CosWindDirection58mMinus_t_1',\n",
    "#        'WindSpeed60mMinus_t_1', 'SinWindDirection60mMinus_t_1',\n",
    "#        'CosWindDirection60mMinus_t_1', 'WindSpeed58mPlus_t_1',\n",
    "#        'SinWindDirection58mPlus_t_1', 'CosWindDirection58mPlus_t_1',\n",
    "#        'WindSpeed60mPlus_t_1', 'SinWindDirection60mPlus_t_1',\n",
    "#        'CosWindDirection60mPlus_t_1', ]\n",
    "\n",
    "# cat_names = [\"Month\", \"Day\", \"Hour\", \"rotor_diameter_m\", \"hub_height_m\"]\n",
    "# y_names = 'PowerGeneration'\n",
    "# pd.options.mode.chained_assignment=None\n",
    "# pre_process=[AddSeasonalFeatures, \n",
    "#              FilterByCol(\"TestFlag\", drop_col_after_filter=False), \n",
    "# #              DropYear(year=2020),\n",
    "# #              FilterMonths([1,2,3,4]), \n",
    "#              NormalizePerTask]\n",
    "\n",
    "# procs = [NormalizePerTask, Categorify]\n",
    "# procs = [Categorify]\n",
    "\n",
    "# dfs = read_files(files[0:n_files], key_metadata=\"metadata\")\n",
    "\n",
    "# to = TabularRenewables(pd.concat(dfs, axis=0), \n",
    "#                   cont_names = cont_names, \n",
    "#                   cat_names=cat_names, \n",
    "#                   y_names=y_names, \n",
    "#                   pre_process=pre_process, \n",
    "#                     procs=procs,\n",
    "#                 splits=RandomSplitter(valid_pct=0.2))\n",
    "# print(to.items.index)\n",
    "# dls = to.dataloaders(bs=256)\n",
    "# dls.show_batch()\n",
    "# learner = tabular_learner(dls, metrics=rmse)\n",
    "# print(learner.dls.train_ds.cat_names)\n",
    "# print(learner.model)\n",
    "# learner.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
