{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gan.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gan.model\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fastrenewables.utils import flatten_ts\n",
    "from fastrenewables.synthetic_data import GaussianDataset, plot_class_hists, DummyDataset\n",
    "from fastrenewables.timeseries.model import TemporalCNN\n",
    "from fastrenewables.tabular.model import EmbeddingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def LinBnAct(si, so, use_bn, act_cls):\n",
    "    layers = [nn.Linear(si, so)]\n",
    "    if use_bn:\n",
    "        layers += [nn.BatchNorm1d(so)]\n",
    "    if act_cls is not None:\n",
    "        layers += [act_cls]\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GANMLP(torch.nn.Module):\n",
    "    def __init__(self, ann_structure, bn_cont=False, act_fct=torch.nn.ReLU, final_act_fct=nn.Sigmoid, embedding_module=None, transpose=False):\n",
    "        super(GANMLP, self).__init__()\n",
    "        \n",
    "        n_cont = ann_structure[0]\n",
    "        if embedding_module is not None:\n",
    "            emb_sz = []\n",
    "            ann_structure[0] = ann_structure[0] + embedding_module.no_of_embeddings\n",
    "\n",
    "        self.embedding_module = embedding_module\n",
    "        \n",
    "        layers = []\n",
    "        for idx in range(1, len(ann_structure)):\n",
    "            cur_use_bn = bn_cont\n",
    "            cur_act_fct = act_fct()\n",
    "            if idx == 1 and not bn_cont:\n",
    "                cur_use_bn = False\n",
    "            if idx == len(ann_structure)-1:\n",
    "                cur_act_fct = None\n",
    "                cur_use_bn = False\n",
    "                \n",
    "            layer = LinBnAct(ann_structure[idx-1], ann_structure[idx], cur_use_bn, cur_act_fct)\n",
    "            layers.append(layer)\n",
    "        if final_act_fct is not None:\n",
    "            layers.append(final_act_fct())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.embedding_module is not None:\n",
    "            x_cat = self.embedding_module(x_cat)\n",
    "            x_cont = torch.cat([x_cat, x_cont], 1)\n",
    "        \n",
    "        return self.model(x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide\n",
    "\n",
    "# n_samples = 1024\n",
    "# n_classes = 2\n",
    "# n_features = 1\n",
    "# batch_size = 512\n",
    "# n_z = 10\n",
    "# n_in = n_features\n",
    "# n_hidden = 64\n",
    "# epochs = 2\n",
    "\n",
    "# data = GaussianDataset(n_samples, n_classes)\n",
    "# dl = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "# emb_module = EmbeddingModule(categorical_dimensions=[n_classes+1])\n",
    "\n",
    "# model = get_gan_model(structure=[n_z, n_hidden, n_hidden, n_in], n_classes=n_classes, emb_module=emb_module, bn=True, gan_type='bce')\n",
    "# #print(model)    \n",
    "# for e in tqdm(range(epochs)):\n",
    "#     for x_cat, x_cont, y in dl:\n",
    "#         x_cat = x_cat.to(model.device).long()\n",
    "#         x_cont = x_cont.to(model.device)\n",
    "#         y = y.to(model.device)\n",
    "#         model.train_discriminator(x_cat, x_cont, y)\n",
    "#         model.train_generator(x_cat, x_cont, y)\n",
    "\n",
    "# plt.figure(figsize=(16, 9))\n",
    "# plt.plot(model.real_loss, label='Real Loss')\n",
    "# plt.plot(model.fake_loss, label='Fake Loss')\n",
    "# plt.plot(model.aux_loss, label='Aux Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# model.eval()\n",
    "# z = model.noise(x_cont)\n",
    "# x_fake = model.generator(x_cat, z)\n",
    "\n",
    "# print('distribution of real data:')\n",
    "# plot_class_hists(x_cat.cpu(), x_cont.cpu())\n",
    "\n",
    "# print('distribution of generated data:')\n",
    "# plot_class_hists(x_cat.cpu(), x_fake.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# from fastai.data.core import DataLoader,DataLoaders\n",
    "\n",
    "\n",
    "# opt = torch.optim.Adam(params=model.parameters())\n",
    "# loss = torch.nn.MSELoss()\n",
    "\n",
    "# n_cats, n_z, n_targets = 1,2, 2\n",
    "# data = DummyDataset(n_samples=100, n_cat_feats=n_cats, n_cont_feats=n_z, n_targets=n_targets, n_dim=3)\n",
    "\n",
    "\n",
    "# dl_train = DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "# dl_valid = DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.data.core import *\n",
    "\n",
    "# cats, conts, ys = DataLoaders(dl_train, dl_valid).one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats.shape, conts.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_hidden = 5\n",
    "# gen_structure = [n_z, n_hidden, n_hidden, n_targets]\n",
    "# dis_structure = [n_targets, n_hidden, n_hidden, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_module = EmbeddingModule(categorical_dimensions=None, embedding_dimensions=[(2,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generator = TemporalCNN(cnn_structure=gen_structure, batch_norm_cont=False, \n",
    "#                                    cnn_type='tcn', \n",
    "#                                    final_activation=nn.Sigmoid,\n",
    "#                                    embedding_module=emb_module, \n",
    "#                                    add_embedding_at_layer=[idx for idx in range(len(gen_structure)-2)],\n",
    "#                        )\n",
    "# generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# discriminator = TemporalCNN(cnn_structure=dis_structure, batch_norm_cont=False, \n",
    "#                                    cnn_type='tcn', \n",
    "#                                    final_activation=nn.Sigmoid,\n",
    "#                                    embedding_module=emb_module, \n",
    "#                                    add_embedding_at_layer=[idx for idx in range(len(dis_structure)-2)],\n",
    "#                        )\n",
    "# discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_fct = torch.optim.Adam\n",
    "# gan_class = GAN\n",
    "# auxiliary = False\n",
    "# aux_factor=0.1\n",
    "# label_noise=0\n",
    "# label_bias=0\n",
    "\n",
    "# gen_opt = opt_fct(params=generator.parameters())\n",
    "# dis_opt = opt_fct(params=discriminator.parameters())\n",
    "\n",
    "# model = gan_class(generator=generator, discriminator=discriminator, \\\n",
    "#                   gen_optim=gen_opt, dis_optim=dis_opt, n_z=n_z, auxiliary=auxiliary,\\\n",
    "#                   auxiliary_weighting_factor=aux_factor, label_noise=label_noise, label_bias=label_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cat.shape, x_cont.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cont.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# for e in tqdm(range(epochs)):\n",
    "#     for x_cat, x_cont, y in dl_train:\n",
    "#         x_cat = x_cat.to(model.device).long()\n",
    "#         x_cont = x_cont.to(model.device)\n",
    "#         y = y.to(model.device)\n",
    "        \n",
    "#         model.train_generator(x_cat, x_cont, y)\n",
    "#         model.train_discriminator(x_cat, y, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastrenewables.gan.learner import GANLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_gen, n_dis = 1,1\n",
    "# epochs = 5\n",
    "# lr = 1e-4\n",
    "# plot_epochs = 2\n",
    "# learner = GANLearner(gan=model, n_gen=n_gen, n_dis=n_dis)\n",
    "# learner.fit(dl_train, epochs=epochs, lr=lr, plot_epochs=plot_epochs, save_model=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#generator = GANMLP([n_z, n_hidden, n_in], embedding_module=emb, bn_cont=True)\n",
    "#discriminator = GANMLP([n_in, n_hidden, 1], bn_cont=True)\n",
    "#gen_opt = torch.optim.Adam(generator.parameters())\n",
    "#dis_opt = torch.optim.Adam(discriminator.parameters())\n",
    "#model = GAN(generator, discriminator, gen_opt, dis_opt, n_z=n_z)\n",
    "#print(model)\n",
    "#\n",
    "#for e in tqdm(range(epochs)):\n",
    "#    for x_cat, x_cont, y in dl:\n",
    "#        x_cat = x_cat.to(model.device).long()\n",
    "#        x_cont = x_cont.to(model.device)\n",
    "#        y = y.to(model.device)\n",
    "#\n",
    "#        model.train_discriminator(x_cat, x_cont, y)\n",
    "#        model.train_generator(x_cat, x_cont, y)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(model.real_loss, label='Real Loss')\n",
    "#plt.plot(model.fake_loss, label='Fake Loss')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#\n",
    "#assert(np.abs(model.real_loss[-1] - model.fake_loss[-1]) < 0.5)\n",
    "#\n",
    "#z = model.noise(x_cont)\n",
    "#x_fake = model.generator(x_cat, z)\n",
    "#assert((x_fake - x_cont).mean().abs().item() < 0.5)\n",
    "#\n",
    "#print('distribution of real data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_cont.cpu())\n",
    "#\n",
    "#print('distribution of generated data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_fake.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#generator = GANMLP([n_z, n_hidden,  n_in], embedding_module=emb, bn_cont=True)\n",
    "#discriminator = GANMLP([n_in, n_hidden, 1], final_act_fct=nn.Identity, bn_cont=True)\n",
    "#gen_opt = torch.optim.RMSprop(generator.parameters())\n",
    "#dis_opt = torch.optim.RMSprop(discriminator.parameters())\n",
    "#model = WGAN(generator, discriminator, gen_opt, dis_opt, n_z=n_z)\n",
    "#print(model)\n",
    "#\n",
    "#for e in tqdm(range(epochs)):\n",
    "#    for x_cat, x_cont, y in dl:\n",
    "#        x_cat = x_cat.to(model.device).long()\n",
    "#        x_cont = x_cont.to(model.device)\n",
    "#        y = y.to(model.device)\n",
    "#\n",
    "#        model.train_discriminator(x_cat, x_cont, y)\n",
    "#        model.train_generator(x_cat, x_cont, y)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(model.real_loss, label='Real Loss')\n",
    "#plt.plot(model.fake_loss, label='Fake Loss')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#\n",
    "#z = model.noise(x_cont)\n",
    "#x_fake = model.generator(x_cat, z)\n",
    "#\n",
    "#print('distribution of real data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_cont.cpu())\n",
    "#\n",
    "#print('distribution of generated data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_fake.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#generator = GANMLP([n_z, n_hidden, n_hidden, n_in], embedding_module=emb, bn_cont=True)\n",
    "#discriminator = GANMLP([n_in, n_hidden, n_hidden], final_act_fct=nn.ReLU, bn_cont=True)\n",
    "#discriminator = AuxiliaryDiscriminator(basic_discriminator=discriminator, n_classes=n_classes, final_input_size=n_hidden, len_ts=1)\n",
    "#gen_opt = torch.optim.Adam(generator.parameters())\n",
    "#dis_opt = torch.optim.Adam(discriminator.parameters())\n",
    "#model = GAN(generator, discriminator, gen_opt, dis_opt, n_z=n_z, auxiliary=True, auxiliary_weighting_factor=1)\n",
    "#print(model)\n",
    "#\n",
    "#for e in tqdm(range(epochs)):\n",
    "#    for x_cat, x_cont, y in dl:\n",
    "#        x_cat = x_cat.to(model.device).long()\n",
    "#        x_cont = x_cont.to(model.device)\n",
    "#        y = y.to(model.device)\n",
    "#\n",
    "#        model.train_discriminator(x_cat, x_cont, y)\n",
    "#        model.train_generator(x_cat, x_cont, y)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.plot(model.real_loss, label='Real Loss')\n",
    "#plt.plot(model.fake_loss, label='Fake Loss')\n",
    "#plt.plot([a.item() for a in model.aux_loss], label='Aux Loss')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#\n",
    "#z = model.noise(x_cont)\n",
    "#x_fake = model.generator(x_cat, z)\n",
    "#\n",
    "#print('distribution of real data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_cont.cpu())\n",
    "#\n",
    "#print('distribution of generated data:')\n",
    "#plot_class_hists(x_cat.cpu(), x_fake.cpu().detach())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
