{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gan.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gan.model\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import BCELoss, CrossEntropyLoss\n",
    "\n",
    "from fastrenewables.synthetic_data import DummyDataset\n",
    "from fastrenewables.timeseries.model import TemporalCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def flatten_ts(x):\n",
    "    \"\"\"assumes matrix of shape (n_samples, n_features, ts_length)\"\"\"\n",
    "    if len(x.shape) in [1,2]:\n",
    "        return x\n",
    "\n",
    "    n_samples, n_features, ts_length = x.shape\n",
    "\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = x.swapaxes(1,2)\n",
    "    else:\n",
    "        x = x.permute(0,2,1)\n",
    "    x = x.reshape(n_samples*ts_length, n_features)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def LinBnAct(si, so, use_bn, act_cls):\n",
    "    layers = [nn.Linear(si, so)]\n",
    "    if use_bn:\n",
    "        layers += [nn.BatchNorm1d(so)]\n",
    "    if act_cls is not None:\n",
    "        layers += [act_cls]\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GANMLP(torch.nn.Module):\n",
    "    def __init__(self, ann_structure, bn_cont=False, act_fct=torch.nn.ReLU, final_act_fct=nn.Sigmoid, embedding_module=None, transpose=False):\n",
    "        # transpose doesn't change anything here but is needed for consistency\n",
    "        super(GANMLP, self).__init__()\n",
    "        \n",
    "        n_cont = ann_structure[0]\n",
    "        if embedding_module is not None:\n",
    "            emb_sz = []\n",
    "            ann_structure[0] = ann_structure[0] + embedding_module.no_of_embeddings\n",
    "\n",
    "        self.embedding_module = embedding_module\n",
    "        \n",
    "        layers = []\n",
    "        for idx in range(1, len(ann_structure)):\n",
    "            cur_use_bn = bn_cont\n",
    "            cur_act_fct = act_fct()\n",
    "            if idx == 1 and not bn_cont:\n",
    "                cur_use_bn = False\n",
    "            if idx == len(ann_structure)-1:\n",
    "                cur_act_fct = None\n",
    "                cur_use_bn = False\n",
    "                \n",
    "            layer = LinBnAct(ann_structure[idx-1], ann_structure[idx], cur_use_bn , cur_act_fct)\n",
    "            layers.append(layer)\n",
    "        if final_act_fct is not None:\n",
    "            layers.append(final_act_fct())\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.embedding_module is not None:\n",
    "            cat = self.embedding_module(x_cat)\n",
    "            x_cont = torch.cat([x_cat, x_cont], 1)\n",
    "        \n",
    "        return self.model(x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GANMLP(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=1, bias=True)\n",
      "    )\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "model = GANMLP(ann_structure=[4, 8, 1])\n",
    "print(model)\n",
    "opt = torch.optim.Adam(params=model.parameters())\n",
    "loss = torch.nn.MSELoss()\n",
    "data = DummyDataset(n_samples=100, n_cat_feats=0, n_cont_feats=4, n_targets=1, n_dim=2)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    for x_cat, x_cont, y in dl:\n",
    "        opt.zero_grad()\n",
    "        pred = model(x_cat, x_cont)\n",
    "        error = loss(pred, y)\n",
    "        error.backward()\n",
    "        opt.step()\n",
    "    errors.append(error.item())\n",
    "    \n",
    "assert(errors[0] > errors[-1]) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GANCNN(torch.nn.Module):\n",
    "    def __init__(self, ann_structure, bn_cont=False, act_fct=nn.ReLU, final_act_fct=nn.Sigmoid, embedding_module=None, transpose=False):\n",
    "        super(GANCNN, self).__init__()\n",
    "        \n",
    "        self.model = TemporalCNN(cnn_structure=ann_structure, batch_norm_cont=bn_cont, cnn_type='cnn', act_func=act_fct, final_activation=final_act_fct, transpose=transpose)\n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        return self.model(x_cat, x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GANCNN(\n",
      "  (model): TemporalCNN(\n",
      "    (layers): TemporalConvNet(\n",
      "      (temporal_blocks): Sequential(\n",
      "        (0): BasicTemporalBlock(\n",
      "          (conv): ConvLayer(\n",
      "            (0): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicTemporalBlock(\n",
      "          (conv): ConvLayer(\n",
      "            (0): Conv1d(8, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            (1): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "model = GANCNN(ann_structure=[4, 8, 1])\n",
    "print(model)\n",
    "opt = torch.optim.Adam(params=model.parameters())\n",
    "loss = torch.nn.MSELoss()\n",
    "data = DummyDataset(n_samples=100, n_cat_feats=0, n_cont_feats=4, n_targets=1, n_dim=3)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    for x_cat, x_cont, y in dl:\n",
    "        opt.zero_grad()\n",
    "        pred = model(x_cat, x_cont)\n",
    "        error = loss(pred, y)\n",
    "        error.backward()\n",
    "        opt.step()\n",
    "    errors.append(error.item())\n",
    "    \n",
    "assert(errors[0] > errors[-1]) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "    \n",
    "class GAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, generator, discriminator, gen_optim, dis_optim, n_z=100, auxiliary=False, auxiliary_weighting_factor=1):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_optim = gen_optim\n",
    "        self.dis_optim = dis_optim\n",
    "        self.n_z = n_z\n",
    "        self.real_loss = []\n",
    "        self.fake_loss = []\n",
    "        self.auxiliary = auxiliary\n",
    "        self.bce_loss = BCELoss()\n",
    "        self.auxiliary_loss_function = CrossEntropyLoss()\n",
    "        self.auxiliary_weighting_factor=auxiliary_weighting_factor\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.to_device(self.device)\n",
    "        \n",
    "    def noise(self, x):\n",
    "        if x.dim() == 2:\n",
    "            z = torch.randn(x.shape[0], self.n_z).to(self.device)\n",
    "        elif x.dim() == 3:\n",
    "            z = torch.randn(x.shape[0], self.n_z, x.shape[2]).to(self.device)\n",
    "        return z\n",
    "    \n",
    "    def to_device(self, device):\n",
    "        self.device = device\n",
    "        self.generator = self.generator.to(device)\n",
    "        self.discriminator = self.discriminator.to(device)\n",
    "        self.bce_loss = self.bce_loss.to(device)\n",
    "        self.auxiliary_loss_function = self.auxiliary_loss_function.to(device)\n",
    "        \n",
    "    def _split_pred(self, y):\n",
    "        if self.auxiliary:\n",
    "            y, class_probs = y\n",
    "        else:\n",
    "            y, class_probs = y, None\n",
    "        return y, class_probs\n",
    "    \n",
    "    def auxiliary_loss(self, class_probs, y):\n",
    "        return self.auxiliary_loss_function(class_probs, y.ravel().to(torch.int64))*self.auxiliary_weighting_factor\n",
    "    \n",
    "    def train_generator(self, x_cat, x_cont, y):\n",
    "        z = self.noise(x_cont)\n",
    "        self.generator.zero_grad()\n",
    "        x_cont_fake = self.generator(x_cat, z)\n",
    "        y_fake = self.discriminator(None, x_cont_fake)  \n",
    "        y_fake, class_probs = self._split_pred(y_fake)\n",
    "        loss = self.bce_loss(y_fake, torch.ones_like(y_fake))\n",
    "        if self.auxiliary:\n",
    "            aux_loss = self.auxiliary_loss(class_probs, y)\n",
    "            loss = (loss + aux_loss)/2\n",
    "        loss.backward()\n",
    "        self.gen_optim.step()\n",
    "        return\n",
    "    \n",
    "    def train_discriminator(self, x_cat, x_cont, y):\n",
    "        z = self.noise(x_cont)\n",
    "        self.discriminator.zero_grad()\n",
    "        y_real = self.discriminator(None, x_cont)\n",
    "        y_real, class_probs = self._split_pred(y_real)\n",
    "        real_loss = self.bce_loss(y_real, torch.ones_like(y_real))\n",
    "        if self.auxiliary:\n",
    "            aux_loss = self.auxiliary_loss(class_probs, y)\n",
    "            real_loss = (real_loss + aux_loss)/2\n",
    "        \n",
    "        real_loss.backward()\n",
    "        self.dis_optim.step()\n",
    "        self.real_loss.append(real_loss.item())\n",
    "        \n",
    "        z = self.noise(x_cont)\n",
    "        self.discriminator.zero_grad()\n",
    "        x_cont_fake = self.generator(x_cat, z).detach()\n",
    "        y_fake = self.discriminator(None, x_cont_fake)\n",
    "        y_fake, class_probs = self._split_pred(y_fake)\n",
    "        \n",
    "        fake_loss =  self.bce_loss(y_fake, torch.zeros_like(y_fake))\n",
    "        if self.auxiliary:\n",
    "            aux_loss = self.auxiliary_loss(class_probs, y)\n",
    "            fake_loss = (fake_loss + aux_loss)/2\n",
    "            \n",
    "        fake_loss.backward()\n",
    "        self.dis_optim.step()\n",
    "        self.fake_loss.append(fake_loss.item())\n",
    "        return\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        z = self.noise(x_cont)\n",
    "        x_gen = self.generator(x_cat, z)\n",
    "        assert(x_gen.shape == x_cont.shape)\n",
    "        self.discriminator(None, x_gen)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN(\n",
      "  (generator): GANMLP(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (discriminator): GANMLP(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=50, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=1, bias=True)\n",
      "      )\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (bce_loss): BCELoss()\n",
      "  (auxiliary_loss_function): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = GANMLP([100, 50, 4])\n",
    "discriminator = GANMLP([4, 50, 1])\n",
    "gen_optim = torch.optim.Adam(generator.parameters())\n",
    "dis_optim = torch.optim.Adam(discriminator.parameters())\n",
    "model = GAN(generator, discriminator, gen_optim, dis_optim)\n",
    "print(model)\n",
    "\n",
    "data = DummyDataset(n_samples=100, n_cat_feats=0, n_cont_feats=4, n_targets=1, n_dim=2)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "    \n",
    "for x_cat, x_cont, y in dl:\n",
    "    model(x_cat, x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class WGAN(GAN):\n",
    "    def __init__(self, generator, discriminator, gen_optim, dis_optim, n_z=100, clip=0.001, auxiliary=False):\n",
    "        super(WGAN, self).__init__(generator, discriminator, gen_optim, dis_optim, n_z, clip, auxiliary)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_optim = gen_optim\n",
    "        self.dis_optim = dis_optim\n",
    "        self.n_z = n_z\n",
    "        self.clip = clip\n",
    "        self.auxiliary = auxiliary\n",
    "        self.real_loss = []\n",
    "        self.fake_loss = []\n",
    "        \n",
    "    def train_generator(self, x_cat, x_cont, y):\n",
    "        z = self.noise(x_cont)\n",
    "        self.generator.zero_grad()\n",
    "        x_cont_fake = self.generator(x_cat, z)\n",
    "        y_fake = self.discriminator(None, x_cont_fake)\n",
    "        loss = - y_fake.mean()\n",
    "        loss.backward()\n",
    "        self.gen_optim.step()\n",
    "        return\n",
    "    \n",
    "    def train_discriminator(self, x_cat, x_cont, y):\n",
    "        z = self.noise(x_cont)\n",
    "        self.discriminator.zero_grad()\n",
    "        y_real = self.discriminator(None, x_cont)\n",
    "        real_loss = - y_real.mean()\n",
    "        real_loss.backward()\n",
    "        self.dis_optim.step()\n",
    "        self.real_loss.append(real_loss.item())\n",
    "        \n",
    "        z = self.noise(x_cont)\n",
    "        self.discriminator.zero_grad()\n",
    "        x_cont_fake = self.generator(x_cat, z).detach()\n",
    "        y_fake = self.discriminator(None, x_cont_fake)\n",
    "        fake_loss = y_fake.mean()\n",
    "        fake_loss.backward()\n",
    "        self.dis_optim.step()\n",
    "        self.fake_loss.append(fake_loss.item())\n",
    "        \n",
    "        for p in self.discriminator.parameters():\n",
    "            p = torch.clamp(p, -self.clip, self.clip)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGAN(\n",
      "  (generator): GANMLP(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (discriminator): GANMLP(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=50, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bce_loss): BCELoss()\n",
      "  (auxiliary_loss_function): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = GANMLP([100, 50, 4])\n",
    "discriminator = GANMLP([4, 50, 1], final_act_fct=None)\n",
    "gen_optim = torch.optim.Adam(generator.parameters())\n",
    "dis_optim = torch.optim.Adam(discriminator.parameters())\n",
    "model = WGAN(generator, discriminator, gen_optim, dis_optim)\n",
    "print(model)\n",
    "\n",
    "data = DummyDataset(n_samples=100, n_cat_feats=0, n_cont_feats=4, n_targets=1, n_dim=2)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "    \n",
    "for x_cat, x_cont, y in dl:\n",
    "    model(x_cat, x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "\n",
    "class AuxiliaryDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, basic_discriminator, n_classes, final_input_size, len_ts=1, model_type='mlp'):\n",
    "        super(AuxiliaryDiscriminator, self).__init__()\n",
    "        self.basic_discriminator = basic_discriminator\n",
    "        self.n_classes = n_classes\n",
    "        self.final_input_size = final_input_size\n",
    "        self.len_ts = len_ts\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if self.model_type == 'mlp':\n",
    "            self.adv_layer = nn.Sequential(nn.Linear(self.final_input_size, 1), nn.Sigmoid())\n",
    "            self.aux_layer = nn.Sequential(nn.Linear(self.final_input_size, self.n_classes), nn.Softmax(dim=1))\n",
    "        elif self.model_type == 'cnn':\n",
    "            self.adv_layer = nn.Sequential(nn.Flatten(1), nn.Linear(self.final_input_size*self.len_ts, 1), nn.Sigmoid())\n",
    "            self.aux_layer = nn.Sequential(nn.Flatten(1), nn.Linear(self.final_input_size*self.len_ts, self.n_classes), nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        out = self.basic_discriminator(cats, conts)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return (validity, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGAN(\n",
      "  (generator): GANMLP(\n",
      "    (model): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=4, bias=True)\n",
      "      )\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (discriminator): AuxiliaryDiscriminator(\n",
      "    (basic_discriminator): GANMLP(\n",
      "      (model): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=50, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (adv_layer): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (aux_layer): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=4, bias=True)\n",
      "      (1): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      "  (bce_loss): BCELoss()\n",
      "  (auxiliary_loss_function): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = GANMLP([100, 50, 4])\n",
    "discriminator = GANMLP([4, 50], final_act_fct=None)\n",
    "discriminator = AuxiliaryDiscriminator(basic_discriminator=discriminator, n_classes=4, final_input_size=50, len_ts=1, model_type='mlp')\n",
    "gen_optim = torch.optim.Adam(generator.parameters())\n",
    "dis_optim = torch.optim.Adam(discriminator.parameters())\n",
    "model = WGAN(generator, discriminator, gen_optim, dis_optim)\n",
    "print(model)\n",
    "\n",
    "data = DummyDataset(n_samples=100, n_cat_feats=0, n_cont_feats=4, n_targets=1, n_dim=2)\n",
    "dl = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, drop_last=True)\n",
    "    \n",
    "for x_cat, x_cont, y in dl:\n",
    "    model(x_cat, x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_gan_model(gan_type, model_type, structure, len_ts=1, n_classes=1):\n",
    "    gen_structure = structure.copy()\n",
    "    structure.reverse()\n",
    "    dis_structure = structure\n",
    "    dis_structure[-1] = 1\n",
    "    n_z = gen_structure[0]\n",
    "    \n",
    "    if model_type == 'mlp':\n",
    "        model_fct = GANMLP\n",
    "    elif model_type == 'cnn':\n",
    "        model_fct = GANCNN\n",
    "    \n",
    "    if gan_type == 'bce' or gan_type == 'aux':\n",
    "        final_act_dis = nn.Sigmoid\n",
    "        opt_fct = torch.optim.Adam\n",
    "        gan_class = GAN\n",
    "    elif gan_type == 'wgan':\n",
    "        final_act_dis = None\n",
    "        opt_fct = torch.optim.RMSprop\n",
    "        gan_class = WGAN\n",
    "       \n",
    "    generator = model_fct(ann_structure=gen_structure, act_fct=nn.ReLU, final_act_fct=nn.Sigmoid, transpose=True)\n",
    "    if gan_type == 'aux':\n",
    "        auxiliary = True\n",
    "        dis_structure = dis_structure[:-1]\n",
    "        final_input_size = dis_structure[-1]\n",
    "        discriminator = model_fct(ann_structure=dis_structure, act_fct=nn.LeakyReLU, final_act_fct=final_act_dis)\n",
    "        discriminator = AuxiliaryDiscriminator(basic_discriminator=discriminator, n_classes=n_classes, final_input_size=final_input_size, len_ts=len_ts, model_type=model_type)  \n",
    "    else:\n",
    "        auxiliary = False\n",
    "        discriminator = model_fct(ann_structure=dis_structure, act_fct=nn.LeakyReLU, final_act_fct=final_act_dis)\n",
    "        \n",
    "    gen_opt = opt_fct(params=generator.parameters())\n",
    "    dis_opt = opt_fct(params=discriminator.parameters())\n",
    "    model = gan_class(generator=generator, discriminator=discriminator, gen_optim=gen_opt, dis_optim=dis_opt, n_z=n_z, auxiliary=auxiliary)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
