{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: API details.\n",
    "output-file: autoencoder_models.html\n",
    "title: models.autoencoders\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# default_exp models.autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from fastrenewables.tabular.model import *\n",
    "from fastrenewables.timeseries.model import *\n",
    "from fastai.tabular.all import *\n",
    "from torch.autograd import Variable\n",
    "from sklearn.datasets import make_regression\n",
    "from fastai.learner import *\n",
    "from fastrenewables.utils_pytorch import *\n",
    "from fastrenewables.losses import VAEReconstructionLoss\n",
    "from blitz.utils import variational_estimator\n",
    "from fastrenewables.utils_blitz import set_train_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@variational_estimator\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, categorical_data, continuous_data, as_np=False):\n",
    "        z = self.encoder(categorical_data, continuous_data)\n",
    "        \n",
    "        if as_np: return to_np(z)\n",
    "        else: return z\n",
    "        \n",
    "    \n",
    "    def decode(self, categorical_data, continuous_data, as_np=False):\n",
    "        x = self.decoder(categorical_data, continuous_data)\n",
    "        \n",
    "        if as_np: return to_np(x)\n",
    "        else: return x\n",
    "        \n",
    "    def forward(self, categorical_data, continuous_data):\n",
    "        x = self.encode(categorical_data, continuous_data)\n",
    "        x = self.decode(categorical_data, x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        set_train_mode(self, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create some data that we wann to compress through an autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "N = 2000\n",
    "X, y = make_regression(n_samples=N, n_features=20, n_informative=15)\n",
    "df = pd.DataFrame(X)\n",
    "x_names = [str(c) for c in df.columns]\n",
    "df.columns = x_names\n",
    "df[\"y\"] = (y - y.min())/(y.max()-y.min())\n",
    "dls = TabularDataLoaders.from_df(df, cont_names=x_names, y_names=x_names, deivce=\"cpu\", procs=Normalize, bs=N//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean        0.536016\n",
       "std         0.141274\n",
       "min         0.000000\n",
       "25%         0.440804\n",
       "50%         0.538036\n",
       "75%         0.632638\n",
       "max         1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 20]), torch.Size([200, 20]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()[1].shape, dls.one_batch()[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "num_features = get_c(dls)\n",
    "ann_structure = [num_features, num_features*5, 5]\n",
    "ae = Autoencoder(MultiLayerPerceptron(ann_structure), MultiLayerPerceptron(ann_structure[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, ae, metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.428278</td>\n",
       "      <td>1.092438</td>\n",
       "      <td>1.045198</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.152587</td>\n",
       "      <td>1.000705</td>\n",
       "      <td>1.000353</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.028257</td>\n",
       "      <td>0.876347</td>\n",
       "      <td>0.936134</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.952321</td>\n",
       "      <td>0.812868</td>\n",
       "      <td>0.901592</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.902199</td>\n",
       "      <td>0.810575</td>\n",
       "      <td>0.900320</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.868325</td>\n",
       "      <td>0.785216</td>\n",
       "      <td>0.886124</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.841133</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.879779</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.820236</td>\n",
       "      <td>0.762218</td>\n",
       "      <td>0.873051</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.803485</td>\n",
       "      <td>0.765871</td>\n",
       "      <td>0.875141</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.789689</td>\n",
       "      <td>0.759147</td>\n",
       "      <td>0.871291</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=5e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast based on latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a model that is a wrapper for an autoencoder to forecast a regression or classification based on the latent space from an autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@variational_estimator\n",
    "class AutoencoderForecast(nn.Module):\n",
    "    def __init__(self, autoencoder, forecast_model):\n",
    "        super().__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.forecast_model = forecast_model\n",
    "        \n",
    "    def forward(self, categorical_data, continuous_data):\n",
    "        \n",
    "        latent_space = self.autoencoder.encode(categorical_data, continuous_data)\n",
    "        yhat = self.forecast_model(categorical_data, latent_space)\n",
    "        \n",
    "        return yhat\n",
    "    \n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        set_train_mode(self, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the data loader that has the target feature as output in the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "freeze(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (encoder): (\n",
      "  (Identity())\n",
      "  (ModuleList())\n",
      "  (Dropout(p=0.0, inplace=False))\n",
      "  (BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False\n",
      "   (layers): (\n",
      "    Sequential (0): (\n",
      "      (Linear(in_features=20, out_features=100, bias=False)) Requires grad: False\n",
      "      (ReLU(inplace=True))\n",
      "      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False\n",
      "    )\n",
      "    Sequential (1): (\n",
      "      (Linear(in_features=100, out_features=5, bias=True)) Requires grad: False\n",
      "    )\n",
      "  )\n",
      ")\n",
      " (decoder): (\n",
      "  (Identity())\n",
      "  (ModuleList())\n",
      "  (Dropout(p=0.0, inplace=False))\n",
      "  (BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False\n",
      "   (layers): (\n",
      "    Sequential (0): (\n",
      "      (Linear(in_features=5, out_features=100, bias=False)) Requires grad: False\n",
      "      (ReLU(inplace=True))\n",
      "      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False\n",
      "    )\n",
      "    Sequential (1): (\n",
      "      (Linear(in_features=100, out_features=20, bias=True)) Requires grad: False\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print_requires_grad(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(df, cont_names=x_names, y_names=\"y\", deivce=\"cpu\",procs=Normalize, bs=N//10)\n",
    "mlp_regression = MultiLayerPerceptron([ann_structure[-1], get_c(dls)])\n",
    "model = AutoencoderForecast(learn.model, mlp_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     []                  \n",
       "Identity                                                       \n",
       "BatchNorm1d                               40         False     \n",
       "____________________________________________________________________________\n",
       "                     200 x 100           \n",
       "Linear                                    2000       False     \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               200        False     \n",
       "____________________________________________________________________________\n",
       "                     200 x 5             \n",
       "Linear                                    505        False     \n",
       "ReLU                                                           \n",
       "Identity                                                       \n",
       "BatchNorm1d                               10         True      \n",
       "____________________________________________________________________________\n",
       "                     200 x 1             \n",
       "Linear                                    6          True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 2,761\n",
       "Total trainable params: 16\n",
       "Total non-trainable params: 2,745\n",
       "\n",
       "Optimizer used: <function Adam>\n",
       "Loss function: FlattenedLoss of MSELoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.349329</td>\n",
       "      <td>0.271204</td>\n",
       "      <td>0.520773</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.257536</td>\n",
       "      <td>0.129253</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.196753</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.264711</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.153731</td>\n",
       "      <td>0.043250</td>\n",
       "      <td>0.207967</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.122593</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.171098</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class UnFlatten(nn.Module):\n",
    "        \n",
    "    def forward(self, input, dims):\n",
    "        return input.view(*dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@variational_estimator\n",
    "class VariationalAutoencoder(Autoencoder):\n",
    "    def __init__(self, encoder, decoder, h_dim, z_dim, is_ts=False, kernel_size=3):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = UnFlatten()\n",
    "        \n",
    "        \n",
    "        if is_ts:\n",
    "            self.hidden2mu = nn.Conv1d(h_dim, z_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "            self.hidden2logvar = nn.Conv1d(h_dim, z_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        else:\n",
    "            self.hidden2mu = nn.Linear(h_dim, z_dim)\n",
    "            self.hidden2logvar = nn.Linear(h_dim, z_dim)\n",
    "        \n",
    "        \n",
    "        self.latent_dimensions = None\n",
    "        self._mu, self._logvar = None, None\n",
    "        \n",
    "    def encode(self, categorical_data, continuous_data, as_np=False):\n",
    "        \n",
    "        x_hidden = self.encoder(categorical_data, continuous_data)\n",
    "        \n",
    "#         self.latent_dimensions = x_hidden.shape\n",
    "        \n",
    "#         x_hidden = self.flatten(x_hidden)\n",
    "        \n",
    "        mu, logvar = self.hidden2mu(x_hidden), self.hidden2logvar(x_hidden)\n",
    "        \n",
    "        # required for vae loss\n",
    "        self._mu, self._logvar = mu, logvar\n",
    "        \n",
    "        z = self.reparam(mu, logvar)\n",
    "        \n",
    "        if as_np: return to_np(z)\n",
    "        else: return z\n",
    "\n",
    "    def decode(self, categorical_data, continuous_data, as_np=False, latent_dimensions=None):\n",
    "        \n",
    "#         if not latent_dimensions and not self.latent_dimensions:\n",
    "#             raise ValueError(\"latent_dimensions are not set to unflatten data.\")\n",
    "#         if not latent_dimensions:\n",
    "#             latent_dimensions = self.latent_dimensions\n",
    "            \n",
    "#         x = self.unflatten(continuous_data, latent_dimensions)\n",
    "        \n",
    "        x = self.decoder(categorical_data, continuous_data)\n",
    "        \n",
    "        if as_np: return to_np(x)\n",
    "        else: return x\n",
    "        \n",
    "    def get_posteriors(self, categorical_data, continuous_data):\n",
    "\n",
    "        return self.encode(continuous_data, categorical_data)\n",
    "\n",
    "    def get_z(self, categorical_data, continuous_data):\n",
    "        \"\"\"Encode a batch of data points, x, into their z representations.\"\"\"\n",
    "\n",
    "        mu, logvar = self.encode(categorical_data, continuous_data)\n",
    "        \n",
    "        return self.reparam(mu, logvar)\n",
    "\n",
    "    def reparam(self, mu, logvar):\n",
    "        \"\"\"Reparameterisation trick to sample z values.\n",
    "        This is stochastic during training, and returns the mode during evaluation.\"\"\"\n",
    "\n",
    "        if self.training:\n",
    "            # convert logarithmic variance to standard deviation representation\n",
    "            std = torch.exp(logvar / 2)\n",
    "            \n",
    "            # create normal distribution as large as the data\n",
    "            eps = torch.randn_like(std)\n",
    "            # scale by learned mean and standard deviation\n",
    "            return mu + eps*std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        set_train_mode(self, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(df, cont_names=x_names, y_names=x_names, deivce=\"cpu\", procs=Normalize, bs=N//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "num_features = get_c(dls)\n",
    "ann_structure = [num_features, num_features*5, 5]\n",
    "ae = VariationalAutoencoder(MultiLayerPerceptron(ann_structure), \n",
    "                            MultiLayerPerceptron(ann_structure[::-1]), \n",
    "                            ann_structure[-1], ann_structure[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, ae, loss_func=VAEReconstructionLoss(ae), metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.596399</td>\n",
       "      <td>1.065887</td>\n",
       "      <td>1.013617</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.332493</td>\n",
       "      <td>1.035455</td>\n",
       "      <td>0.998344</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.218520</td>\n",
       "      <td>1.016526</td>\n",
       "      <td>0.989190</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.151910</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>0.976294</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.110286</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>0.968629</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.081265</td>\n",
       "      <td>0.984784</td>\n",
       "      <td>0.961178</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.060152</td>\n",
       "      <td>0.977901</td>\n",
       "      <td>0.958488</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.044141</td>\n",
       "      <td>0.971379</td>\n",
       "      <td>0.955548</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.030627</td>\n",
       "      <td>0.966010</td>\n",
       "      <td>0.945443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.019400</td>\n",
       "      <td>0.963970</td>\n",
       "      <td>0.943432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=5e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast based on latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "freeze(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(df, cont_names=x_names, y_names=\"y\", deivce=\"cpu\",procs=Normalize, bs=N//10)\n",
    "mlp_regression = MultiLayerPerceptron([ann_structure[-1], get_c(dls)])\n",
    "model = AutoencoderForecast(learn.model, mlp_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     []                  \n",
       "Identity                                                       \n",
       "BatchNorm1d                               40         False     \n",
       "____________________________________________________________________________\n",
       "                     200 x 100           \n",
       "Linear                                    2000       False     \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               200        False     \n",
       "____________________________________________________________________________\n",
       "                     200 x 5             \n",
       "Linear                                    505        False     \n",
       "ReLU                                                           \n",
       "Linear                                    30         False     \n",
       "Linear                                    30         False     \n",
       "Identity                                                       \n",
       "BatchNorm1d                               10         True      \n",
       "____________________________________________________________________________\n",
       "                     200 x 1             \n",
       "Linear                                    6          True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 2,821\n",
       "Total trainable params: 16\n",
       "Total non-trainable params: 2,805\n",
       "\n",
       "Optimizer used: <function Adam>\n",
       "Loss function: FlattenedLoss of MSELoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(dls, model, metrics=rmse)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.292249</td>\n",
       "      <td>0.062326</td>\n",
       "      <td>0.249652</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209268</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>0.184123</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152156</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>0.149691</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113911</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.140529</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089203</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.138215</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks that the autoencoders also work with temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ts_length = 24\n",
    "n_features = 10\n",
    "n_samples = 3\n",
    "latent_dim  = 2 \n",
    "ann_structure = [10, latent_dim]\n",
    "\n",
    "x = torch.randn(( n_samples, n_features,ts_length), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ae_tcn = Autoencoder(TemporalCNN(ann_structure), TemporalCNN(ann_structure[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "yhat = ae_tcn(None, x)\n",
    "\n",
    "test_eq(True, yhat.requires_grad)\n",
    "test_eq([n_samples, n_features, ts_length], list(yhat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "vae_tcn = VariationalAutoencoder(TemporalCNN(ann_structure), \n",
    "                                TemporalCNN(ann_structure[::-1]),\n",
    "#                                ann_structure[-1]*ts_length, ann_structure[-1]*ts_length)\n",
    "                                 ann_structure[-1], ann_structure[-1], is_ts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "yhat = vae_tcn(None, x)\n",
    "\n",
    "test_eq(True, yhat.requires_grad)\n",
    "test_eq([n_samples, n_features, ts_length], list(yhat.shape))\n",
    "test_eq([n_samples, latent_dim,ts_length], list(vae_tcn._mu.shape))\n",
    "test_eq([n_samples, latent_dim,ts_length], list(vae_tcn._logvar.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
