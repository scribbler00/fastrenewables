# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00e_metrics.ipynb.

# %% auto 0
__all__ = ['crps_for_quantiles', 'rmse_nll', 'normalized_sum_of_squared_residuals_np', 'distance_ideal_curve',
           'normalized_sum_of_squared_residuals_torch', 'energy_distance']

# %% ../nbs/00e_metrics.ipynb 2
#| include: false
import numpy as np
import torch
from scipy.stats import chi2 as Chi2Dist
import matplotlib.pyplot as plt
from sklearn.metrics import auc
from fastcore.test import *
from fastai.metrics import rmse
import dcor

# %% ../nbs/00e_metrics.ipynb 3
def crps_for_quantiles(probabilistic_forecasts, measurements, quantiles=np.linspace(0.1, 0.9, 9)):
    """ Computes the CRPS score with quantile representation.
        This variant is the variant proposed in Hersbach H. Decomposition of the Continuous Ranked Probability Score for
        Ensemble Prediction Systems. Weather Forecast. 2000;15(5):559-570.
        Parameters
        ----------
            probabilistic_forecasts: array_like
               Either list of "M" scipy.stats.rv_continuous distributions
               https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.html
               OR
               2D-numpy array with quantile forecasts with dimensionality M x Q,
               where "Q" is number of quantiles.
            measurements: array_like
               List or numpy array with "M" measurements / observations.
            quantiles: array_like
               List of "Q" values of the quantiles to be evaluated.
        Returns
        -------
            mean_crps: float
                The mean CRIGN over all probabilistic_forecast - measurement pairs.
            single_crps: array, shape (M,)
                CRIGN value for each probabilistic_forecast - measurement pair.
    """

    quantile_forecasts = np.array(probabilistic_forecasts)

    measurements = np.atleast_2d(measurements).T

    alpha_mat = np.diff(np.hstack([quantile_forecasts, measurements]))
    alpha_mat = np.maximum(0, alpha_mat)
    alpha_mat = np.minimum(alpha_mat, np.maximum(0, np.repeat(measurements, quantile_forecasts.shape[1],
                                                              axis=1) - quantile_forecasts))

    beta_mat = np.diff(np.hstack([measurements, quantile_forecasts]))
    beta_mat = np.maximum(0, beta_mat)
    beta_mat = np.minimum(beta_mat,
                          np.maximum(0,
                                     quantile_forecasts - np.repeat(measurements, quantile_forecasts.shape[1], axis=1)))

    single_crps = np.matmul(alpha_mat, np.power(quantiles, 2)) + np.matmul(beta_mat, np.power(quantiles - 1, 2))

    return np.mean(single_crps), single_crps

# %% ../nbs/00e_metrics.ipynb 6
def rmse_nll(preds, targs, pos_mean=0):
    """RMSE for negative log likelihood forecast, where we have e.g. the mean and the variance as prediction."""
    return rmse(preds[:, pos_mean], targs)

# %% ../nbs/00e_metrics.ipynb 7
def normalized_sum_of_squared_residuals_np(stochastic_preds, targets):
    """
        Calculates normalized sof of squared residuals according to Eq. 50-52 in https://arxiv.org/pdf/2007.06823.pdf 
        stochastic samples of shape [n_observation, n_targets, n_samples]
        targets of shape [n_observation, n_targets]
    """
    nruntests = len(stochastic_preds)
    predictions = stochastic_preds.mean(axis=-1, keepdims=True)
    errors = targets - predictions.squeeze(-1)
    covs = stochastic_preds-predictions
    
    covs = (covs @ covs.swapaxes(1,2)) / (nruntests-1.)
    
    
    weights = np.linalg.inv(covs)
    nssr = np.matmul(errors[:,np.newaxis,:], np.matmul(weights, errors[:,:,np.newaxis]))
   
    nssr = np.sort(nssr.flatten())
    
    p_prediction = Chi2Dist.cdf(nssr, targets.shape[1]);
    p_expected = np.linspace(1./nssr.size, 1.0, nssr.size)
    
    return p_prediction, p_expected

# %% ../nbs/00e_metrics.ipynb 14
def distance_ideal_curve(p_prediction, p_expected):
    return np.trapz((p_prediction-p_expected)**2)**0.5

# %% ../nbs/00e_metrics.ipynb 16
def normalized_sum_of_squared_residuals_torch(stochastic_preds, targets):
    """
        Calculates normalized sof of squared residuals according to Eq. 50-52 in https://arxiv.org/pdf/2007.06823.pdf 
        stochastic samples of shape [n_observation, n_targets, n_samples]
        targets of shape [n_observation, n_targets]
    """
    
    predictions = stochastic_preds.mean(axis=-1, keepdim=True)
    errors = targets - predictions.squeeze(dim=-1)
    nruntests = len(stochastic_preds)
    predictions = stochastic_preds.mean(axis=-1, keepdims=True)
    covs = stochastic_preds - predictions
    
    covs = torch.matmul(covs, torch.transpose(covs, 1, 2))/(nruntests-1.)
    
    
    weights = torch.linalg.inv(covs) #
    nssr = torch.matmul(errors[:,np.newaxis,:].float(), 
                    torch.matmul(weights.float(), errors[:,:,np.newaxis].float()).float() )
    
    nssr = nssr.cpu().numpy().flatten()
    nssr = np.sort(nssr)
    
    p_prediction = Chi2Dist.cdf(nssr, targets.shape[1]);
    p_expected = np.linspace(1./nssr.size, 1.0, nssr.size)
    
    return p_prediction, p_expected

# %% ../nbs/00e_metrics.ipynb 22
def energy_distance(samples, targets):
    """
        samples tensor (e.g. from a Bayesian Model) of shape [n_observation, n_samples]
        target tensor observatrion fo shape [n_observation, 1]
    """
    return dcor.energy_distance(samples.reshape(samples.shape[0], samples.shape[-1]).T, targets.T)
