# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00c_utils_blitz.ipynb (unless otherwise specified).

__all__ = ['convert_layer_to_bayesian', 'convert_to_bayesian_model', 'set_train_mode']

# Cell
#hide
from blitz.modules import BayesianLinear
from blitz.modules import BayesianEmbedding, BayesianConv1d, BayesianConv2d, BayesianConv3d
from blitz.modules.base_bayesian_module import BayesianModule
from torch import nn
import torch
from fastcore.basics import patch

# Cell
def convert_layer_to_bayesian(layer, config: dict):
    if isinstance(layer, torch.nn.Linear):
        new_layer = BayesianLinear(
            layer.in_features,
            layer.out_features,
            prior_sigma_1=config["prior_sigma_1"],
            prior_sigma_2=config["prior_sigma_2"],
            prior_pi=config["prior_pi"],
            posterior_mu_init=config["posterior_mu_init"],
            posterior_rho_init=config["posterior_rho_init"],
        )
    elif isinstance(layer, nn.Embedding):
        new_layer = BayesianEmbedding(
            layer.num_embeddings,
            layer.embedding_dim,
            prior_sigma_1=config["prior_sigma_1"],
            prior_sigma_2=config["prior_sigma_2"],
            prior_pi=config["prior_pi"],
            posterior_mu_init=config["posterior_mu_init"],
            posterior_rho_init=config["posterior_rho_init"],
        )
    elif isinstance(layer, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):
        matching_class = BayesianConv1d
        kernel_size = layer.kernel_size[0]
        if type(layer) == nn.Conv2d:
            kernel_size = layer.kernel_size
            matching_class = BayesianConv2d
        elif type(layer) == nn.Conv3d:
            matching_class = BayesianConv3d
            kernel_size = layer.kernel_size
        new_layer = matching_class(
            layer.in_channels,
            layer.out_channels,
            kernel_size=kernel_size,
            groups=layer.groups,
            padding=layer.padding,
            dilation=layer.dilation,
            prior_sigma_1=config["prior_sigma_1"],
            prior_sigma_2=config["prior_sigma_2"],
            prior_pi=config["prior_pi"],
            posterior_mu_init=config["posterior_mu_init"],
            posterior_rho_init=config["posterior_rho_init"],
        )
    else:
        Warning(
            f"Could not find correct type for conversion of layer {layer} with type {type(layer)}"
        )
        new_layer = layer

    return new_layer

# Cell
def convert_to_bayesian_model(model, config: dict):
    for p in model.named_children():
        cur_layer_name = p[0]
        cur_layer = p[1]
        if len(list(cur_layer.named_children())) > 0:
            convert_to_bayesian_model(cur_layer, config)
        elif not isinstance(cur_layer, BayesianModule):
            new_layer = convert_layer_to_bayesian(cur_layer, config)
            setattr(model, cur_layer_name, new_layer)

    return model

# Cell
def set_train_mode(model, mode):
    if isinstance(model, BayesianModule):
        model.freeze = not mode

    for module in model.children():
        set_train_mode(module, mode)