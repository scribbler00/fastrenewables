# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_tabular.learner.ipynb (unless otherwise specified).

__all__ = ['fast_prediction', 'RenewableLearner', 'renewable_learner']

# Cell
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.tabular.data import *
from fastai.tabular.core import *
from fastai.tabular.model import *
from fastai.basics import *
from .core import *
from .data import *
from .model import *
from ..losses import VILoss
from ..utils import *

# Cell
def fast_prediction(model, to, flatten, filter, device="cpu"):
     # to increase speed we direclty predict on all tensors
    if isinstance(to, (TabularPandas, TabularRenewables, TabDataLoader)):
        if getattr(to, 'regression_setup', False):
            ys_type = np.float32
        else:
            ys_type = np.long

        cats = tensor(to.cats.values.astype(np.long))
        xs = tensor(to.conts.values.astype(np.float32))
        targets = tensor(to.ys.values.astype(ys_type))

        with torch.no_grad():
            preds = model.to(device)(cats.to(device), xs.to(device))

        preds, targets = to_np(preds), to_np(targets)
        if flatten:
            preds, targets = preds.reshape(-1), targets.reshape(-1)

        if filter:
            targets, preds = filter_preds(targets, preds)
    else:
        raise NotImplementedError("Unknown type")

    return preds, targets


# Cell
class RenewableLearner(Learner):
    "`Learner` for renewable data."
    def predict(self, ds_idx=1, test_dl=None, filter=True, flatten=True):
        device = next(self.model.parameters()).device
        preds, targets = None, None
        if test_dl is not None:
            to = test_dl.train_ds
        elif ds_idx == 0:
            to = self.dls.train_ds
        elif ds_idx == 1:
            to = self.dls.valid_ds

        preds, targets = fast_prediction(self.model, to, flatten=flatten, filter=filter)

        return preds, targets

# Cell
@delegates(Learner.__init__)
def renewable_learner(dls, layers=None, emb_szs=None, config=None, n_out=None, y_range=None, embedding_type=EmbeddingType.Normal, **kwargs):
    "Get a `Learner` using `dls`, with `metrics`, including a `RenewableModel` created using the remaining params."
    if config is None: config = tabular_config()

    if n_out is None: n_out = get_c(dls)
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"

    if layers is None: layers = [len(dls.cont_names), 200, 100, n_out]
    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')

    embed_p = kwargs["embed_p"].pop() if "embed_p" in kwargs.keys() else 0.1

    emb_module = None
    if len(dls.train_ds.cat_names) > 0:
        emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)
        emb_module = EmbeddingModule(None, embedding_dropout=embed_p, embedding_dimensions=emb_szs)

    model = MultiLayerPerceptron(layers, embedding_module=emb_module, **config)

    if embedding_type==EmbeddingType.Bayes and "loss_func" not in kwargs.keys():
        base_loss = getattr(dls.train_ds, 'loss_func', None)
        assert base_loss is not None, "Could not infer loss function from the data, please pass a loss function."
        loss_func=VILoss(model=model, base_loss=base_loss, kl_weight=0.1)
        kwargs["loss_func"] = loss_func

    return RenewableLearner(dls, model, **kwargs)