# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_tabular.learner.ipynb (unless otherwise specified).

__all__ = ['RenewableLearner', 'renewable_learner']

# Cell
from fastai.torch_basics import *
from fastai.data.all import *
from fastai.tabular.data import *
from fastai.tabular.core import *
from fastai.tabular.model import *
from fastai.basics import *
from .core import *
from .data import *
from .model import *
from ..losses import VILoss

# Cell
class RenewableLearner(Learner):
    "`Learner` for renewable data"
    def predict(self, ds_idx=1, test_dl=None, filter=True):
        device = next(self.model.parameters()).device

        if test_dl is not None:
            cur_dl = test_dl
        elif ds_idx == 0:
            cur_dl = self.dls.train_ds
        elif ds_idx == 1:
            cur_dl = self.dls.valid_ds

        if type(cur_dl) == TabularPandas or \
            type(cur_dl) == TabDataLoader or \
            type(cur_dl) == TabularRenewables:

            cats = tensor(cur_dl.cats.values).long()
            xs = tensor(cur_dl.conts.values)
            targets = tensor(cur_dl.y.values)

        with torch.no_grad():
            preds = self.model(cats.to(device), xs.to(device))

        preds, targets = to_np(preds).reshape(-1), to_np(targets).reshape(-1)
        if filter:
            preds[preds < 0] = 0
            preds[preds > 1.1] = 1.1

        return preds, targets

# Cell
@delegates(Learner.__init__)
def renewable_learner(dls, layers=None, emb_szs=None, config=None, n_out=None, y_range=None, embedding_type=EmbeddingType.Normal, **kwargs):
    "Get a `Learner` using `dls`, with `metrics`, including a `TabularModel` created using the remaining params."
    if config is None: config = tabular_config()

    to = dls.train_ds
    emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)
    if n_out is None: n_out = get_c(dls)
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"

    if layers is None: layers = [len(dls.cont_names), 200, 100, n_out]
    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')

    embed_p = kwargs["embed_p"].pop() if "embed_p" in kwargs.keys() else 0.1

    if emb_szs is not None:
        emb_module = EmbeddingModule(None, embedding_dropout=embed_p, embedding_dimensions=emb_szs)

    model = MultiLayerPerceptron(layers, embedding_module=emb_module, **config)

    if embedding_type==EmbeddingType.Bayes and "loss_func" not in kwargs.keys():
        base_loss = getattr(dls.train_ds, 'loss_func', None)
        assert base_loss is not None, "Could not infer loss function from the data, please pass a loss function."
        loss_func=VILoss(model=model, base_loss=base_loss, kl_weight=0.1)
        kwargs["loss_func"] = loss_func

    return RenewableLearner(dls, model, **kwargs)