# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00g_synthetic_data.ipynb (unless otherwise specified).

__all__ = ['plot_class_hists', 'fit_kde', 'calculate_kld', 'GaussianDataset']

# Cell

import torch
import numpy as np
import matplotlib.pyplot as plt
import torch.nn.functional as F

from sklearn.neighbors import KernelDensity

# Cell

def plot_class_hists(x_cat, x_cont, bandwidth=1/25, figsize=(16, 9)):
    plt.figure(figsize=figsize)
    for c in x_cat.unique():
        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)
        x_plot = x_cont[x_cat==c].reshape(-1, 1)
        kde.fit(x_plot)
        x_range = np.linspace(0, 1, 100).reshape(-1, 1)
        log_dens = kde.score_samples(x_range)
        plt.plot(x_range, np.exp(log_dens), label=f'{int(c)}')
        plt.hist(x_plot.reshape(1, -1), alpha=0.75, label=f'{int(c)}', density=True)
    plt.xlim(0, 1)
    plt.show()
    return

def fit_kde(x, kernel='gaussian', bandwidth=1/25, x_min=0, x_max=1, n_x=1000, figsize=(16, 9), show_plot=False):
    x_range = np.linspace(x_min, x_max, n_x).reshape(-1, 1)

    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth)
    kde.fit(x.reshape(-1, 1))
    x_score = kde.score_samples(x_range)

    if show_plot:
        plt.figure(figsize=figsize)
        plt.plot(x_range, np.exp(x_score))
        plt.hist(x.reshape(1, -1), alpha=0.75, density=True, bins=25)
        plt.xlim(x_min, x_max)
        plt.show()
    return x_score

def calculate_kld(p, q):
    p = torch.tensor(p)
    q = torch.tensor(q)

    pq = F.kl_div(p, q, reduction='batchmean', log_target=True)
    qp = F.kl_div(q, p, reduction='batchmean', log_target=True)

    kl_div = (pq+qp)/2
    return kl_div.item()

# Cell

class GaussianDataset(torch.utils.data.Dataset):

    def __init__(self, n_samples=1024, n_classes=2):
        self.n_samples = n_samples
        self.n_classes = n_classes
        self.x_cat = torch.zeros(self.n_samples*self.n_classes, 1)
        self.x_cont = torch.zeros(self.n_samples*self.n_classes, 1)
        self.y = torch.zeros(self.n_samples*self.n_classes, 1)
        self.means = torch.linspace(0, n_classes, n_classes)
        self.scales = torch.linspace(1, 1/n_classes, n_classes)

        self.generate_series()
        self.x_cont = (self.x_cont-self.x_cont.min())/(self.x_cont.max()-self.x_cont.min())

    def generate_series(self):
        for c in range(self.n_classes):
            for idx in range(self.n_samples):
                self.x_cat[c*self.n_samples + idx] = c+1
                self.y[c*self.n_samples + idx] = c
                self.x_cont[c*self.n_samples + idx] = torch.distributions.Normal(self.means[c], self.scales[c]).rsample()

    def __len__(self):
            return self.n_samples*self.n_classes

    def __getitem__(self, idx):
        x_cat = self.x_cat[idx, :]
        x_cont = self.x_cont[idx, :]
        y = self.y[idx, :]
        return x_cat, x_cont, y