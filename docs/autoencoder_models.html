---

title: models.autoencoders


keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs/10_autoencoder_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/10_autoencoder_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Autoencoder">Autoencoder<a class="anchor-link" href="#Autoencoder"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Autoencoder" class="doc_header"><code>class</code> <code>Autoencoder</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L22" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Autoencoder</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="AE-Training">AE Training<a class="anchor-link" href="#AE-Training"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets create some data that we wann to compress through an autoencoder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">x_names</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">x_names</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>count    2000.000000
mean        0.523222
std         0.138718
min         0.000000
25%         0.428973
50%         0.526034
75%         0.616048
max         1.000000
Name: y, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([200, 20]), torch.Size([200, 20]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_features</span> <span class="o">=</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)</span>
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">ae</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> <span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">ae</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.400510</td>
      <td>1.059659</td>
      <td>1.029397</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.139224</td>
      <td>0.915602</td>
      <td>0.956871</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.015282</td>
      <td>0.814481</td>
      <td>0.902486</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.939656</td>
      <td>0.782552</td>
      <td>0.884620</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.889630</td>
      <td>0.762809</td>
      <td>0.873389</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.854850</td>
      <td>0.752478</td>
      <td>0.867455</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.829248</td>
      <td>0.744346</td>
      <td>0.862755</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.809016</td>
      <td>0.740375</td>
      <td>0.860450</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.793158</td>
      <td>0.737706</td>
      <td>0.858898</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.779633</td>
      <td>0.736026</td>
      <td>0.857920</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forecast-based-on-latent-space">Forecast based on latent space<a class="anchor-link" href="#Forecast-based-on-latent-space"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we create a model that is a wrapper for an autoencoder to forecast a regression or classification based on the latent space from an autoencoder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AutoencoderForecast" class="doc_header"><code>class</code> <code>AutoencoderForecast</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L55" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AutoencoderForecast</code>(<strong><code>autoencoder</code></strong>, <strong><code>forecast_model</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we create the data loader that has the target feature as output in the dataloader.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">freeze</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_requires_grad</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> (encoder): (
  (Identity())
  (ModuleList())
  (Dropout(p=0.0, inplace=False))
  (BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
   (layers): (
    Sequential (0): (
      (Linear(in_features=20, out_features=100, bias=False)) Requires grad: False
      (ReLU(inplace=True))
      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
    )
    Sequential (1): (
      (Linear(in_features=100, out_features=5, bias=True)) Requires grad: False
    )
  )
)
 (decoder): (
  (Identity())
  (ModuleList())
  (Dropout(p=0.0, inplace=False))
  (BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
   (layers): (
    Sequential (0): (
      (Linear(in_features=5, out_features=100, bias=False)) Requires grad: False
      (ReLU(inplace=True))
      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
    )
    Sequential (1): (
      (Linear(in_features=100, out_features=20, bias=True)) Requires grad: False
    )
  )
)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span><span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mlp_regression</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">([</span><span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderForecast</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">mlp_regression</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     []                  
Identity                                                       
BatchNorm1d                               40         False     
____________________________________________________________________________
                     200 x 100           
Linear                                    2000       False     
ReLU                                                           
BatchNorm1d                               200        False     
____________________________________________________________________________
                     200 x 5             
Linear                                    505        False     
ReLU                                                           
Identity                                                       
BatchNorm1d                               10         True      
____________________________________________________________________________
                     200 x 1             
Linear                                    6          True      
____________________________________________________________________________

Total params: 2,761
Total trainable params: 16
Total non-trainable params: 2,745

Optimizer used: &lt;function Adam at 0x7f2c55772f70&gt;
Loss function: FlattenedLoss of MSELoss()

Callbacks:
  - TrainEvalCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.314161</td>
      <td>0.260491</td>
      <td>0.510383</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.247836</td>
      <td>0.158668</td>
      <td>0.398332</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.199370</td>
      <td>0.097397</td>
      <td>0.312085</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.160442</td>
      <td>0.061318</td>
      <td>0.247625</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.130171</td>
      <td>0.042172</td>
      <td>0.205357</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Variational-Autoencoder">Variational Autoencoder<a class="anchor-link" href="#Variational-Autoencoder"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="VAE-Training">VAE Training<a class="anchor-link" href="#VAE-Training"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnFlatten" class="doc_header"><code>class</code> <code>UnFlatten</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L73" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnFlatten</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VariationalAutoencoder" class="doc_header"><code>class</code> <code>VariationalAutoencoder</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L80" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VariationalAutoencoder</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>, <strong><code>h_dim</code></strong>, <strong><code>z_dim</code></strong>) :: <a href="/fastrenewables/autoencoder_models.html#Autoencoder"><code>Autoencoder</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_features</span> <span class="o">=</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)</span>
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">ae</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> 
                            <span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
                            <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">ae</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">VAEReconstructionLoss</span><span class="p">(</span><span class="n">ae</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.625394</td>
      <td>1.027008</td>
      <td>0.999831</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.353855</td>
      <td>1.009958</td>
      <td>0.981047</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.232008</td>
      <td>0.987417</td>
      <td>0.979559</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.164160</td>
      <td>0.975075</td>
      <td>0.970965</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.120605</td>
      <td>0.967925</td>
      <td>0.961196</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.089931</td>
      <td>0.962036</td>
      <td>0.962075</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.068224</td>
      <td>0.961635</td>
      <td>0.958414</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.051640</td>
      <td>0.960990</td>
      <td>0.960682</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.038519</td>
      <td>0.955296</td>
      <td>0.958315</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.028276</td>
      <td>0.957994</td>
      <td>0.960198</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forecast-based-on-latent-space">Forecast based on latent space<a class="anchor-link" href="#Forecast-based-on-latent-space"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">freeze</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span><span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mlp_regression</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">([</span><span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderForecast</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">mlp_regression</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     []                  
Identity                                                       
BatchNorm1d                               40         False     
____________________________________________________________________________
                     200 x 100           
Linear                                    2000       False     
ReLU                                                           
BatchNorm1d                               200        False     
____________________________________________________________________________
                     200 x 5             
Linear                                    505        False     
ReLU                                                           
Flatten                                                        
Linear                                    30         False     
Linear                                    30         False     
Identity                                                       
BatchNorm1d                               10         True      
____________________________________________________________________________
                     200 x 1             
Linear                                    6          True      
____________________________________________________________________________

Total params: 2,821
Total trainable params: 16
Total non-trainable params: 2,805

Optimizer used: &lt;function Adam at 0x7f2c55772f70&gt;
Loss function: FlattenedLoss of MSELoss()

Callbacks:
  - TrainEvalCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.655513</td>
      <td>0.409079</td>
      <td>0.639593</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.527697</td>
      <td>0.295510</td>
      <td>0.543608</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.432311</td>
      <td>0.213990</td>
      <td>0.462591</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.358125</td>
      <td>0.138118</td>
      <td>0.371642</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.297741</td>
      <td>0.079909</td>
      <td>0.282682</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checks-that-the-autoencoders-also-work-with-temporal-data">Checks that the autoencoders also work with temporal data<a class="anchor-link" href="#Checks-that-the-autoencoders-also-work-with-temporal-data"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ts_length</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">latent_dim</span>  <span class="o">=</span> <span class="mi">2</span> 
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span><span class="n">ts_length</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ae_tcn</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> <span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">ae_tcn</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">yhat</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vae_tcn</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> 
                                <span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                               <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">ts_length</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">vae_tcn</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">yhat</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">*</span><span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">vae_tcn</span><span class="o">.</span><span class="n">_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">*</span><span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">vae_tcn</span><span class="o">.</span><span class="n">_logvar</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

