---

title: models.autoencoders


keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs/10_autoencoder_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/10_autoencoder_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Autoencoder">Autoencoder<a class="anchor-link" href="#Autoencoder"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Autoencoder" class="doc_header"><code>class</code> <code>Autoencoder</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L19" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Autoencoder</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="AE-Training">AE Training<a class="anchor-link" href="#AE-Training"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets create some data that we wann to compress through an autoencoder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">x_names</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">x_names</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>count    2000.000000
mean        0.518202
std         0.160907
min         0.000000
25%         0.408547
50%         0.520172
75%         0.626163
max         1.000000
Name: y, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([200, 20]), torch.Size([200, 20]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_features</span> <span class="o">=</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)</span>
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">ae</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> <span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">ae</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.417418</td>
      <td>1.028195</td>
      <td>1.013999</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.142217</td>
      <td>0.976013</td>
      <td>0.987934</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.022015</td>
      <td>0.859396</td>
      <td>0.927036</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.950629</td>
      <td>0.816512</td>
      <td>0.903610</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.901302</td>
      <td>0.787643</td>
      <td>0.887493</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.865102</td>
      <td>0.772275</td>
      <td>0.878792</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.838625</td>
      <td>0.774557</td>
      <td>0.880089</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.817726</td>
      <td>0.765040</td>
      <td>0.874666</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.800567</td>
      <td>0.758330</td>
      <td>0.870822</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.786278</td>
      <td>0.760223</td>
      <td>0.871907</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forecast-based-on-latent-space">Forecast based on latent space<a class="anchor-link" href="#Forecast-based-on-latent-space"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we create a model that is a wrapper for an autoencoder to forecast a regression or classification based on the latent space from an autoencoder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AutoencoderForecast" class="doc_header"><code>class</code> <code>AutoencoderForecast</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L47" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AutoencoderForecast</code>(<strong><code>autoencoder</code></strong>, <strong><code>forecast_model</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we create the data loader that has the target feature as output in the dataloader.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">freeze</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_requires_grad</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> (encoder): (
  (Identity())
  (ModuleList())
  (Dropout(p=0.0, inplace=False))
  (BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
   (layers): (
    Sequential (0): (
      (Linear(in_features=20, out_features=100, bias=False)) Requires grad: False
      (ReLU(inplace=True))
      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
    )
    Sequential (1): (
      (Linear(in_features=100, out_features=5, bias=True)) Requires grad: False
    )
  )
)
 (decoder): (
  (Identity())
  (ModuleList())
  (Dropout(p=0.0, inplace=False))
  (BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
   (layers): (
    Sequential (0): (
      (Linear(in_features=5, out_features=100, bias=False)) Requires grad: False
      (ReLU(inplace=True))
      (BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) Requires grad: False
    )
    Sequential (1): (
      (Linear(in_features=100, out_features=20, bias=True)) Requires grad: False
    )
  )
)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span><span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mlp_regression</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">([</span><span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderForecast</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">mlp_regression</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     []                  
Identity                                                       
BatchNorm1d                               40         False     
____________________________________________________________________________
                     200 x 100           
Linear                                    2000       False     
ReLU                                                           
BatchNorm1d                               200        False     
____________________________________________________________________________
                     200 x 5             
Linear                                    505        False     
ReLU                                                           
Identity                                                       
BatchNorm1d                               10         True      
____________________________________________________________________________
                     200 x 1             
Linear                                    6          True      
____________________________________________________________________________

Total params: 2,761
Total trainable params: 16
Total non-trainable params: 2,745

Optimizer used: &lt;function Adam at 0x7fb6c4cf3820&gt;
Loss function: FlattenedLoss of MSELoss()

Callbacks:
  - TrainEvalCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.326834</td>
      <td>0.217491</td>
      <td>0.466360</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.235854</td>
      <td>0.111830</td>
      <td>0.334410</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.181198</td>
      <td>0.065184</td>
      <td>0.255312</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.142332</td>
      <td>0.039793</td>
      <td>0.199481</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.114708</td>
      <td>0.032569</td>
      <td>0.180468</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Variational-Autoencoder">Variational Autoencoder<a class="anchor-link" href="#Variational-Autoencoder"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="VAE-Training">VAE Training<a class="anchor-link" href="#VAE-Training"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnFlatten" class="doc_header"><code>class</code> <code>UnFlatten</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L62" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnFlatten</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VariationalAutoencoder" class="doc_header"><code>class</code> <code>VariationalAutoencoder</code><a href="https://github.com/scribbler00/fastrenewables/tree/master/fastrenewables/models/autoencoders.py#L68" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VariationalAutoencoder</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>, <strong><code>h_dim</code></strong>, <strong><code>z_dim</code></strong>) :: <a href="/fastrenewables/autoencoder_models.html#Autoencoder"><code>Autoencoder</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_features</span> <span class="o">=</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)</span>
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_features</span><span class="p">,</span> <span class="n">num_features</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">ae</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> 
                            <span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
                            <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">ae</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">VAEReconstructionLoss</span><span class="p">(</span><span class="n">ae</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.603892</td>
      <td>1.039223</td>
      <td>0.997177</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.352651</td>
      <td>1.030828</td>
      <td>0.993362</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.233508</td>
      <td>1.002076</td>
      <td>0.987172</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.165651</td>
      <td>0.984741</td>
      <td>0.977986</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.121756</td>
      <td>0.970083</td>
      <td>0.971174</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.090632</td>
      <td>0.965951</td>
      <td>0.966367</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.068473</td>
      <td>0.957949</td>
      <td>0.961562</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>1.051438</td>
      <td>0.955730</td>
      <td>0.956740</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>1.037688</td>
      <td>0.954759</td>
      <td>0.954648</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>1.027215</td>
      <td>0.944164</td>
      <td>0.947959</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forecast-based-on-latent-space">Forecast based on latent space<a class="anchor-link" href="#Forecast-based-on-latent-space"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">freeze</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TabularDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cont_names</span><span class="o">=</span><span class="n">x_names</span><span class="p">,</span> <span class="n">y_names</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">deivce</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span><span class="n">procs</span><span class="o">=</span><span class="n">Normalize</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="n">N</span><span class="o">//</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mlp_regression</span> <span class="o">=</span> <span class="n">MultiLayerPerceptron</span><span class="p">([</span><span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">get_c</span><span class="p">(</span><span class="n">dls</span><span class="p">)])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderForecast</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">mlp_regression</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">rmse</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AutoencoderForecast (Input shape: 200 x torch.Size([200, 20]))
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     []                  
Identity                                                       
BatchNorm1d                               40         False     
____________________________________________________________________________
                     200 x 100           
Linear                                    2000       False     
ReLU                                                           
BatchNorm1d                               200        False     
____________________________________________________________________________
                     200 x 5             
Linear                                    505        False     
ReLU                                                           
Flatten                                                        
Linear                                    30         False     
Linear                                    30         False     
Identity                                                       
BatchNorm1d                               10         True      
____________________________________________________________________________
                     200 x 1             
Linear                                    6          True      
____________________________________________________________________________

Total params: 2,821
Total trainable params: 16
Total non-trainable params: 2,805

Optimizer used: &lt;function Adam at 0x7fb6c4cf3820&gt;
Loss function: FlattenedLoss of MSELoss()

Callbacks:
  - TrainEvalCallback
  - Recorder
  - ProgressCallback</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.243670</td>
      <td>0.117833</td>
      <td>0.343267</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.176788</td>
      <td>0.073938</td>
      <td>0.271916</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.134227</td>
      <td>0.046644</td>
      <td>0.215971</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.106050</td>
      <td>0.029965</td>
      <td>0.173103</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.085935</td>
      <td>0.022111</td>
      <td>0.148699</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checks-that-the-autoencoders-also-work-with-temporal-data">Checks that the autoencoders also work with temporal data<a class="anchor-link" href="#Checks-that-the-autoencoders-also-work-with-temporal-data"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ts_length</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">latent_dim</span>  <span class="o">=</span> <span class="mi">2</span> 
<span class="n">ann_structure</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span><span class="n">ts_length</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ae_tcn</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> <span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">ae_tcn</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">yhat</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vae_tcn</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">),</span> 
                                <span class="n">TemporalCNN</span><span class="p">(</span><span class="n">ann_structure</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                               <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">ann_structure</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">ts_length</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">vae_tcn</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">yhat</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">yhat</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">*</span><span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">vae_tcn</span><span class="o">.</span><span class="n">_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">*</span><span class="n">ts_length</span><span class="p">],</span> <span class="nb">list</span><span class="p">(</span><span class="n">vae_tcn</span><span class="o">.</span><span class="n">_logvar</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

